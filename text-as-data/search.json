{
  "articles": [
    {
      "path": "apis.html",
      "title": "Application Programming Interfaces (APIs)",
      "description": "When webscraping is too difficult and/or impolite",
      "author": [],
      "contents": "\r\n\r\nContents\r\nCongress API\r\nStep 1: Keep Your API Key Safe\r\nStep 2: Get the data from the API\r\nStep 3: Convert to content from JSON to an R object\r\nStep 4: Get The Bill Text\r\nPutting Steps 1 through 4 into a function\r\n\r\nYouTube API\r\nHow to Drive Python from RStudio\r\nStep 1: Get the video ID\r\nStep 2: Create a Python object\r\nStep 3: Get the transcript\r\nStep 4 (optional): Paste together the transcript parts\r\nPutting Steps 1 through 4 into a function\r\n\r\nPractice Problems\r\nFurther Reading\r\n\r\nIn the webscraping tutorial, we harvested text directly from the HTML code of a webpage. This can be pretty laborious, so fortunately, some websites provide an easier path to collecting their data, called an Application Programming Interface (API). Generally, when an API is available, using it is the easiest and most polite way to harvest your text data. On this page, we’ll introduce ourselves to APIs by collecting bill text from the US Congress and video transcripts from YouTube.\r\nCongress API\r\nSuppose we wanted to collect the full text of bills introduced in the US Congress. As a running example, let’s try to load the text of “The Tax Cuts and Jobs Act” (HR 1, 115th Congress), which you can find here. Although we can access that page through our web browser, if I try to read the HTML in R…\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(rvest)\r\n\r\npage <- read_html(\"https://www.congress.gov/bill/115th-congress/house-bill/1/text\")\r\n\r\n\r\n\r\n…I get a foreboding “HTTP Error 403 - Forbidden” message. It turns out the US Federal Government does not take kindly to bots scraping their webpages.\r\nFortunately, the good people at congress.gov provide an API that we can use instead. An API endpoint is, in essence, a special web address that returns data instead of a webpage. For congress.gov, these web addresses all begin with https://api.congress.gov/v3/. But to access them, we’ll need an API key, a unique password that identifies each user. You can sign up for one at the top of the documentation page.\r\nOnce you have your API key, you will include it as part of the web address you use to access information. Per the API documentation, you can retrieve the text of bills with a web address in the following format:\r\nhttps://api.congress.gov/v3/bill/{congress}/{billType}/{billNumber}/text?api_key={INSERT_KEY}\r\nWherever you see curly braces {}, replace them with values for the bill you want. In our example, those values will be {congress} = 115, {billType} = hr, and {billNumber} = 1. Rather than accessing this web address through the browser, we will ask R to read the data from the API endpoint directly.\r\nStep 1: Keep Your API Key Safe\r\nYou will be tempted to copy-paste your API key directly into your R script. Avoid this temptation. It’s best practice to keep things like passwords and API keys saved in a separate location, not hard-coded into your scripts. That way, if you share your code (like I’m doing now), you don’t accidentally reveal your secrets. I’m keeping my API key in a text file called congress-api-key.txt. The first step is to read it into memory.\r\n\r\n\r\napi_key <- read_file('congress-api-key.txt')\r\n\r\n\r\nStep 2: Get the data from the API\r\nNext, we’ll use the glue package to format web addresses:\r\n\r\n\r\nlibrary(glue)\r\n\r\ncongress <- 115\r\nbillType <- 'hr'\r\nbillNumber <- 1\r\n\r\n# glue() uses curly braces when inserting variable names\r\nglue('/bill/{congress}/{billType}/{billNumber}/text')\r\n\r\n/bill/115/hr/1/text\r\n\r\nurl <- glue('https://api.congress.gov/v3/bill/{congress}/{billType}/{billNumber}/text?api_key={api_key}')\r\n\r\n\r\nOnce we’ve formatted the web address, we can use the httr package to get data from the API.\r\n\r\n\r\nlibrary(httr)\r\nd <- GET(url)\r\n\r\n\r\nStep 3: Convert to content from JSON to an R object\r\nThe object d is a JSON object. If you don’t know what a JSON object is, not to worry! We can just use the jsonlite package to convert it into an R object.\r\n\r\n\r\nlibrary(jsonlite)\r\n\r\n# take the content attribute from d\r\ncontent <- d$content |>\r\n  # convert from unicode to English characters\r\n  rawToChar() |>\r\n  # convert the JSON format to an R object\r\n  fromJSON()\r\n\r\n\r\nNow we have an R object (a list) called content. Sadly, this is not yet the content we want. The wrinkle here is that there are 8 versions of the text of this bill, beginning with the first version that was introduced in the House and ending with the final version that was signed into law. The content$textVersions object tells us where to find the full text of each version.\r\n\r\n\r\ncontent$textVersions\r\n\r\n                  date\r\n1                 <NA>\r\n2 2017-12-20T05:00:00Z\r\n3 2017-12-14T05:00:00Z\r\n4 2017-11-28T05:00:00Z\r\n5 2017-11-16T05:00:00Z\r\n6 2017-11-13T05:00:00Z\r\n7 2017-11-02T04:00:00Z\r\n8 2017-12-22T05:00:00Z\r\n                                                                                                                                                                                                                            formats\r\n1            Formatted Text, PDF, Formatted XML, https://www.congress.gov/115/bills/hr1/BILLS-115hr1enr.htm, https://www.congress.gov/115/bills/hr1/BILLS-115hr1enr.pdf, https://www.congress.gov/115/bills/hr1/BILLS-115hr1enr.xml\r\n2         Formatted Text, PDF, Formatted XML, https://www.congress.gov/115/bills/hr1/BILLS-115hr1eas2.htm, https://www.congress.gov/115/bills/hr1/BILLS-115hr1eas2.pdf, https://www.congress.gov/115/bills/hr1/BILLS-115hr1eas2.xml\r\n3            Formatted Text, PDF, Formatted XML, https://www.congress.gov/115/bills/hr1/BILLS-115hr1eas.htm, https://www.congress.gov/115/bills/hr1/BILLS-115hr1eas.pdf, https://www.congress.gov/115/bills/hr1/BILLS-115hr1eas.xml\r\n4            Formatted Text, PDF, Formatted XML, https://www.congress.gov/115/bills/hr1/BILLS-115hr1pcs.htm, https://www.congress.gov/115/bills/hr1/BILLS-115hr1pcs.pdf, https://www.congress.gov/115/bills/hr1/BILLS-115hr1pcs.xml\r\n5               Formatted Text, PDF, Formatted XML, https://www.congress.gov/115/bills/hr1/BILLS-115hr1eh.htm, https://www.congress.gov/115/bills/hr1/BILLS-115hr1eh.pdf, https://www.congress.gov/115/bills/hr1/BILLS-115hr1eh.xml\r\n6               Formatted Text, PDF, Formatted XML, https://www.congress.gov/115/bills/hr1/BILLS-115hr1rh.htm, https://www.congress.gov/115/bills/hr1/BILLS-115hr1rh.pdf, https://www.congress.gov/115/bills/hr1/BILLS-115hr1rh.xml\r\n7                                                                                         Formatted Text, PDF, https://www.congress.gov/115/bills/hr1/BILLS-115hr1ih.htm, https://www.congress.gov/115/bills/hr1/BILLS-115hr1ih.pdf\r\n8 Formatted Text, PDF, Formatted XML, https://www.congress.gov/115/plaws/publ97/PLAW-115publ97.htm, https://www.congress.gov/115/plaws/publ97/PLAW-115publ97.pdf, https://www.congress.gov/115/plaws/publ97/PLAW-115publ97_uslm.xml\r\n                        type\r\n1              Enrolled Bill\r\n2 Engrossed Amendment Senate\r\n3 Engrossed Amendment Senate\r\n4  Placed on Calendar Senate\r\n5         Engrossed in House\r\n6          Reported in House\r\n7        Introduced in House\r\n8                 Public Law\r\n\r\nStep 4: Get The Bill Text\r\nLet’s get the text for the latest version of the bill (the version that became law).\r\n\r\n\r\nmostRecent <- content$textVersions |> \r\n  # keep the row with the most recent date\r\n  slice_max(date, n = 1) |> \r\n  # pull the formats column\r\n  pull(formats)\r\n\r\nmostRecent\r\n\r\n[[1]]\r\n            type\r\n1 Formatted Text\r\n2            PDF\r\n3  Formatted XML\r\n                                                                url\r\n1      https://www.congress.gov/115/plaws/publ97/PLAW-115publ97.htm\r\n2      https://www.congress.gov/115/plaws/publ97/PLAW-115publ97.pdf\r\n3 https://www.congress.gov/115/plaws/publ97/PLAW-115publ97_uslm.xml\r\n\r\n# get the URL for the most recent Formatted Text\r\ntextURL <- mostRecent[[1]] |> \r\n  filter(type == 'Formatted Text') |> \r\n  pull(url)\r\n\r\n# read the text\r\ntext <- read_file(textURL)\r\n\r\n\r\nFinally! The object text contains the entire text of the bill. Printing this in its entirety would be too long, but here’s a snippet:\r\n\r\n\r\ntext |> \r\n  substr(1,1000) |> \r\n  cat()\r\n\r\n<html><body><pre>\r\n[115th Congress Public Law 97]\r\n[From the U.S. Government Publishing Office]\r\n\r\n\r\n\r\n[[Page 2053]]\r\n\r\n                                     \r\n\r\n                                     \r\n\r\n                                     \r\n\r\n                                     \r\n\r\n                                     \r\n\r\n    NOTE: Public Law 115-97 is re-printed to remove the editorial \r\ndescription contained on the original half title page of the printed \r\nSlip law.\r\n\r\n&lt;star&gt; (Star Print)\r\n\r\n[[Page 131 STAT. 2054]]\r\n\r\nPublic Law 115-97\r\n115th Congress\r\n\r\n                                 An Act\r\n\r\n\r\n \r\n    To provide for reconciliation pursuant to titles II and V of the \r\n concurrent resolution on the budget for fiscal year 2018. &lt;&lt;NOTE: Dec. \r\n                         22, 2017 -  [H.R. 1]&gt;&gt; \r\n\r\n    Be it enacted by the Senate and House of Representatives of the \r\nUnited States of America in Congress assembled,\r\n\r\n                                 TITLE I\r\n\r\nSECTION 11000. SHORT TITLE, ETC.\r\n\r\n    (a) Amend\r\n\r\nPutting Steps 1 through 4 into a function\r\nSteps 1 through 4 make up the entire workflow for retrieving the text of a bill from the congress.gov API. If we ever plan to use that workflow again, it would be wise to encode it as a function. That way we’re not copy-pasting large blocks of code every time we want to get the text of a new bill. Let’s create a new function called get_bill_text(). This function will take as inputs the congress, billType and billNumber of a bill, complete Steps 1-4, and return the full text of the bill we want.\r\n\r\n\r\nget_bill_text <- function(congress, billType, billNumber){\r\n  \r\n  # Step 1: Get the API Key\r\n  api_key <- read_file('congress-api-key.txt')\r\n  \r\n  # Step 2: Read the data from the API\r\n  url <- glue('https://api.congress.gov/v3/bill/{congress}/{billType}/{billNumber}/text?api_key={api_key}')\r\n  \r\n  d <- GET(url)\r\n  \r\n  # Step 3: Convert the JSON object to an R list\r\n  content <- d$content |>\r\n    rawToChar() |>\r\n    fromJSON()\r\n  \r\n  # Step 4: Get the most recent bill text\r\n  mostRecent <- content$textVersions |>\r\n    slice_max(date, n = 1) |>\r\n    pull(formats)\r\n\r\n  textURL <- mostRecent[[1]] |> \r\n    filter(type == 'Formatted Text') |> \r\n    pull(url)\r\n\r\n  text <- read_file(textURL)\r\n  \r\n  # Return the text object\r\n  return(text)\r\n}\r\n\r\n\r\nDoes the function work? If so, it should get the same text object we created before:\r\n\r\n\r\ntext == get_bill_text(congress = 115, billType = 'hr', billNumber = 1)\r\n\r\n[1] TRUE\r\n\r\nPlay with the function a bit, changing the inputs to make sure that it returns the correct text when you ask for a different bill. And see the practice problems at the end of the page to get more practice working with the congress.gov API.\r\nYouTube API\r\nIn this next tutorial, we’ll see how to retrieve YouTube video transcripts using its API and the youtube-transcript-api Python module. This Python module allows us to avoid all tedious the work we did formatting web addresses for the congress.gov API. We just need a way to run Python modules from R. Fortunately, the reticulate package does just that.\r\nHow to Drive Python from RStudio\r\nFor R users, the reticulate package is a convenient way to run Python code and return outputs as R objects. The setup will be a little bit different depending on whether you’re working with a PC or Mac.\r\nWindows PC Setup\r\nIf you’re on a Windows machine, first install the reticulate package through the R console, then install a version of Python, using the following two lines of code:\r\n\r\n\r\ninstall.packages('reticulate')\r\nreticulate::install_miniconda()\r\n\r\n\r\nMac Setup\r\nIf you are a Mac user, you should follow the instructions for Windows PCs above, but then you’re going to create a Python “virtual environment”, using the following command in the R console.\r\n\r\n\r\nreticulate::conda_create('myenv')\r\n\r\n\r\nNext, restart your R session. Then enter the following command to use the virtual environment you just created.\r\n\r\n\r\nreticulate::use_condaenv('myenv')\r\n\r\n\r\nInstall the Python package\r\nRegardless of your operating system, you’ll now want to install the youtube-transcript-api Python module, using the following function from reticulate.\r\n\r\n\r\nreticulate::py_install('youtube-transcript-api')\r\n\r\n\r\nSetup is done! Let’s play.\r\nStep 1: Get the video ID\r\nSuppose we want the transcript of this YouTube video:\r\n\r\n\r\n\r\n\r\nYou can click the CC button in the bottom right of the video to see YouTube’s auto-generated transcript. Note that the quality of these transcripts can vary significantly, depending on the quality of the audio.\r\nTo get the transcript using R, we’ll need the video ID, which you can find at the end of the video’s URL (the bolded text here):\r\nhttps://www.youtube.com/watch?v=mLyOj_QD4a4\r\nStep 2: Create a Python object\r\nNext, we’ll import the Python module, creating an object called youtubecaption.\r\n\r\n\r\nyoutubecaption <- reticulate::import('youtube_transcript_api')\r\n\r\n\r\nStep 3: Get the transcript\r\nWe can then use the Python module to get the transcript of the video we want.\r\n\r\n\r\nd <- youtubecaption$YouTubeTranscriptApi$get_transcript('mLyOj_QD4a4')\r\n\r\n\r\nNotice that the object d is a list object with 50 entries. Each element contains a snippet of text from the transcript, along with its timestamp and duration.\r\n\r\n\r\nd[[1]]\r\n\r\n$text\r\n[1] \"okay guys uh these eggs have given us a\"\r\n\r\n$start\r\n[1] 3.719\r\n\r\n$duration\r\n[1] 4.601\r\n\r\nd[[2]]\r\n\r\n$text\r\n[1] \"lot of trouble in the past uh does\"\r\n\r\n$start\r\n[1] 5.839\r\n\r\n$duration\r\n[1] 4.88\r\n\r\nStep 4 (optional): Paste together the transcript parts\r\nIf we would rather have the entire transcript in a single character object, we can loop through the list and paste all the text snippets together, like so:\r\n\r\n\r\n# start with an empty character object\r\ntranscript <- ''\r\n\r\n# for each element in the list, paste it onto the existing transcript\r\nfor(i in 1:length(d)){\r\n  transcript <- paste(transcript, d[[i]]$text)\r\n}\r\n\r\ntranscript\r\n\r\n[1] \" okay guys uh these eggs have given us a lot of trouble in the past uh does anybody need anything off this guy or can we bypass him uh I think Leroy needs something from this guy oh he he needs those devout shoulders doesn't isn't he a paladin yeah but that'll help him heal better I'll have more Mana Christ okay uh Well what we'll do I'll run in first uh gather up all the eggs so we can kind of just you know blast and all down with AOE um I will use intimidating shout to kind of scatter them so we don't have to fight a whole bunch of them at once uh when my shouts done uh I'll need Anthony to come in and drop his shout too uh so we can keep him scattered not to fight too many um when his is done bass of course we need to run in do the same thing uh we're going to need divine intervention on our Mages uh so they can uh AE uh so we can course get them down fast because we're bringing all these guys I mean we'll be in trouble if we don't take them down quick I think it's a pretty good plan we should be able to pull it off this time uh what do you think of du can you give me a number crunch real quick uh yeah give me a sec I'm coming up with 32 point 33 uh repeating of course percentage of survival oh that's a lot better than we usually do uh up let's do this lero dragons oh my God he just ran in save him oh jeez stick to the plane oh Jes let's go let's go stick to the plan stick to the plane oh gee oh give me div intervention hurry up saying I can't I can't move am I lagging up I can't move what the what the hell I can't oh my God egg spotting I don't think you can cast with that oh my God got we got I got it I got it down oh my God God damn it Leroy God damn it this this is ridiculous so M I'm down for down God damn on this God ohy res us do this I'm trying it's not my fault who's Soul Stone we do have a soul Stone up don't we oh god oh for great job Christ sake Leroy you are just stupid as hell at least I have chicken\"\r\n\r\nThe transcript object is now a single character object with the entire video transcript.\r\nPutting Steps 1 through 4 into a function\r\nAs in the last tutorial, it’s best practice to write a function any time you’ve created a multi-step workflow that you’d like to use more than once.\r\n\r\n\r\nget_youtube_transcript <- function(video_id, lang = 'en'){\r\n\r\n  # 1. create an object from the python package\r\n  youtubecaption <- reticulate::import('youtube_transcript_api')\r\n\r\n  # 2. get the transcript from the video you want\r\n  d <- youtubecaption$YouTubeTranscriptApi$get_transcript(video_id,\r\n                                                          languages = c(lang, 'en'))\r\n\r\n\r\n  # 3. paste together the transcript snippets\r\n  transcript <- ''\r\n  for(i in 1:length(d)){\r\n    transcript <- paste(transcript, d[[i]]$text)\r\n  }\r\n\r\n  return(transcript)\r\n}\r\n\r\n\r\nNotice that I’ve written this function with two inputs: the video ID and an option to create transcripts for videos in different languages. For a list of available language codes, see the ISO 639-1 column here.\r\nTo verify that the function works, let’s pull the transcript of the 2023 State of the Union Address.\r\n\r\n\r\nsotu_transcript <- get_youtube_transcript(video_id = 'gzcBTUvVp7M')\r\n\r\nsotu_transcript |> \r\n  substr(1, 1000) |> \r\n  cat()\r\n\r\n foreign Mr Speaker the president of the United States [Applause] thank you [Applause] foreign foreign [Applause] foreign foreign [Applause] [Applause] foreign [Applause] members of Congress I have the high privilege and the distinct honor to present to you the president of the United States Mr Speaker thank you you can smile it's okay thank you thank you thank you thank you please Mr Speaker Madam vice president our first lady and second gentleman good to see you guys up there members of Congress by the way chief justice I may need a court order she gets to go to the the game tomorrow next week I have to stay home got to work something out here members of the cabinet leaders of our military chief justice associate Justice and retired Justice Supreme Court and to you my fellow Americans you know I start tonight by congratulating 118th Congress and the new Speaker of the House Kevin McCarthy speaker I don't want to ruin your reputation but I look forward to working with you and I want t\r\n\r\nPractice Problems\r\nGet the full text of the Patient Protection and Affordable Care Act (2010).\r\nCreate a dataframe with information on several Congressional bills, including columns for congress, billType, billNumber, and full_text. Using the get_bill_text() function we created, collect the full text for at least 10 bills in this dataframe.\r\nCreate a function to get the Congressional Research Service’s summary of a bill from the congress.gov API. You’ll need to check the documentation to figure out how to format the URL for the correct API endpoint.\r\nThe sotu package is missing some of the most recent State of the Union addresses. See if you can collect their transcripts through YouTube. How is the quality of those transcripts?\r\nFurther Reading\r\nChristopher Kennedy’s congress package, which provides a tidy R interface to the congress.gov API.\r\nThe youtube-transcript-api module documentation\r\n\r\n\r\n\r\n",
      "last_modified": "2025-06-13T13:58:32-04:00"
    },
    {
      "path": "bag-of-words.html",
      "title": "The Bag of Words",
      "description": "What if we ignored everything we know about language and just counted the words? Would that get us anywhere?\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nStep 1: Choose a Unit of Analysis\r\nStep 2: Tokenize\r\nStep 3: Reduce Complexity\r\nStep 4: Create the Document-Feature Matrix\r\nPractice Problems\r\n\r\nWhenever we analyze a text as data, the first step after digitizing is to decide how we’re going to represent the text quantitatively. The most straightforward such representation is the so-called “bag of words”. We ignore word order, syntax, punctuation, meaning, and context, focusing only on the frequency with which words appear in the text. Though this representation throws out a lot of detail, it can nevertheless be useful, depending on what you’re trying to accomplish.\r\nIn Chapter 5, Grimmer, Stewart, and Roberts (2021) present their “standard recipe” for representing a text corpus as a bag of words:\r\nChoose a unit of analysis\r\nTokenize\r\nReduce complexity\r\nCreate a document-feature matrix\r\nLet’s demonstrate this workflow using the State of the Union speeches application from Chapter 5. Our objective is to describe what words presidents use when discussing the topic of manufacturing.\r\nStep 1: Choose a Unit of Analysis\r\nThe unit of analysis (or “document”) for this application is the sentence. We want to just look at the sentences that include a mention of manufacturing, ignoring the rest of the speeches. To do so, let’s load in the sotu dataset and use the excellent unnest_tokens() function from the tidytext package to split the corpus into sentences.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(tidytext)\r\n\r\n# load the data from the sotu package\r\ndf <- sotu::sotu_meta |> \r\n  mutate(text = sotu::sotu_text,\r\n         speech_id = 1:length(sotu::sotu_text)) |> \r\n  select(speech_id, president, year, text)\r\n\r\nhead(df)\r\n\r\n  speech_id         president year\r\n1         1 George Washington 1790\r\n2         2 George Washington 1790\r\n3         3 George Washington 1791\r\n4         4 George Washington 1792\r\n5         5 George Washington 1793\r\n6         6 George Washington 1794\r\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text\r\n1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Fellow-Citizens of the Senate and House of Representatives: \\n\\nI embrace with great satisfaction the opportunity which now presents itself of congratulating you on the present favorable prospects of our public affairs. The recent accession of the important state of North Carolina to the Constitution of the United States (of which official information has been received), the rising credit and respectability of our country, the general and increasing good will toward the government of the Union, and the concord, peace, and plenty with which we are blessed are circumstances auspicious in an eminent degree to our national prosperity.\\n\\nIn resuming your consultations for the general good you can not but derive encouragement from the reflection that the measures of the last session have been as satisfactory to your constituents as the novelty and difficulty of the work allowed you to hope. Still further to realize their expectations and to secure the blessings which a gracious Providence has placed within our reach will in the course of the present important session call for the cool and deliberate exertion of your patriotism, firmness, and wisdom.\\n\\nAmong the many interesting objects which will engage your attention that of providing for the common defense will merit particular regard. To be prepared for war is one of the most effectual means of preserving peace.\\n\\nA free people ought not only to be armed, but disciplined; to which end a uniform and well-digested plan is requisite; and their safety and interest require that they should promote such manufactories as tend to render them independent of others for essential, particularly military, supplies.\\n\\nThe proper establishment of the troops which may be deemed indispensable will be entitled to mature consideration. In the arrangements which may be made respecting it it will be of importance to conciliate the comfortable support of the officers and soldiers with a due regard to economy.\\n\\nThere was reason to hope that the pacific measures adopted with regard to certain hostile tribes of Indians would have relieved the inhabitants of our southern and western frontiers from their depredations, but you will perceive from the information contained in the papers which I shall direct to be laid before you (comprehending a communication from the Commonwealth of Virginia) that we ought to be prepared to afford protection to those parts of the Union, and, if necessary, to punish aggressors.\\n\\nThe interests of the United States require that our intercourse with other nations should be facilitated by such provisions as will enable me to fulfill my duty in that respect in the manner which circumstances may render most conducive to the public good, and to this end that the compensation to be made to the persons who may be employed should, according to the nature of their appointments, be defined by law, and a competent fund designated for defraying the expenses incident to the conduct of foreign affairs.\\n\\nVarious considerations also render it expedient that the terms on which foreigners may be admitted to the rights of citizens should be speedily ascertained by a uniform rule of naturalization.\\n\\nUniformity in the currency, weights, and measures of the United States is an object of great importance, and will, I am persuaded, be duly attended to.\\n\\nThe advancement of agriculture, commerce, and manufactures by all proper means will not, I trust, need recommendation; but I can not forbear intimating to you the expediency of giving effectual encouragement as well to the introduction of new and useful inventions from abroad as to the exertions of skill and genius in producing them at home, and of facilitating the intercourse between the distant parts of our country by a due attention to the post-office and post-roads.\\n\\nNor am I less persuaded that you will agree with me in opinion that there is nothing which can better deserve your patronage than the promotion of science and literature. Knowledge is in every country the surest basis of public happiness. In one in which the measures of government receive their impressions so immediately from the sense of the community as in ours it is proportionably essential.\\n\\nTo the security of a free constitution it contributes in various ways - by convincing those who are intrusted with the public administration that every valuable end of government is best answered by the enlightened confidence of the people, and by teaching the people themselves to know and to value their own rights; to discern and provide against invasions of them; to distinguish between oppression and the necessary exercise of lawful authority; between burthens proceeding from a disregard to their convenience and those resulting from the inevitable exigencies of society; to discriminate the spirit of liberty from that of licentiousness - cherishing the first, avoiding the last - and uniting a speedy but temperate vigilance against encroachments, with an inviolable respect to the laws.\\n\\nWhether this desirable object will be best promoted by affording aids to seminaries of learning already established, by the institution of a national university, or by any other expedients will be well worthy of a place in the deliberations of the legislature.\\n\\nGentlemen of the House of Representatives: \\n\\nI saw with peculiar pleasure at the close of the last session the resolution entered into by you expressive of your opinion that an adequate provision for the support of the public credit is a matter of high importance to the national honor and prosperity. In this sentiment I entirely concur; and to a perfect confidence in your best endeavors to devise such a provision as will be truly with the end I add an equal reliance on the cheerful cooperation of the other branch of the legislature.\\n\\nIt would be superfluous to specify inducements to a measure in which the character and interests of the United States are so obviously so deeply concerned, and which has received so explicit a sanction from your declaration. \\n\\nGentlemen of the Senate and House of Representatives: \\n\\nI have directed the proper officers to lay before you, respectively, such papers and estimates as regard the affairs particularly recommended to your consideration, and necessary to convey to you that information of the state of the Union which it is my duty to afford.\\n\\nThe welfare of our country is the great object to which our cares and efforts ought to be directed, and I shall derive great satisfaction from a cooperation with you in the pleasing though arduous task of insuring to our fellow citizens the blessings which they have a right to expect from a free, efficient, and equal government. GEORGE WASHINGTON\\n\r\n2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \\n\\n Fellow-Citizens of the Senate and House of Representatives: \\n\\nIn meeting you again I feel much satisfaction in being able to repeat my congratulations on the favorable prospects which continue to distinguish our public affairs. The abundant fruits of another year have blessed our country with plenty and with the means of a flourishing commerce.\\n\\nThe progress of public credit is witnessed by a considerable rise of American stock abroad as well as at home, and the revenues allotted for this and other national purposes have been productive beyond the calculations by which they were regulated. This latter circumstance is the more pleasing, as it is not only a proof of the fertility of our resources, but as it assures us of a further increase of the national respectability and credit, and, let me add, as it bears an honorable testimony to the patriotism and integrity of the mercantile and marine part of our citizens. The punctuality of the former in discharging their engagements has been exemplary.\\n\\nIn conformity to the powers vested in me by acts of the last session, a loan of 3,000,000 florins, toward which some provisional measures had previously taken place, has been completed in Holland. As well the celerity with which it has been filled as the nature of the terms (considering the more than ordinary demand for borrowing created by the situation of Europe) give a reasonable hope that the further execution of those powers may proceed with advantage and success. The Secretary of the Treasury has my directions to communicate such further particulars as may be requisite for more precise information.\\n\\nSince your last sessions I have received communications by which it appears that the district of Kentucky, at present a part of Virginia, has concurred in certain propositions contained in a law of that State, in consequence of which the district is to become a distinct member of the Union, in case the requisite sanction of Congress be added. For this sanction application is now made. I shall cause the papers on this very transaction to be laid before you.\\n\\nThe liberality and harmony with which it has been conducted will be found to do great honor to both the parties, and the sentiments of warm attachment to the Union and its present Government expressed by our fellow citizens of Kentucky can not fail to add an affectionate concern for their particular welfare to the great national impressions under which you will decide on the case submitted to you.\\n\\nIt has been heretofore known to Congress that frequent incursion have been made on our frontier settlements by certain banditti of Indians from the northwest side of the Ohio. These, with some of the tribes dwelling on and near the Wabash, have of late been particularly active in their depredations, and being emboldened by the impunity of their crimes and aided by such parts of the neighboring tribes as could be seduced to join in their hostilities or afford them a retreat for their prisoners and plunder, they have, instead of listening to the humane invitations and overtures made on the part of the United States, renewed their violences with fresh alacrity and greater effect. The lives of a number of valuable citizens have thus been sacrificed, and some of them under circumstances peculiarly shocking, whilst others have been carried into a deplorable captivity.\\n\\nThese aggravated provocations rendered it essential to the safety of the Western settlements that the aggressors should be made sensible that the Government of the Union is not less capable of punishing their crimes than it is disposed to respect their rights and reward their attachments. As this object could not be effected by defensive measures, it became necessary to put in force the act which empowers the President to call out the militia for the protection of the frontiers, and I have accordingly authorized an expedition in which the regular troops in that quarter are combined with such drafts of militia as were deemed sufficient. The event of the measure is yet unknown to me. The Secretary of War is directed to lay before you a statement of the information on which it is founded, as well as an estimate of the expense with which it will be attended.\\n\\nThe disturbed situation of Europe, and particularly the critical posture of the great maritime powers, whilst it ought to make us the more thankful for the general peace and security enjoyed by the United States, reminds us at the same time of the circumspection with which it becomes us to preserve these blessings. It requires also that we should not overlook the tendency of a war, and even of preparations for a war, among the nations most concerned in active commerce with this country to abridge the means, and thereby at least enhance the price, of transporting its valuable productions to their markets. I recommend it to your serious reflections how far and in what mode it may be expedient to guard against embarrassments from these contingencies by such encouragements to our own navigation as will render our commerce and agriculture less dependent on foreign bottoms, which may fail us in the very moments most interesting to both of these great objects. Our fisheries and the transportation of our own produce offer us abundant means for guarding ourselves against this evil.\\n\\nYour attention seems to be not less due to that particular branch of our trade which belongs to the Mediterranean. So many circumstances unite in rendering the present state of it distressful to us that you will not think any deliberations misemployed which may lead to its relief and protection.\\n\\nThe laws you have already passed for the establishment of a judiciary system have opened the doors of justice to all descriptions of persons. You will consider in your wisdom whether improvements in that system may yet be made, and particularly whether an uniform process of execution on sentences issuing from the Federal courts be not desirable through all the States.\\n\\nThe patronage of our commerce, of our merchants and sea men, has called for the appointment of consuls in foreign countries. It seems expedient to regulate by law the exercise of that jurisdiction and those functions which are permitted them, either by express convention or by a friendly indulgence, in the places of their residence. The consular convention, too, with His Most Christian Majesty has stipulated in certain cases the aid of the national authority to his consuls established here. Some legislative provision is requisite to carry these stipulations into full effect.\\n\\nThe establishment of the militia, of a mint, of standards of weights and measures, of the post office and post roads are subjects which I presume you will resume of course, and which are abundantly urged by their own importance.\\n\\n Gentlemen of the House of Representatives: \\n\\nThe sufficiency of the revenues you have established for the objects to which they are appropriated leaves no doubt that the residuary provisions will be commensurate to the other objects for which the public faith stands now pledged. Allow me, moreover, to hope that it will be a favorite policy with you, not merely to secure a payment of the interest of the debt funded, but as far and as fast as the growing resources of the country will permit to exonerate it of the principal itself. The appropriation you have made of the Western land explains your dispositions on this subject, and I am persuaded that the sooner that valuable fund can be made to contribute, along with the other means, to the actual reduction of the public debt the more salutary will the measure be to every public interest, as well as the more satisfactory to our constituents.\\n\\n Gentlemen of the Senate and House of Representatives: \\n\\nin pursuing the various and weighty business of the present session I indulge the fullest persuasion that your consultation will be equally marked with wisdom and animated by the love of your country. In whatever belongs to my duty you shall have all the cooperation which an undiminished zeal for its welfare can inspire. It will be happy for us both, and our best reward, if, by a successful administration of our respective trusts, we can make the established Government more and more instrumental in promoting the good of our fellow citizens, and more and more the object of their attachment and confidence. GO. WASHINGTON\\n\r\n3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \\n\\n Fellow-Citizens of the Senate and House of Representatives: \\n\\n \"In vain may we expect peace with the Indians on our frontiers so long as a lawless set of unprincipled wretches can violate the rights of hospitality, or infringe the most solemn treaties, without receiving the punishment they so justly merit.\" \\n\\nI meet you upon the present occasion with the feelings which are naturally inspired by a strong impression of the prosperous situations of our common country, and by a persuasion equally strong that the labors of the session which has just commenced will, under the guidance of a spirit no less prudent than patriotic, issue in measures conducive to the stability and increase of national prosperity.\\n\\nNumerous as are the providential blessings which demand our grateful acknowledgments, the abundance with which another year has again rewarded the industry of the husbandman is too important to escape recollection.\\n\\nYour own observations in your respective situations will have satisfied you of the progressive state of agriculture, manufactures, commerce, and navigation. In tracing their causes you will have remarked with particular pleasure the happy effects of that revival of confidence, public as well as private, to which the Constitution and laws of the United States have so eminently contributed; and you will have observed with no less interest new and decisive proofs of the increasing reputation and credit of the nation. But you nevertheless can not fail to derive satisfaction from the confirmation of these circumstances which will be disclosed in the several official communications that will be made to you in the course of your deliberations.\\n\\nThe rapid subscriptions to the Bank of the United States, which completed the sum allowed to be subscribed in a single day, is among the striking and pleasing evidences which present themselves, not only of confidence in the Government, but of resource in the community.\\n\\nIn the interval of your recess due attention has been paid to the execution of the different objects which were specially provided for by the laws and resolutions of the last session.\\n\\nAmong the most important of these is the defense and security of the western frontiers. To accomplish it on the most humane principles was a primary wish.\\n\\nAccordingly, at the same time the treaties have been provisionally concluded and other proper means used to attach the wavering and to confirm in their friendship the well-disposed tribes of Indians, effectual measures have been adopted to make those of a hostile description sensible that a pacification was desired upon terms of moderation and justice.\\n\\nThose measures having proved unsuccessful, it became necessary to convince the refractory of the power of the United States to punish their depredations. Offensive operations have therefore been directed, to be conducted, however, as consistently as possible with the dictates of humanity.\\n\\nSome of these have been crowned with full success and others are yet depending. The expeditions which have been completed were carried on under the authority and at the expense of the United States by the militia of Kentucky, whose enterprise, intrepidity, and good conduct are entitled of peculiar commendation.\\n\\nOvertures of peace are still continued to the deluded tribes, and considerable numbers of individuals belonging to them have lately renounced all further opposition, removed from their former situations, and placed themselves under the immediate protection of the United States.\\n\\nIt is sincerely to be desired that all need of coercion in future may cease and that an intimate intercourse may succeed, calculated to advance the happiness of the Indians and to attach them firmly to the United States.\\n\\nIn order to this it seems necessary -  That they should experience the benefits of an impartial dispensation of justice.  That the mode of alienating their lands, the main source of discontent and war, should be so defined and regulated as to obviate imposition and as far as may be practicable controversy concerning the reality and extent of the alienations which are made.  That commerce with them should be promoted under regulations tending to secure an equitable deportment toward them, and that such rational experiments should be made for imparting to them the blessings of civilization as may from time to time suit their condition.  That the Executive of the United States should be enabled to employ the means to which the Indians have been long accustomed for uniting their immediate interests with the preservation of peace.  And that efficacious provision should be made for inflicting adequate penalties upon all those who, by violating their rights, shall infringe the treaties and endanger the peace of the Union.  A system corresponding with the mild principles of religion and philanthropy toward an unenlightened race of men, whose happiness materially depends on the conduct of the United States, would be as honorable to the national character as conformable to the dictates of sound policy.\\n\\nThe powers specially vested in me by the act laying certain duties on distilled spirits, which respect the subdivisions of the districts into surveys, the appointment of officers, and the assignment of compensations, have likewise carried into effect. In a manner in which both materials and experience were wanting to guide the calculation it will be readily conceived that there must have been difficulty in such an adjustment of the rates of compensation as would conciliate a reasonable competency with a proper regard to the limits prescribed by the law. It is hoped that the circumspection which has been used will be found in the result to have secured that last two objects; but it is probable that with a view to the first in some instances a revision of the provision will be found advisable.\\n\\nThe impressions with which this law has been received by the community have been upon the whole such as were to be expected among enlightened and well-disposed citizens from the propriety and necessity of the measure. The novelty, however, of the tax in a considerable part of the United States and a misconception of some of its provisions have given occasion in particular places to some degree of discontent; but it is satisfactory to know that this disposition yields to proper explanations and more just apprehensions of the true nature of the law, and I entertain a full confidence that it will in all give way to motives which arise out of a just sense of duty and a virtuous regard to the public welfare.\\n\\nIf there are any circumstances in the law which consistently with its main design may be so varied as to remove any well-intentioned objections that may happen to exist, it will consist with a wise moderation to make the proper variations. It is desirable on all occasions to unite with a steady and firm adherence to constitutional and necessary acts of Government the fullest evidence of a disposition as far as may be practicable to consult the wishes of every part of the community and to lay the foundations of the public administration in the affections of the people.\\n\\nPursuant to the authority contained in the several acts on that subject, a district of 10 miles square for the permanent seat of the Government of the United State has been fixed and announced by proclamation, which district will comprehend lands on both sides of the river Potomac and the towns of Alexandria and Georgetown. A city has also been laid out agreeably to a plan which will be placed before Congress, and as there is a prospect, favored by the rate of sales which have already taken place, of ample funds for carrying on the necessary public buildings, there is every expectation of their due progress.\\n\\nThe completion of the census of the inhabitants, for which provision was made by law, has been duly notified (excepting one instance in which the return has been informal, and another in which it has been omitted or miscarried), and the returns of the officers who were charged with this duty, which will be laid before you, will give you the pleasing assurance that the present population of the United States borders on 4,000,000 persons.\\n\\nIt is proper also to inform you that a further loan of 2,500,000 florins has been completed in Holland, the terms of which are similar to those of the one last announced, except as to a small reduction of charges. Another, on like terms, for 6,000,000 florins, had been set on foot under circumstances that assured an immediate completion.\\n\\n Gentlemen of the Senate: \\n\\nTwo treaties which have been provisionally concluded with the Cherokees and Six Nations of Indians will be laid before you for your consideration and ratification.\\n\\n Gentlemen of the House of Representatives: \\n\\nIn entering upon the discharge of your legislative trust you must anticipate with pleasure that many of the difficulties necessarily incident to the first arrangements of a new government for an extensive country have been happily surmounted by the zealous and judicious exertions of your predecessors in cooperation with the other branch of the Legislature. The important objects which remain to be accomplished will, I am persuaded, be conducted upon principles equally comprehensive and equally well calculated of the advancement of the general weal.\\n\\nThe time limited for receiving subscriptions to the loans proposed by the act making provision for the debt of the United States having expired, statements from the proper department will as soon as possible apprise you of the exact result. Enough, however, is known already to afford an assurance that the views of that act have been substantially fulfilled. The subscription in the domestic debt of the United States has embraced by far the greatest proportion of that debt, affording at the same time proof of the general satisfaction of the public creditors with the system which has been proposed to their acceptance and of the spirit of accommodation to the convenience of the Government with which they are actuated. The subscriptions in the debts of the respective States as far as the provisions of the law have permitted may be said to be yet more general. The part of the debt of the United States which remains unsubscribed will naturally engage your further deliberations.\\n\\nIt is particularly pleasing to me to be able to announce to you that the revenues which have been established promise to be adequate to their objects, and may be permitted, if no unforeseen exigency occurs, to supersede for the present the necessity of any new burthens upon our constituents.\\n\\nAn object which will claim your early attention is a provision for the current service of the ensuing year, together with such ascertained demands upon the Treasury as require to be immediately discharged, and such casualties as may have arisen in the execution of the public business, for which no specific appropriation may have yet been made; of all which a proper estimate will be laid before you.\\n\\n Gentlemen of the Senate and of the House of Representatives: \\n\\nI shall content myself with a general reference to former communications for several objects upon which the urgency of other affairs has hitherto postponed any definitive resolution. Their importance will recall them to your attention, and I trust that the progress already made in the most arduous arrangements of the Government will afford you leisure to resume them to advantage.\\n\\nThese are, however, some of them of which I can not forbear a more particular mention. These are the militia, the post office and post roads, the mint, weights and measures, a provision for the sale of the vacant lands of the United States.\\n\\nThe first is certainly an object of primary importance whether viewed in reference to the national security to the satisfaction of the community or to the preservation of order. In connection with this the establishment of competent magazines and arsenals and the fortification of such places as are peculiarly important and vulnerable naturally present themselves to consideration. The safety of the United States under divine protection ought to rest on the basis of systematic and solid arrangements, exposed as little as possible to the hazards of fortuitous circumstances.\\n\\nThe importance of the post office and post roads on a plan sufficiently liberal and comprehensive, as they respect the expedition, safety, and facility of communication, is increased by their instrumentality in diffusing a knowledge of the laws and proceedings of the Government, which, while it contributes to the security of the people, serves also to guard them against the effects of misrepresentation and misconception. The establishment of additional cross posts, especially to some of the important points in the Western and Northern parts of the Union, can not fail to be of material utility.\\n\\nThe disorders in the existing currency, and especially the scarcity of small change, a scarcity so peculiarly distressing to the poorer classes, strongly recommend the carrying into immediate effect the resolution already entered into concerning the establishment of a mint. Measures have been taken pursuant to that resolution for procuring some of the most necessary artists, together with the requisite apparatus.\\n\\nAn uniformity in the weights and measures of the country is among the important objects submitted to you by the Constitution, and if it can be derived from a standard at once invariable and universal, must be no less honorable to the public councils than conducive to the public convenience.\\n\\nA provision for the sale of the vacant lands of the United States is particularly urged, among other reasons, by the important considerations that they are pledged as a fund for reimbursing the public debt; that if timely and judiciously applied they may save the necessity of burthening our citizens with new taxes for the extinguishment of the principal; and that being free to discharge the principal but in a limited proportion, no opportunity ought to be lost for availing the public of its right. GO. WASHINGTON\\n\r\n4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Fellow-Citizens of the Senate and House of Representatives: \\n\\nIt is some abatement of the satisfaction with which I meet you on the present occasion that, in felicitating you on a continuance of the national prosperity generally, I am not able to add to it information that the Indian hostilities which have for some time past distressed our Northwestern frontier have terminated.\\n\\nYou will, I am persuaded, learn with no less concern than I communicate it that reiterated endeavors toward effecting a pacification have hitherto issued only in new and outrageous proofs of persevering hostility on the part of the tribes with whom we are in contest. An earnest desire to procure tranquillity to the frontier, to stop the further effusion of blood, to arrest the progress of expense, to forward the prevalent wish of the nation for peace has led to strenuous efforts through various channels to accomplish these desirable purposes; in making which efforts I consulted less my own anticipations of the event, or the scruples which some considerations were calculated to inspire, than the wish to find the object attainable, or if not attainable, to ascertain unequivocally that such is the case.\\n\\nA detail of the measures which have been pursued and of their consequences, which will be laid before you, while it will confirm to you the want of success thus far, will, I trust, evince that means as proper and as efficacious as could have been devised have been employed. The issue of some of them, indeed, is still depending, but a favorable one, though not to be despaired of, is not promised by anything that has yet happened.\\n\\nIn the course of the attempts which have been made some valuable citizens have fallen victims to their zeal for the public service. A sanction commonly respected even among savages has been found in this instance insufficient to protect from massacre the emissaries of peace. It will, I presume, be duly considered whether the occasion does not call for an exercise of liberality toward the families of the deceased.\\n\\nIt must add to your concern to be informed that, besides the continuation of hostile appearances among the tribes north of the Ohio, some threatening symptoms have of late been revived among some of those south of it.\\n\\nA part of the Cherokees, known by the name of Chickamaugas, inhabiting five villages on the Tennessee River, have long been in the practice of committing depredations on the neighboring settlements.\\n\\nIt was hoped that the treaty of Holston, made with the Cherokee Nation in July, 1791, would have prevented a repetition of such depredations; but the event has not answered this hope. The Chickamaugas, aided by some banditti of another tribe in their vicinity, have recently perpetrated wanton and unprovoked hostilities upon the citizens of the United States in that quarter. The information which has been received on this subject will be laid before you. Hitherto defensive precautions only have been strictly enjoined and observed.\\n\\nIt is not understood that any breach of treaty or aggression whatsoever on the part of the United States or their citizens is even alleged as a pretext for the spirit of hostility in this quarter.\\n\\nI have reason to believe that every practicable exertion has been made (pursuant to the provision by law for that purpose) to be prepared for the alternative of a prosecution of the war in the event of a failure of pacific overtures. A large proportion of the troops authorized to be raised have been recruited, though the number is still incomplete, and pains have been taken to discipline and put them in condition for the particular kind of service to be performed. A delay of operations (besides being dictated by the measures which were pursuing toward a pacific termination of the war) has been in itself deemed preferable to immature efforts. A statement from the proper department with regard to the number of troops raised, and some other points which have been suggested, will afford more precise information as a guide to the legislative consultations, and among other things will enable Congress to judge whether some additional stimulus to the recruiting service may not be advisable.\\n\\nIn looking forward to the future expense of the operations which may be found inevitable I derive consolation from the information I receive that the product of the revenues for the present year is likely to supersede the necessity of additional burthens on the community for the service of the ensuing year. This, however, will be better ascertained in the course of the session, and it is proper to add that the information alluded to proceeds upon the supposition of no material extension of the spirit of hostility.\\n\\nI can not dismiss the subject of Indian affairs without again recommending to your consideration the expediency of more adequate provision for giving energy to the laws throughout our interior frontier and for restraining the commission of outrages upon the Indians, without which all pacific plans must prove nugatory. To enable, by competent rewards, the employment of qualified and trusty persons to reside among them as agents would also contribute to the preservation of peace and good neighborhood. If in addition to these expedients an eligible plan could be devised for promoting civilization among the friendly tribes and for carrying on trade with them upon a scale equal to their wants and under regulations calculated to protect them from imposition and extortion, its influence in cementing their interest with ours could not but be considerable.\\n\\nThe prosperous state of our revenue has been intimated. This would be still more the case were it not for the impediments which in some places continue to embarrass the collection of the duties on spirits distilled within the United States. These impediments have lessened and are lessening in local extent, and, as applied to the community at large, the contentment with the law appears to be progressive.\\n\\nBut symptoms of increased opposition having lately manifested themselves in certain quarters, I judged a special interposition on my part proper and advisable, and under this impression have issued a proclamation warning against all unlawful combinations and proceedings having for their object or tending to obstruct the operation of the law in question, and announcing that all lawful ways and means would be strictly put in execution for bringing to justice the infractors thereof and securing obedience thereto.\\n\\nMeasures have also been taken for the prosecution of offenders, and Congress may be assured that nothing within constitutional and legal limits which may depend upon me shall be wanting to assert and maintain the just authority of the laws. In fulfilling this trust I shall count entirely upon the full cooperation of the other departments of the Government and upon the zealous support of all good citizens.\\n\\nI can not forbear to bring again into the view of the Legislature the subject of a revision of the judiciary system. A representation from the judges of the Supreme Court, which will be laid before you, points out some of the inconveniences that are experienced. In the course of the execution of the laws considerations arise out of the structure of the system which in some cases tend to relax their efficacy. As connected with this subject, provisions to facilitate the taking of bail upon processes out of the courts of the United States and a supplementary definition of offenses against the Constitution and laws of the Union and of the punishment for such offenses will, it is presumed, be found worthy of particular attention.\\n\\nObservations on the value of peace with other nations are unnecessary. It would be wise, however, by timely provisions to guard against those acts of our own citizens which might tend to disturb it, and to put ourselves in a condition to give that satisfaction to foreign nations which we may sometimes have occasion to require from them. I particularly recommend to your consideration the means of preventing those aggressions by our citizens on the territory of other nations, and other infractions of the law of nations, which, furnishing just subject of complaint, might endanger our peace with them; and, in general, the maintenance of a friendly intercourse with foreign powers will be presented to your attention by the expiration of the law for that purpose, which takes place, if not renewed, at the close of the present session.\\n\\nIn execution of the authority given by the Legislature measures have been taken for engaging some artists from abroad to aid in the establishment of our mint. Others have been employed at home. Provision has been made of the requisite buildings, and these are now putting into proper condition for the purposes of the establishment. There has also been a small beginning in the coinage of half dimes, the want of small coins in circulation calling the first attention to them.\\n\\nThe regulation of foreign coins in correspondency with the principles of our national coinage, as being essential to their due operation and to order in our money concerns, will, I doubt not, be resumed and completed.\\n\\nIt is represented that some provisions in the law which establishes the post office operate, in experiment, against the transmission of news papers to distant parts of the country. Should this, upon due inquiry, be found to be the fact, a full conviction of the importance of facilitating the circulation of political intelligence and information will, I doubt not, lead to the application of a remedy.\\n\\nThe adoption of a constitution for the State of Kentucky has been notified to me. The Legislature will share with me in the satisfaction which arises from an event interesting to the happiness of the part of the nation to which it relates and conducive to the general order.\\n\\nIt is proper likewise to inform you that since my last communication on the subject, and in further execution of the acts severally making provision for the public debt and for the reduction thereof, three new loans have been effected, each for 3,000,000 florins - one at Antwerp, at the annual interest of 4.5%, with an allowance of 4% in lieu of all charges, in the other 2 at Amsterdam, at the annual interest of 4%, with an allowance of 5.5% in one case and of 5% in the other in lieu of all charges. The rates of these loans and the circumstances under which they have been made are confirmations of the high state of our credit abroad.\\n\\nAmong the objects to which these funds have been directed to be applied, the payment of the debts due to certain foreign officers, according to the provision made during the last session, has been embraced.\\n\\n Gentlemen of the House of Representatives: \\n\\nI entertain a strong hope that the state of the national finances is now sufficiently matured to enable you to enter upon a systematic and effectual arrangement for the regular redemption and discharge of the public debt, according to the right which has been reserved to the Government. No measure can be more desirable, whether viewed with an eye to its intrinsic importance or to the general sentiment and wish of the nation.\\n\\nProvision is likewise requisite for the reimbursement of the loan which has been made of the Bank of the United States, pursuant to the eleventh section of the act by which it is incorporated. In fulfilling the public stipulations in this particular it is expected a valuable saving will be made.\\n\\nAppropriations for the current service of the ensuing year and for such extraordinaries as may require provision will demand, and I doubt not will engage, your early attention.\\n\\n Gentlemen of the Senate and of the House of Representatives: \\n\\nI content myself with recalling your attention generally to such objects, not particularized in my present, as have been suggested in my former communications to you.\\n\\nVarious temporary laws will expire during the present session. Among these, that which regulates trade and intercourse with the Indian tribes will merit particular notice.\\n\\nThe results of your common deliberations hitherto will, I trust, be productive of solid and durable advantages to our constituents, such as, by conciliating more and more their ultimate suffrage, will tend to strengthen and confirm their attachment to that Constitution of Government upon which, under Divine Providence, materially depend their union, their safety, and their happiness.\\n\\nStill further to promote and secure these inestimable ends there is nothing which can have a more powerful tendency than the careful cultivation of harmony, combined with a due regard to stability, in the public councils. GO. WASHINGTON\\n\r\n5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               \\n\\n Fellow-Citizens of the Senate and House of Representatives: \\n\\nSince the commencement of the term for which I have been again called into office no fit occasion has arisen for expressing to me fellow citizens at large the deep and respectful sense which I feel of the renewed testimony of public approbation. While on the one hand it awakened my gratitude for all those instances of affectionate partiality with which I have been honored by my country, on the other it could not prevent an earnest wish for that retirement from which no private consideration should ever have torn me. But influenced by the belief that my conduct would be estimated according to its real motives, and that the people, and the authorities derived from them, would support exertions having nothing personal for their object, I have obeyed the suffrage which commanded me to resume the Executive power; and I humbly implore that Being on whose will the fate of nations depends to crown with success our mutual endeavors for the general happiness.\\n\\nAs soon as the war in Europe had embraced those powers with whom the United States have the most extensive relations there was reason to apprehend that our intercourse with them might be interrupted and our disposition for peace drawn into question by the suspicions too often entertained by belligerent nations. It seemed, therefore, to be my duty to admonish our citizens of the consequences of a contraband trade and of hostile acts to any of the parties, and to obtain by a declaration of the existing legal state of things an easier admission of our right to the immunities belonging to our situation. Under these impressions the proclamation which will be laid before you was issued.\\n\\nIn this posture of affairs, both new and delicate, I resolved to adopt general rules which should conform to the treaties and assert the privileges of the United States. These were reduced into a system, which will be communicated to you. Although I have not thought of myself at liberty to forbid the sale of the prizes permitted by our treaty of commerce with France to be brought into our ports, I have not refused to cause them to be restored when they were taken within the protection of our territory, or by vessels commissioned or equipped in a warlike form within the limits of the United States.\\n\\nIt rests with the wisdom of Congress to correct, improve, or enforce this plan of procedure; and it will probably be found expedient to extend the legal code and the jurisdiction of the courts of the United States to many cases which, though dependent on principles already recognized, demand some further provisions.\\n\\nWhere individuals shall, within the United States, array themselves in hostility against any of the powers at war, or enter upon military expeditions or enterprises within the jurisdiction of the United States, or usurp and exercise judicial authority within the United States, or where the penalties on violations of the law of nations may have been indistinctly marked, or are inadequate - these offenses can not receive too early and close an attention, and require prompt and decisive remedies.\\n\\nWhatsoever those remedies may be, they will be well administered by the judiciary, who possess a long-established course of investigation, effectual process, and officers in the habit of executing it.\\n\\nIn like manner, as several of the courts have doubted, under particular circumstances, their power to liberate the vessels of a nation at peace, and even of a citizen of the United States, although seized under a false color of being hostile property, and have denied their power to liberate certain captures within the protection of our territory, it would seem proper to regulate their jurisdiction in these points. But if the Executive is to be the resort in either of the two last-mentioned cases, it is hoped that he will be authorized by law to have facts ascertained by the courts when for his own information he shall request it.\\n\\nI can not recommend to your notice measures for the fulfillment of our duties to the rest of the world without again pressing upon you the necessity of placing ourselves in a condition of complete defense and of exacting from them the fulfillment of their duties toward us. The United States ought not to indulge a persuasion that, contrary to the order of human events, they will forever keep at a distance those painful appeals to arms with which the history of every other nation abounds. There is a rank due to the United States among nations which will be withheld, if not absolutely lost, by the reputation of weakness. If we desire to avoid insult, we must be able to repel it; if we desire to secure peace, one of the most powerful instruments of our rising prosperity, it must be known that we are at all times ready for war. The documents which will be presented to you will shew the amount and kinds of arms and military stores now in our magazines and arsenals; and yet an addition even to these supplies can not with prudence be neglected, as it would leave nothing to the uncertainty of procuring warlike apparatus in the moment of public danger.\\n\\nNor can such arrangements, with such objects, be exposed to the censure or jealousy of the warmest friends of republican government. They are incapable of abuse in the hands of the militia, who ought to possess a pride in being the depository of the force of the Republic, and may be trained to a degree of energy equal to every military exigency of the United States. But it is an inquiry which can not be too solemnly pursued, whether the act \"more effectually to provide for the national defense by establishing an uniform militia throughout the United States\" has organized them so as to produce their full effect; whether your own experience in the several States has not detected some imperfections in the scheme, and whether a material feature in an improvement of it ought not to be to afford an opportunity for the study of those branches of the military art which can scarcely ever be attained by practice alone.\\n\\nThe connection of the United States with Europe has become extremely interesting. The occurrences which relate to it and have passed under the knowledge of the Executive will be exhibited to Congress in a subsequent communication.\\n\\nWhen we contemplate the war on our frontiers, it may be truly affirmed that every reasonable effort has been made to adjust the causes of dissension with the Indians north of the Ohio. The instructions given to the commissioners evince a moderation and equity proceeding from a sincere love of peace, and a liberality having no restriction but the essential interests and dignity of the United States. The attempt, however, of an amicable negotiation having been frustrated, the troops have marched to act offensively. Although the proposed treaty did not arrest the progress of military preparation, it is doubtful how far the advance of the season, before good faith justified active movements, may retard them during the remainder of the year. From the papers and intelligence which relate to this important subject you will determine whether the deficiency in the number of troops granted by law shall be compensated by succors of militia, or additional encouragements shall be proposed to recruits.\\n\\nAn anxiety has been also demonstrated by the Executive for peace with the Creeks and the Cherokees. The former have been relieved with corn and with clothing, and offensive measures against them prohibited during the recess of Congress. To satisfy the complaints of the latter, prosecutions have been instituted for the violences committed upon them. But the papers which will be delivered to you disclose the critical footing on which we stand in regard to both those tribes, and it is with Congress to pronounce what shall be done.\\n\\nAfter they shall have provided for the present emergency, it will merit their most serious labors to render tranquillity with the savages permanent by creating ties of interest. Next to a rigorous execution of justice on the violators of peace, the establishment of commerce with the Indian nations in behalf of the United States is most likely to conciliate their attachment. But it ought to be conducted without fraud, without extortion, with constant and plentiful supplies, with a ready market for the commodities of the Indians and a stated price for what they give in payment and receive in exchange. Individuals will not pursue such a traffic unless they be allured by the hope of profit; but it will be enough for the United States to be reimbursed only. Should this recommendation accord with the opinion of Congress, they will recollect that it can not be accomplished by any means yet in the hands of the Executive.\\n\\n Gentlemen of the House of Representatives: \\n\\nThe commissioners charged with the settlement of accounts between the United States and individual States concluded their important function within the time limited by law, and the balances struck in their report, which will be laid before Congress, have been placed on the books of the Treasury.\\n\\nOn the first day of June last an installment of 1,000,000 florins became payable on the loans of the United States in Holland. This was adjusted by a prolongation of the period of reimbursement in nature of a new loan at an interest of 5% for the term of ten years, and the expenses of this operation were a commission of 3%.\\n\\nThe first installment of the loan of $2,000,000 from the Bank of the United States has been paid, as was directed by law. For the second it is necessary that provision be made.\\n\\nNo pecuniary consideration is more urgent than the regular redemption and discharge of the public debt. On none can delay be more injurious or an economy of time more valuable.\\n\\nThe productiveness of the public revenues hitherto has continued to equal the anticipations which were formed of it, but it is not expected to prove commensurate with all the objects which have been suggested. Some auxiliary provisions will therefore, it is presumed, be requisite, and it is hoped that these may be made consistently with a due regard to the convenience of our citizens, who can not but be sensible of the true wisdom of encountering a small present addition to their contributions to obviate a future accumulation of burthens.\\n\\nBut here I can not forbear to recommend a repeal of the tax on the transportation of public prints. There is no resource so firm for the Government of the United States as the affections of the people, guided by an enlightened policy; and to this primary good nothing can conduce more than a faithful representation of public proceedings, diffused without restraint throughout the United States.\\n\\nAn estimate of the appropriations necessary for the current service of the ensuing year and a statement of a purchase of arms and military stores made during the recess will be presented to Congress.\\n\\n Gentlemen of the Senate and of the House of Representatives: \\n\\nThe several subjects to which I have now referred open a wide range to your deliberations and involve some of the choicest interests of our common country. Permit me to bring to your remembrance the magnitude of your task. Without an unprejudiced coolness the welfare of the Government may be hazarded; without harmony as far as consists with freedom of sentiment its dignity may be lost. But as the legislative proceedings of the United States will never, I trust, be reproached for the want of temper or of candor, so shall not the public happiness languish from the want of my strenuous and warmest cooperation GO. WASHINGTON\\n\r\n6 \\n\\n Fellow-Citizens of the Senate and House of Representatives: \\n\\nWhen we call to mind the gracious indulgence of Heaven by which the American people became a nation; when we survey the general prosperity of our country, and look forward to the riches, power, and happiness to which it seems destined, with the deepest regret do I announce to you that during your recess some of the citizens of the United States have been found capable of insurrection. It is due, however, to the character of our Government and to its stability, which can not be shaken by the enemies of order, freely to unfold the course of this event.\\n\\nDuring the session of the year 1790 it was expedient to exercise the legislative power granted by the Constitution of the United States \"to lay and collect excises\". In a majority of the States scarcely an objection was heard to this mode of taxation. In some, indeed, alarms were at first conceived, until they were banished by reason and patriotism. In the four western counties of Pennsylvania a prejudice, fostered and imbittered by the artifice of men who labored for an ascendency over the will of others by the guidance of their passions, produced symptoms of riot and violence.\\n\\nIt is well known that Congress did not hesitate to examine the complaints which were presented, and to relieve them as far as justice dictated or general convenience would permit. But the impression which this moderation made on the discontented did not correspond with what it deserved. The arts of delusion were no longer confined to the efforts of designing individuals. The very forbearance to press prosecutions was misinterpreted into a fear of urging the execution of the laws, and associations of men began to denounce threats against the officers employed. From a belief that by a more formal concert their operation might be defeated, certain self-created societies assumed the tone of condemnation. Hence, while the greater part of Pennsylvania itself were conforming themselves to the acts of excise, a few counties were resolved to frustrate them. It is now perceived that every expectation from the tenderness which had been hitherto pursued was unavailing, and that further delay could only create an opinion of impotency or irresolution in the Government. Legal process was therefore delivered to the marshal against the rioters and delinquent distillers.\\n\\nNo sooner was he understood to be engaged in this duty than the vengeance of armed men was aimed at his person and the person and property of the inspector of the revenue. They fired upon the marshal, arrested him, and detained him for some time as a prisoner. He was obliged, by the jeopardy of his life, to renounce the service of other process on the west side of the Allegheny Mountain, and a deputation was afterwards sent to him to demand a surrender of that which he had served. A numerous body repeatedly attacked the house of the inspector, seized his papers of office, and finally destroyed by fire his buildings and whatsoever they contained. Both of these officers, from a just regard to their safety, fled to the seat of Government, it being avowed that the motives to such outrages were to compel the resignation of the inspector, to withstand by force of arms the authority of the United States, and thereby to extort a repeal of the laws of excise and an alteration in the conduct of Government.\\n\\nUpon testimony of these facts an associate justice of the Supreme Court of the United States notified to me that \"in the counties of Washington and Allegheny, in Pennsylvania, laws of the United States were opposed, and the execution thereof obstructed, by combinations too powerful to be suppressed by the ordinary course of judicial proceedings or by the powers vested in the marshal of that district\".\\n\\nOn this call, momentous in the extreme, I sought and weighted what might best subdue the crisis. On the one hand the judiciary was pronounced to be stripped of its capacity to enforce the laws; crimes which reached the very existence of social order were perpetrated without control; the friends of Government were insulted, abused, and overawed into silence or an apparent acquiescence; and to yield to the treasonable fury of so small a portion of the United States would be to violate the fundamental principle of our Constitution, which enjoins that the will of the majority shall prevail. On the other, to array citizen against citizen, to publish the dishonor of such excesses, to encounter the expense and other embarrassments of so distant an expedition, were steps too delicate, too closely interwoven with many affecting considerations, to be lightly adopted.\\n\\nI postponed, therefore, the summoning of the militia immediately into the field, but I required them to be held in readiness, that if my anxious endeavors to reclaim the deluded and to convince the malignant of their danger should be fruitless, military force might be prepared to act before the season should be too far advanced.\\n\\nMy proclamation of the 7th of August last [1794-08-07] was accordingly issued, and accompanied by the appointment of commissioners, who were charged to repair to the scene of insurrection. They were authorized to confer with any bodies of men or individuals. They were instructed to be candid and explicit in stating the sensations which had been excited in the Executive, and his earnest wish to avoid a resort to coercion; to represent, however, that, without submission, coercion must be the resort; but to invite them, at the same time, to return to the demeanor of faithful citizens, by such accommodations as lay within the sphere of Executive power. Pardon, too, was tendered to them by the Government of the United States and that of Pennsylvania, upon no other condition than a satisfactory assurance of obedience to the laws.\\n\\nAlthough the report of the commissioners marks their firmness and abilities, and must unite all virtuous men, by shewing that the means of conciliation have been exhausted, all of those who had committed or abetted the tumults did not subscribe the mild form which was proposed as the atonement, and the indications of a peaceable temper were neither sufficiently general nor conclusive to recommend or warrant the further suspension of the march of the militia.\\n\\nThus the painful alternative could not be discarded. I ordered the militia to march, after once more admonishing the insurgents in my proclamation of the 25th of September last [1794-09-25].\\n\\nIt was a task too difficult to ascertain with precision the lowest degree of force competent to the quelling of the insurrection. From a respect, indeed, to economy and the ease of my fellow citizens belonging to the militia, it would have gratified me to accomplish such an estimate. My very reluctance to ascribe too much importance to the opposition, had its extent been accurately seen, would have been a decided inducement to the smallest efficient numbers. In this uncertainty, therefore, I put into motion 15K men, as being an army which, according to all human calculation, would be prompt and adequate in every view, and might, perhaps, by rendering resistance desperate, prevent the effusion of blood. Quotas had been assigned to the States of New Jersey, Pennsylvania, Maryland, and Virginia, the governor of Pennsylvania having declared on this occasion an opinion which justified a requisition to the other States.\\n\\nAs commander in chief of the militia when called into the actual service of the United States, I have visited the places of general rendezvous to obtain more exact information and to direct a plan for ulterior movements. Had there been room for a persuasion that the laws were secure from obstruction; that the civil magistrate was able to bring to justice such of the most culpable as have not embraced the proffered terms of amnesty, and may be deemed fit objects of example; that the friends to peace and good government were not in need of that aid and countenance which they ought always to receive, and, I trust, ever will receive, against the vicious and turbulent, I should have caught with avidity the opportunity of restoring the militia to their families and homes. But succeeding intelligence has tended to manifest the necessity of what has been done, it being now confessed by those who were not inclined to exaggerate the ill conduct of the insurgents that their malevolence was not pointed merely to a particular law, but that a spirit inimical to all order has actuated many of the offenders. If the state of things had afforded reason for the continuance of my presence with the army, it would not have been withholden. But every appearance assuring such an issue as will redound to the reputation and strength of the United States, I have judged it most proper to resume my duties at the seat of Government, leaving the chief command with the governor of Virginia.\\n\\nStill, however, as it is probable that in a commotion like the present, whatsoever may be the pretense, the purposes of mischief and revenge may not be laid aside, the stationing of a small force for a certain period in the four western counties of Pennsylvania will be indispensable, whether we contemplate the situation of those who are connected with the execution of the laws or of others who may have exposed themselves by an honorable attachment to them. Thirty days from the commencement of this session being the legal limitation of the employment of the militia, Congress can not be too early occupied with this subject.\\n\\nAmong the discussions which may arise from this aspect of our affairs, and from the documents which will be submitted to Congress, it will not escape their observation that not only the inspector of the revenue, but other officers of the United States in Pennsylvania have, from their fidelity in the discharge of their functions, sustained material injuries to their property. The obligation and policy of indemnifying them are strong and obvious. It may also merit attention whether policy will not enlarge this provision to the retribution of other citizens who, though not under the ties of office, may have suffered damage by their generous exertions for upholding the Constitution and the laws. The amount, even if all the injured were included, would not be great, and on future emergencies the Government would be amply repaid by the influence of an example that he who incurs a loss in its defense shall find a recompense in its liberality.\\n\\nWhile there is cause to lament that occurrences of this nature should have disgraced the name or interrupted the tranquillity of any part of our community, or should have diverted to a new application any portion of the public resources, there are not wanting real and substantial consolations for the misfortune. It has demonstrated that our prosperity rests on solid foundations, by furnishing an additional that my fellow citizens understand the true principles of government and liberty; that they feel their inseparable union; that notwithstanding all the devices which have been used to sway them from their interest and duty, they are not as ready to maintain the authority of the laws against licentious invasions as they were to defend their rights against usurpation. It has been a spectacle displaying to the highest advantage of republican government to behold the most and the least wealthy of our citizens standing in the same ranks as private soldiers, preeminently distinguished by being the army of the Constitution - undeterred by a march of 300 miles over rugged mountains, by approach of an inclement season, or by any other discouragement. Nor ought I to omit to acknowledge the efficacious and patriotic cooperation which I have experienced from the chief magistrates of the States to which my requisitions have been addressed.\\n\\nTo every description of citizens, let praise be given. but let them persevere in their affectionate vigilance over that precious depository of American happiness, the Constitution of the United States. Let them cherish it, too, for the sake of those who, from every clime, are daily seeking a dwelling in our land. And when in the calm moments of reflection they shall have retraced the origin and progress of the insurrection, let them determine whether it has not been fomented by combinations of men who, careless of consequences and disregarding the unerring truth that those who rouse can not always appease a civil convulsion, have disseminated, from an ignorance or perversion of facts, suspicions, jealousies, and accusations of the whole Government.\\n\\nHaving thus fulfilled the engagement which I took when I entered into office, \"to the best of my ability to preserve, protect, and defend the Constitution of the United States\", on you, gentlemen, and the people by whom you are deputed, I rely for support.\\n\\nIn the arrangement to which the possibility of a similar contingency will naturally draw your attention it ought not to be forgotten that the militia laws have exhibited such striking defects as could not have been supplied by the zeal of our citizens. Besides the extraordinary expense and waste, which are not the least of the defects, every appeal to those laws is attended with a doubt on its success.\\n\\nThe devising and establishing of a well regulated militia would be a genuine source of legislative honor and a perfect title to public gratitude. I therefore entertain a hope that the present session will not pass without carrying to its full energy the power of organizing, arming, and disciplining the militia, and thus providing, in the language of the Constitution, for calling them forth to execute the laws of the Union, suppress insurrections, and repel invasions.\\n\\nAs auxiliary to the state of our defense, to which Congress can never too frequently recur, they will not omit to inquire whether the fortifications which have been already licensed by law be commensurate with our exigencies.\\n\\nThe intelligence from the army under the command of General Wayne is a happy presage to our military operations against the hostile Indians north of the Ohio. From the advices which have been forwarded, the advance which he has made must have damped the ardor of the savages and weakened their obstinacy in waging war against the United States. And yet, even at this late hour, when our power to punish them can not be questioned, we shall not be unwilling to cement a lasting peace upon terms of candor, equity, and good neighborhood.\\n\\nToward none of the Indian tribes have overtures of friendship been spared. The Creeks in particular are covered from encroachment by the imposition of the General Government and that of Georgia. From a desire also to remove the discontents of the Six nations, a settlement mediated at Presque Isle, on Lake Erie, has been suspended, and an agent is now endeavoring to rectify any misconception into which they may have fallen. But I can not refrain from again pressing upon your deliberations the plan which I recommended at the last session for the improvement of harmony with all the Indians within our limits by the fixing and conducting of trading houses upon the principles then expressed.\\n\\n Gentlemen of the House of Representatives: \\n\\nThe time which has elapsed since the commencement of our fiscal measures has developed our pecuniary resources so as to open the way for a definite plan for the redemption of the public debt. It is believed that the result is such as to encourage Congress to consummate this work without delay. Nothing can more promote the permanent welfare of the nation and nothing would be more grateful to our constituents. Indeed, whatsoever is unfinished of our system of public credit can not be benefited by procrastination; and as far as may be practicable we ought to place that credit on grounds which can not be disturbed, and to prevent that progressive accumulation of debt which must ultimately endanger all governments.\\n\\nAn estimate of the necessary appropriations, including the expenditures into which we have been driven by the insurrection, will be submitted to Congress.\\n\\n Gentlemen of the Senate and of the House of Representatives: \\n\\nThe Mint of the United States has entered upon the coinage of the precious metals, and considerable sums of defective coins and bullion have been lodged with the Director by individuals. There is a pleasing prospect that the institution will at no remote day realize the expectation which was originally formed of its utility.\\n\\nIn subsequent communications certain circumstances of our intercourse with foreign nations will be transmitted to Congress. However, it may not be unseasonable to announce that my policy in our foreign transactions has been to cultivate peace with all the world; to observe the treaties with pure and absolute faith; to check every deviation from the line of impartiality; to explain what may have been misapprehended and correct what may have been injurious to any nation, and having thus acquired the right, to lose no time in acquiring the ability to insist upon justice being done to ourselves.\\n\\nLet us unite, therefore, in imploring the Supreme Ruler of Nations to spread his holy protection over these United States; to turn the machinations of the wicked to the confirming of our Constitution; to enable us at all times to root out internal sedition and put invasion to flight; to perpetuate to our country that prosperity which his goodness has already conferred, and to verify the anticipations of this Government being a safeguard of human rights. GO. WASHINGTON\\n\r\n\r\n# split into sentences\r\ntidy_sotu <- df |> \r\n  unnest_tokens(input = 'text',\r\n                output = 'sentence',\r\n                token = 'sentences') |> \r\n  # keep only the sentences that contain the word stem \"manufactu\"\r\n  filter(str_detect(sentence, 'manufactu'))\r\n\r\nhead(tidy_sotu)\r\n\r\n  speech_id         president year\r\n1         1 George Washington 1790\r\n2         3 George Washington 1791\r\n3         7 George Washington 1795\r\n4         8 George Washington 1796\r\n5         8 George Washington 1796\r\n6         9        John Adams 1797\r\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     sentence\r\n1                                                  the advancement of agriculture, commerce, and manufactures by all proper means will not, i trust, need recommendation; but i can not forbear intimating to you the expediency of giving effectual encouragement as well to the introduction of new and useful inventions from abroad as to the exertions of skill and genius in producing them at home, and of facilitating the intercourse between the distant parts of our country by a due attention to the post-office and post-roads.\r\n2                                                                                                                                                                                                                                                                                                                                                                                your own observations in your respective situations will have satisfied you of the progressive state of agriculture, manufactures, commerce, and navigation.\r\n3                                                                                                                                                                                                                                                     our agriculture, commerce, and manufactures prosper beyond former example, the molestations of our trade (to prevent a continuance of which, however, very pointed remonstrances have been made) being overbalanced by the aggregate benefits which it derives from a neutral position.\r\n4                                                                                                                                                                                                                                                                                                                                                                                                                           congress have repeatedly, and not without success, directed their attention to the encouragement of manufactures.\r\n5 as a general rule, manufactures on public account are inexpedient; but where the state of things in a country leaves little hope that certain branches of manufacture will for a great length of time obtain, when these are of a nature essential to the furnishing and equipping of the public force in time of war, are not establishments for procuring them on public account to the extent of the ordinary demand for the public service recommended by strong considerations of national policy as an exception to the general rule?\r\n6                                                                                                                                                                                                                                                                                                                                                                                                                                                   our agriculture, fisheries, arts, and manufactures are connected with and depend upon it.\r\n\r\nNotice that the unnest_tokens() function converts all the words to lower case. We now have a dataframe where the unit of analysis is the sentence, containing every sentence in State of the Union speeches from 1790 to 2016 that mentions the word “manufacturing”.\r\nStep 2: Tokenize\r\nNow that we have the corpus of text we’re interested in studying, we can tokenize to the word level (using the same unnest_tokens() function) to create our bag of words.\r\n\r\n\r\ntidy_sotu <- tidy_sotu |> \r\n  unnest_tokens(input = 'sentence',\r\n                output = 'word') |> \r\n  # we're just interested in words that occur near manufacturing, so remove\r\n  # the manufacturing words themselves\r\n  filter(str_detect(word, 'manufactu', negate = TRUE))\r\n\r\nhead(tidy_sotu)\r\n\r\n  speech_id         president year        word\r\n1         1 George Washington 1790         the\r\n2         1 George Washington 1790 advancement\r\n3         1 George Washington 1790          of\r\n4         1 George Washington 1790 agriculture\r\n5         1 George Washington 1790    commerce\r\n6         1 George Washington 1790         and\r\n\r\nStep 3: Reduce Complexity\r\nBecause there are so many words in the English language, it can be advantageous to reduce the sparseness of the bag of words a bit. We can do so by removing “stop words” (words like articles and prepositions that are common but do not themselves contain meaning) and representing words with their “stem” (so words like “duties” and “duty” are represented by the same word stem, “duti”).\r\n\r\n\r\n# remove stopwords\r\ntidy_sotu <- tidy_sotu |> \r\n  anti_join(get_stopwords())\r\n\r\nhead(tidy_sotu)\r\n\r\n  speech_id         president year        word\r\n1         1 George Washington 1790 advancement\r\n2         1 George Washington 1790 agriculture\r\n3         1 George Washington 1790    commerce\r\n4         1 George Washington 1790      proper\r\n5         1 George Washington 1790       means\r\n6         1 George Washington 1790       trust\r\n\r\nWord stemming is available courtesy of the SnoballC package.\r\n\r\n\r\nlibrary(SnowballC)\r\n\r\nwordStem('duty')\r\n\r\n[1] \"duti\"\r\n\r\nwordStem('duties')\r\n\r\n[1] \"duti\"\r\n\r\ntidy_sotu <- tidy_sotu |> \r\n  mutate(word_stem = wordStem(word))\r\n\r\nhead(tidy_sotu)\r\n\r\n  speech_id         president year        word  word_stem\r\n1         1 George Washington 1790 advancement     advanc\r\n2         1 George Washington 1790 agriculture agricultur\r\n3         1 George Washington 1790    commerce    commerc\r\n4         1 George Washington 1790      proper     proper\r\n5         1 George Washington 1790       means       mean\r\n6         1 George Washington 1790       trust      trust\r\n\r\nStep 4: Create the Document-Feature Matrix\r\nThis step is only necessary if you need a document-feature matrix for a subsequent statistical model. If not, it can be useful for visualization and summary statistics to keep the word counts in a tidy dataframe.\r\nHere’s a visualization of the word stems that presidents most commonly use when discussing manufacturing.\r\n\r\n\r\nlibrary(wordcloud2)\r\n\r\ntidy_sotu |> \r\n  count(word_stem) |> \r\n  wordcloud2()\r\n\r\n\r\n\r\nTo convert the tidy dataframe to a matrix, we can use the cast_dtm() function from tidytext.\r\n\r\n\r\ndtm_sotu <- tidy_sotu |> \r\n  count(speech_id, word_stem) |> \r\n  cast_dtm(document = 'speech_id',\r\n           term = 'word_stem',\r\n           value = 'n')\r\n\r\ndtm_sotu\r\n\r\n<<DocumentTermMatrix (documents: 145, terms: 2451)>>\r\nNon-/sparse entries: 8961/346434\r\nSparsity           : 97%\r\nMaximal term length: 14\r\nWeighting          : term frequency (tf)\r\n\r\nPractice Problems\r\nCreate a bag of words that co-occur in State of the Union sentences with the word “Mexico”, or some other word of your choice.\r\nCreate a bag of words representation of the Federalist Papers corpus, available in the corpus package (corpus::federalist).\r\n\r\n\r\n\r\nGrimmer, Justin, Brandon M. Stewart, and Margaret E. Roberts. 2021. Text as Data: A New Framework for Machine Learning and the Social Sciences. S.l.: Princeton University Press.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-06-13T13:58:40-04:00"
    },
    {
      "path": "clustering.html",
      "title": "Clustering",
      "description": "For when we don't really know what we're looking for in our data and just want the computer to tell us what it sees.\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nK-means Clustering\r\nValidation, Validation, Validation\r\nClustering with Word Embeddings\r\nPractice Problems\r\n\r\nBroadly speaking, we can divide the approaches for modeling text data into two camps: supervised learning and unsupervised learning. Supervised learning approaches tend to be the most familiar to social scientists – there is some outcome we’d like to predict, so we fit a function of observable covariates to try and predict it. In the context of text as data, this means we have a set of labeled documents, and we fit a model to see how well we can predict the labels (e.g. predicting the authorship of the Federalist Papers).\r\nUnsupervised learning, by comparison, is less about prediction and more about discovery. You start with a set of unlabeled documents, and ask the computer to see if it can find a sensible way to organize them. Are there patterns of language that distinguish one set of documents from others? What words can help identify a cluster of documents, by appearing within them more frequently than one would expect by chance? These sorts of approaches, which include both clustering and topic models, require a healthy dose of human judgment to derive meaningful insights, and they often serve as the first stage of a research agenda that moves from discovery to explanation, prediction, and inference.\r\nK-means Clustering\r\nChapter 12 of Grimmer, Stewart, and Roberts (2021) introduces the dataset of Congressional press releases that Grimmer (2013) explores in his study of representational style. Using a k-means clustering model, he developed a set of categories to describe these ways that members of Congress communicate with their constituents, discovering new categories that were previously understudied by political scientists. The full dataset is available here, and I’ve included the press releases from Senator Lautenberg on the course repository. Let’s load and tidy the data, representing each press release as a bag of word stems.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(tidytext)\r\nlibrary(SnowballC)\r\n\r\nload('data/press-releases/lautenberg-press-releases.RData')\r\n\r\ntidy_press_releases <- df |>\r\n  # remove the preamble common to each press release\r\n  mutate(text = str_replace_all(text,\r\n                                pattern = '     Senator Frank R  Lautenberg                                                                                                                      Press Release        of        Senator Lautenberg                                                                                ',\r\n                                replacement = '')) |>\r\n  # tokenize to the word level\r\n  unnest_tokens(input = 'text',\r\n                output = 'word') |>\r\n  # remove stop words\r\n  anti_join(get_stopwords()) |>\r\n  # remove numerals\r\n  filter(str_detect(word, '[0-9]', negate = TRUE)) |>\r\n  # create word stems\r\n  mutate(word_stem = wordStem(word)) |>\r\n  filter(word_stem != '') |> \r\n  # count up bag of word stems\r\n  count(id, word_stem) |> \r\n  # compute term frequency\r\n  bind_tf_idf(term = 'word_stem',\r\n              document = 'id',\r\n              n = 'n') |>\r\n  filter(!is.na(tf_idf))\r\n\r\ntidy_press_releases\r\n\r\n# A tibble: 81,504 × 6\r\n      id word_stem     n      tf   idf  tf_idf\r\n   <int> <chr>     <int>   <dbl> <dbl>   <dbl>\r\n 1     1 account       2 0.00654 1.86  0.0121 \r\n 2     1 also          2 0.00654 0.891 0.00582\r\n 3     1 america       2 0.00654 1.80  0.0118 \r\n 4     1 american      1 0.00327 1.05  0.00344\r\n 5     1 answer        1 0.00327 3.69  0.0120 \r\n 6     1 apologi       1 0.00327 5.63  0.0184 \r\n 7     1 appropri      1 0.00327 1.60  0.00522\r\n 8     1 april         2 0.00654 2.18  0.0143 \r\n 9     1 ask           1 0.00327 2.13  0.00698\r\n10     1 assault       2 0.00654 3.93  0.0257 \r\n# ℹ 81,494 more rows\r\n\r\nNext, we’ll convert that tidy dataframe into a document-term matrix.\r\n\r\n\r\n# create document-term matrix\r\nlautenberg_dtm <- cast_dtm(data = tidy_press_releases,\r\n                           document = 'id',\r\n                           term = 'word_stem',\r\n                           value = 'tf')\r\nlautenberg_dtm\r\n\r\n<<DocumentTermMatrix (documents: 558, terms: 7073)>>\r\nNon-/sparse entries: 81504/3865230\r\nSparsity           : 98%\r\nMaximal term length: 33\r\nWeighting          : term frequency (tf)\r\n\r\nThe k-means clustering algorithm searches for a set of \\(k\\) centroids that yield the smallest sum of squared distances between the observations and their nearest centroid. If each document is represented by a vector of term frequencies, then k-means produces \\(k\\) sets of documents that have the most similar usages of words.1\r\n\r\n\r\nset.seed(42)\r\n\r\nkm <- kmeans(x = lautenberg_dtm,\r\n             centers = 4,\r\n             nstart = 100)\r\n\r\ntable(km$cluster)\r\n\r\n\r\n  1   2   3   4 \r\n158  53 264  83 \r\n\r\nMaking sense of this algorithm’s output is tricky. Sure, we simplified the problem a bit. We started with 558 documents, each represented by a 7,073-dimensional vector. Now we have 4 document clusters, each represented by a 7,073-dimensional vector.\r\n\r\n\r\n\r\nSo…what do we do with those?\r\nOne of the most common ways to interpret the k-means clusters is to generate a list of the most distinctive words from each cluster. Then we can look at which words show up more frequently in one cluster than any other, and use that information to assign labels to the clusters.\r\n\r\n\r\n# function to find the words that are most overrepresented in the cluster mean for a given cluster\r\nget_top_words <- function(centers, cluster_of_interest, n = 10){\r\n  (centers[cluster_of_interest,] - colMeans(centers[-cluster_of_interest,])) |>\r\n    sort(decreasing = TRUE) |>\r\n    head(n)\r\n}\r\n\r\n\r\n\r\n\r\nget_top_words(km$centers, 1)\r\n\r\n        new      jersei    menendez        fund     project \r\n0.020521488 0.017404097 0.007306990 0.006406194 0.004548713 \r\n    million       feder          nj     program         sen \r\n0.003967707 0.003579091 0.003422422 0.003390473 0.003174855 \r\n\r\nIt looks like that first cluster contains words related to New Jersey-specific projects. Maybe we’ll call this category “credit claiming”.\r\n\r\n\r\nget_top_words(km$centers, 2)\r\n\r\n      secur      chemic    homeland        port     protect \r\n0.047101748 0.017238562 0.012628968 0.009966087 0.005874105 \r\n       risk         law          dh        bill  lautenberg \r\n0.005328492 0.005129255 0.004088366 0.003876055 0.003604233 \r\n\r\nThe second cluster contains words related to security.\r\n\r\n\r\nget_top_words(km$centers, 3)\r\n\r\n     legisl         sen    american        bill         epa \r\n0.003556391 0.002868324 0.002606283 0.002589137 0.002394477 \r\n        act      famili      victim        year      amtrak \r\n0.002078147 0.001866299 0.001717110 0.001707263 0.001613547 \r\n\r\nThe third cluster has words related to various pieces of legislation and Senate business.\r\n\r\n\r\nget_top_words(km$centers, 4)\r\n\r\n     presid        bush   statement       senat     comment \r\n0.019325460 0.015638002 0.007088761 0.004435791 0.004353666 \r\n       unit       elect      follow        issu         tax \r\n0.004192093 0.004036246 0.003940064 0.003897682 0.003500055 \r\n\r\nAnd the final cluster looks like the “partisan taunting” category dicussed in the book.\r\nValidation, Validation, Validation\r\nTo validate our manually-assigned cluster labels, we want to go back to the text and check to see if they do a good job summarizing the documents. If not, we should modify our cluster labels or try a different value for \\(k\\).\r\n\r\n\r\ncluster_assignments <- tibble(id = km$cluster |> \r\n                                names() |> \r\n                                as.numeric(),\r\n                              cluster = km$cluster)\r\n\r\ndf <- df |>\r\n  left_join(cluster_assignments,\r\n            by = 'id')\r\n\r\n\r\nIf we pull a random document from Cluster 1, it should be related to New Jersey in some way.\r\n\r\n\r\nprint_text <- function(text){\r\n  cat(str_wrap(text), sep = '\\n')\r\n}\r\n\r\ndf |>\r\n  filter(cluster == 1) |>\r\n  slice_sample(n = 1) |>\r\n  pull(text) |> \r\n  print_text()\r\n\r\nSenator Frank R Lautenberg Press Release of Senator Lautenberg Lautenberg\r\nMenendez Announce 21 Million for Improvements in Screening Areas at Newark\r\nLiberty Airport Contact Alex Formuzis 202 224 7340 Thursday August 3 2006\r\nWASHINGTON D C Air travelers who depart from Newark Liberty International\r\nAirport will benefit from improvements in the security screening area thanks\r\nto almost 21 million in federal grants announced today by U S Senators Frank\r\nLautenberg D NJ and Robert Menendez D NJ The grants will be used to widen\r\nterminal connecting areas creating more space for passengers waiting to\r\npass through security checkpoints These improvements will make it even more\r\nconvenient to fly from Newark Liberty Airport said Senator Lautenberg By\r\nimproving the airport we protect our economy and our quality of life Newark\r\nLiberty International Airport is a huge hub of activity for New Jersey and\r\nthe nation It provides jobs for New Jerseyans acts as a means for American and\r\ninternational businessmen and women to work throughout the region and allows\r\nvisitors to come enjoy our great state said Senator Menendez Senator Lautenberg\r\nand I fought tirelessly for these funds to improve the safety and efficiency of\r\nthis thriving center of travel The funds were awarded by the Federal Aviation\r\nAdministration to the Port Authority of New York and New Jersey which operates\r\nthe airport Questions or Comments\r\n\r\nIf we pull a random document from Cluster 2, it should be about security.\r\n\r\n\r\ndf |>\r\n  filter(cluster == 2) |>\r\n  slice_sample(n = 1) |>\r\n  pull(text) |> \r\n  print_text()\r\n\r\nSenator Frank R Lautenberg Press Release of Senator Lautenberg Lautenberg\r\nPallone Menendez Blast Proposal to Block New Jersey s Chemical Security\r\nRegulations Contact Alex Formuzis 202 224 7340 Thursday February 8 2007\r\nWASHINGTON D C U S Sens Frank R Lautenberg D NJ and Robert Menendez D NJ and U S\r\nRep Frank Pallone Jr D NJ today blasted the U S Department of Homeland Security\r\nDHS for proposing a federal rule that would preempt New Jersey s existing\r\nchemical security regulations The three lawmakers submitted extensive comments\r\nas part of the public comment period for a DHS proposed regulation to develop\r\ntemporary federal regulations to help secure chemical facilities A copy of that\r\nletter is attached The regulation was developed in response to a legislative\r\nprovision in the Fiscal Year 2007 Homeland Security Appropriations Act passed\r\nin 2006 Although that provision did not give the Department the right to preempt\r\nstate or local laws on the subject the Department s recent proposal assumed\r\nsuch authority As representatives of the citizens of New Jersey we simply cannot\r\naccept a proposed regulatory scheme that requires our constituents to rely\r\nupon the best efforts of private companies and this Administration to ensure\r\ntheir safety from terrorist attacks on chemical facilities in their communities\r\nthe three New Jersey lawmakers wrote In 2005 New Jersey implemented Chemical\r\nSecurity Sector Best Practices requiring all chemical facilities in the state to\r\ncomply with security standards conduct an assessment of their vulnerability to\r\nterrorist attacks develop prevention preparedness and response plans to minimize\r\nsuch attacks and review whether it would be practical to use safer materials\r\nor processes New Jersey took steps to improve its security after 9 11 and it\r\nmay need to take additional steps in the future Lautenberg Pallone and Menendez\r\ncontinued in their public comment letter We strongly oppose any efforts by\r\nDHS and the rest of this Administration to prevent it from doing so Lautenberg\r\nand Pallone have introduced comprehensive chemical security bills in previous\r\nCongresses and announced their intention to do so during this Congress Questions\r\nor Comments\r\n\r\nIf we pull a random document from Cluster 3, it be about legislation and/or Senate business.\r\n\r\n\r\ndf |>\r\n  filter(cluster == 3) |>\r\n  slice_sample(n = 1) |>\r\n  pull(text) |> \r\n  print_text()\r\n\r\nSenator Frank R Lautenberg Press Release of Senator Lautenberg Lautenberg\r\nSpecter Introduce Bill To Give Justice To Victims of State Sponsored Terrorism\r\nMeasure Would Empower Victims To Pursue Assets of Countries Like Iran That\r\nSponsor Terror Contact Press Office 202 224 3224 Thursday August 2 2007\r\nWASHINGTON D C Sen Frank R Lautenberg D NJ and Sen Arlen Specter R PA today\r\nled a strong bipartisan coalition of Senators introducing legislation to give\r\nvictims of state sponsored terrorism their day in court Far too many Americans\r\nhave suffered at the hands of terrorism My bill would allow victims of state\r\nsponsored terror to have their day in court It would let victims sue countries\r\nand hold those countries accountable said Sen Lautenberg I am pleased to\r\ncosponsor this legislation which gives the victims of terrorism and their\r\nfamilies the ability to seek legal redress said Sen Specter This bill reaffirms\r\nthat the United States will not tolerate state sponsored terrorism The bill\r\nwould allow victims of state sponsored terror to sue countries that promote\r\nterrorism The measure would allow victims to seize hidden commercial assets for\r\ncompensation This legislation is important to the families of the victims of the\r\n1983 Marine Barracks bombing in Beirut Lebanon It will hold the government of\r\nIran accountable for the murder of 241 men in this bombing one of whom was my\r\nbrother Captain Vincent L Smith United States Marine Corps The injustice of this\r\nover the long years has been a heavy burden the Iranian government has literally\r\nbeen getting away with murder for almost 24 years The passage of this bill will\r\nbring justice by holding the criminals accountable for their crime And I believe\r\nit will mitigate future terrorism This bill is a huge statement of support for\r\nvictims of terrorism and a powerful way to fight terrorism without the use of\r\nmilitary force said Lynn Derbyshire who serves as the national spokesperson for\r\nThe Beirut Families The legislation the Justice for Victims of State Sponsored\r\nTerrorism Act is based on a 1996 amendment to the Foreign Sovereign Immunities\r\nAct known as the Flatow Amendment which enabled American victims of terrorism to\r\ngo after state sponsors of terrorism in court The billwould reaffirm the rights\r\nof plaintiffs to sue state sponsors of terrorism allow the seizure of hidden\r\ncommercial assets belonging to terrorist states so victims of terrorism can be\r\njustly compensated limit the number of appeals that a terrorist state can pursue\r\nin U S courts and provide foreign nationals working for the U S government these\r\nsame benefits if they are victimized in a terrorist attack during their official\r\nduties The measure has an impressive bipartisan list of original cosponsors\r\nincluding Senators Robert Menendez D NJ Trent Lott R MS Joseph Biden D DE John\r\nCornyn R TX Hillary Clinton D NY Lindsey Graham R SC Diane Feinstein D CA Joseph\r\nLieberman I CT Charles Schumer D NY Norm Coleman R MN Robert Casey D PA Susan\r\nCollins R ME and Ted Stevens R AK Questions or Comments\r\n\r\nAnd a random document from Cluster 4 should contain some form of “partisan taunting”.\r\n\r\n\r\ndf |>\r\n  filter(cluster == 4) |>\r\n  slice_sample(n = 1) |>\r\n  pull(text) |> \r\n  print_text()\r\n\r\nSenator Frank R Lautenberg Press Release of Senator Lautenberg Lautenberg\r\nOutraged Over Bush Admin Decision to Let Libya Off the Hook for Pan Am 103\r\nTerrorist Bombing Contact Alex Formuzis 202 224 7340 Wednesday June 28 2006\r\nWASHINGTON D C United States Senator Frank R Lautenberg D NJ who has led the\r\nfight on behalf of the families of victims of Pan Am 103 today issued the\r\nfollowing statement in response to the Bush Administration s decision to let\r\nthe Libyan government off the hook Today the Bush Administration put other\r\ninterests ahead of American victims of terrorism I am very disappointed that\r\nthe Administration chose to renew its relationship with Qadhafi before making\r\nsure he fulfilled his promises to American victims of his terror said Senator\r\nLautenberg Under the original agreement between the Libyan government and the\r\nfamilies of the victims of Pan Am 103 each family was to receive 10 million from\r\nthe Libyan government to be paid out in three installments 4 million when the U\r\nN lifted its sanctions 4 million when the U S lifted its trade sanctions and the\r\nfinal 2 million when Libya was taken off the U S terrorist list which officially\r\nhappens today On May 15 Secretary of State Condoleezza Rice announced that the\r\nadministration would renew diplomatic relations with Libya at which point a\r\n45 day review began That review period ends today and Libya will be formally\r\nremoved from the U S State Department s list of state sponsors of terrorism\r\nThe Libyan Government and the Bush administration appear to have agreed that\r\nthe final payment does not need to be paid to the families Earlier this month\r\nthe Senate approved a Resolution by Senators Lautenberg and Lindsey Graham R SC\r\nurging the Bush administration not to establish diplomatic relations with Libya\r\nuntil it fulfills its responsibilities to the families of the Pan Am 103 victims\r\nIn August 2003 the Libyan government took responsibility for the bombing of\r\nPan Am flight 103 over Lockerbie Scotland on December 21st 1988 that killed 270\r\npeople Of the 189 Americans who died as a result of the bombing 38 were from New\r\nJersey Questions or Comments\r\n\r\nClustering with Word Embeddings\r\nIn that last clustering exercise, we represented each document as a vector of word counts. This can lead us astray when the documents are very short but our vocabulary is very large. For example, Senator Lautenberg has a number of press releases that I would classify as being about the environment, but the Bag of Words has no idea that words like “preservation”, “mercury”, and “rivers” might belong in the same category.\r\nWhen documents are as brief as these press releases, one could potentially represent them with text embeddings. The k-means clustering algorithm then works in the same way, except that it is assigning clusters within a vector space corresponding to the meaning of the documents (in a sense) rather than a vector space that’s just counting up the frequency of words.\r\nLet’s give it a try, shall we? First, get the document embeddings for each press release using the fuzzylink package.\r\n\r\n\r\nlibrary(fuzzylink)\r\ndocument_embeddings <- get_embeddings(df$text)\r\n\r\n\r\nNow we have a matrix that represents each press release as a 256-dimensional vector. If you’d rather not retrieve that matrix from the OpenAI API yourself, I have it saved on the repository at data/press-releases/embeddings.RData.\r\n\r\n\r\n\r\nUsing k-means, we will identify 9 clusters that best describe those document vectors.\r\n\r\n\r\nset.seed(42)\r\nkm <- kmeans(x = document_embeddings,\r\n             centers = 9,\r\n             nstart = 100)\r\n\r\n# assign the clusters to the original dataframe\r\ndf$cluster <- as.numeric(km$cluster)\r\n\r\ntable(df$cluster)\r\n\r\n\r\n  1   2   3   4   5   6   7   8   9 \r\n 76  42  36  48  78 107  89  43  39 \r\n\r\nYou’ll note, if you’re playing along at home, that this line of code was much quicker than when we estimated k-means on the 7,073-dimensional bag of words vectors. Let’s look at the most over-represented words in each cluster.\r\n\r\n\r\n# a function to get the most over-represented words by cluster\r\nget_top_words <- function(df, cluster_of_interest, num_words = 10){\r\n  df |>\r\n    mutate(in_cluster = if_else(cluster == cluster_of_interest,\r\n                                'within_cluster', 'outside_cluster')) |>\r\n    unnest_tokens(output = 'word',\r\n                  input = 'text') |>\r\n    # remove stop words\r\n    anti_join(get_stopwords()) |>\r\n    # remove numerals\r\n    filter(str_detect(word, '[0-9]', negate = TRUE)) |>\r\n    # create word stems\r\n    mutate(word_stem = wordStem(word)) |>\r\n    # remove \"blank space\" token\r\n    filter(word_stem != '') |>\r\n    # count the words in each cluster\r\n    count(in_cluster, word_stem) |>\r\n    pivot_wider(names_from = 'in_cluster',\r\n                values_from = 'n',\r\n                values_fill = 0) |>\r\n    # compute word shares\r\n    mutate(within_cluster = within_cluster / sum(within_cluster),\r\n           outside_cluster = outside_cluster / sum(outside_cluster)) |>\r\n    mutate(delta = within_cluster - outside_cluster) |>\r\n    arrange(-delta) |>\r\n    head(num_words) |>\r\n    pull(word_stem)\r\n}\r\n\r\nget_top_words(df, 1) # trains / ports / transportation\r\n\r\n [1] \"rail\"      \"amtrak\"    \"secur\"     \"passeng\"   \"transport\"\r\n [6] \"new\"       \"port\"      \"tunnel\"    \"airport\"   \"faa\"      \r\n\r\nget_top_words(df, 2) # military / foreign affairs\r\n\r\n [1] \"iraq\"        \"american\"    \"afghanistan\" \"presid\"     \r\n [5] \"troop\"       \"u\"           \"soldier\"     \"war\"        \r\n [9] \"memori\"      \"honor\"      \r\n\r\nget_top_words(df, 3) # terrorism / middle east\r\n\r\n [1] \"terror\"  \"victim\"  \"libya\"   \"sen\"     \"d\"       \"sponsor\"\r\n [7] \"r\"       \"u\"       \"iran\"    \"opec\"   \r\n\r\nget_top_words(df, 4) # judiciary, but also NFL??\r\n\r\n [1] \"new\"       \"judg\"      \"jersei\"    \"court\"     \"right\"    \r\n [6] \"nfl\"       \"broadband\" \"alito\"     \"honor\"     \"de\"       \r\n\r\nget_top_words(df, 5) # healthcare and health insurance\r\n\r\n [1] \"health\"    \"children\"  \"care\"      \"drug\"      \"medicar\"  \r\n [6] \"program\"   \"prescript\" \"food\"      \"militari\"  \"coverag\"  \r\n\r\nget_top_words(df, 6) # environmental protection\r\n\r\n [1] \"chemic\"      \"epa\"         \"protect\"     \"facil\"      \r\n [5] \"site\"        \"environment\" \"secur\"       \"wast\"       \r\n [9] \"water\"       \"clean\"      \r\n\r\nget_top_words(df, 7) # credit claiming\r\n\r\n [1] \"fund\"     \"new\"      \"jersei\"   \"million\"  \"project\"  \"grant\"   \r\n [7] \"counti\"   \"menendez\" \"flood\"    \"program\" \r\n\r\nget_top_words(df, 8) # tobacco and firearms\r\n\r\n [1] \"gun\"        \"law\"        \"cigarett\"   \"enforc\"     \"tobacco\"   \r\n [6] \"crime\"      \"lautenberg\" \"vaccin\"     \"firearm\"    \"gang\"      \r\n\r\nget_top_words(df, 9) # partisan taunting!\r\n\r\n [1] \"elect\"     \"presid\"    \"administr\" \"mr\"        \"offici\"   \r\n [6] \"report\"    \"bush\"      \"gao\"       \"polit\"     \"white\"    \r\n\r\nThese seem like pretty cohesive categories! And the top words in each cluster seem more likely to share meaning / topic categories. For example, there’s now a cluster for press releases about the environment, consistent with my earlier hunch.\r\nPractice Problems\r\nTry changing the value of \\(k\\) and see if the cluster assignments seem to improve. Look for cluster labels that are exclusive (topics aren’t overlapping; words that are supposed to distinguish one cluster don’t frequently appear in other clusters) and cohesive (it’s easy to identify a unique topic for each cluster).\r\nWhen we estimated k-means with document embeddings, the top words in one cluster included ‘judge’, ‘court’, and ‘alito’, which seems pretty cohesive. But they also included ‘nfl’ and ‘iraq’, which seem out-of-place. Investigate some of the documents included in this cluster. Is there something linking them together, or is this just a poor fit?\r\n\r\n\r\n\r\nGrimmer, Justin. 2013. Representational Style in Congress: What Legislators Say and Why It Matters. New York: Cambridge University Press.\r\n\r\n\r\nGrimmer, Justin, Brandon M. Stewart, and Margaret E. Roberts. 2021. Text as Data: A New Framework for Machine Learning and the Social Sciences. S.l.: Princeton University Press.\r\n\r\n\r\nAllison Horst has a delightful illustrated explanation of how the algorithm works on this page.↩︎\r\n",
      "last_modified": "2025-06-13T13:58:54-04:00"
    },
    {
      "path": "federalist-papers.html",
      "title": "Federalist Paper Authorship",
      "description": "Modeling the bag of words.\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nGet The Data\r\nMultinomial Model\r\nVector Space Model\r\nValidation, Validation, Validation\r\nPractice Problems\r\n\r\nA great entry point for modeling text as data is the now classic problem of guessing who wrote 15 disputed Federalist Papers (Mosteller and Wallace 1964). To do so, we’ll look at the distribution of words that Hamilton, Madison, and Jay tend to write and try to detect their stylistic patterns in the disputed texts. We’ll use two approaches, outlined in Grimmer, Stewart, and Roberts (2021) Chapters 6 and 7: the multinomial model and the vector space model.\r\nGet The Data\r\nWe’ll start by scraping the Federalist Paper corpus from Project Gutenberg.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(tidytext)\r\nlibrary(rvest)\r\n\r\n# read the raw HTML\r\npage <- read_html('https://www.gutenberg.org/cache/epub/18/pg18-images.html')\r\n\r\n# get all the chapters\r\nchapters <- html_elements(page, '.chapter')\r\n\r\n# get just the text from each chapter\r\ntext <- html_text2(chapters)\r\n\r\nd <- tibble(text)\r\n\r\n# get rid of the slightly different version of Federalist 70\r\nd <- d |>\r\n  filter(str_detect(text, 'slightly different version', negate = TRUE))\r\n\r\n# create a column for the title and attributed author\r\nd <- d |>\r\n  mutate(author = text |>\r\n           str_extract('HAMILTON AND MADISON|HAMILTON OR MADISON|HAMILTON|MADISON|JAY') |>\r\n           str_to_title(),\r\n         title = str_extract(text, 'No. [A-Z].*'))\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nMultinomial Model\r\nTo motivate this model, suppose that each author owns a literal bag of words. When they are writing, they randomly draw each word from the bag, replacing it when they’re done writing it down. Evidently, Alexander Hamilton’s word bag has a lot of the word “upon”.\r\n\r\n\r\ntidy_federalist <- d |> \r\n  # tokenize to the word level\r\n  unnest_tokens(input = 'text',\r\n                output = 'word')\r\n\r\n# keep only a selection of stop words\r\ninteresting_words <- c('although', 'always', \r\n                     'commonly', 'consequently',\r\n                     'considerable', 'heretofore', \r\n                     'upon', 'whilst')\r\n\r\ntidy_federalist <- filter(tidy_federalist,\r\n                          word %in% interesting_words)\r\n\r\nlibrary(wordcloud2)\r\n\r\ntidy_federalist |> \r\n  filter(author == 'Hamilton') |> \r\n  count(word) |> \r\n  wordcloud2()\r\n\r\n\r\n\r\nBy comparison, James Madison’s bag of words has relatively more “whilst”.\r\n\r\n\r\ntidy_federalist |> \r\n  filter(author == 'Madison') |> \r\n  count(word)\r\n\r\n# A tibble: 7 × 2\r\n  word             n\r\n  <chr>        <int>\r\n1 although         8\r\n2 always           7\r\n3 consequently    13\r\n4 considerable     5\r\n5 heretofore       1\r\n6 upon             7\r\n7 whilst          12\r\n\r\nObviously this model leaves out a lot of detail about how authors actually write. It ignores word order, syntax, meaning, context, and intent. But for certain questions, such a simplified model may nevertheless prove useful. Let’s consider Federalist Paper No. 18, counting the frequency of “upon”, “whilst”, and the other interesting stop words listed above.1\r\n\r\n\r\ntidy_federalist |> \r\n  filter(title == 'No. XVIII.') |> \r\n  count(word)\r\n\r\n# A tibble: 4 × 2\r\n  word             n\r\n  <chr>        <int>\r\n1 always           1\r\n2 considerable     1\r\n3 upon             1\r\n4 whilst           1\r\n\r\nWhat’s the likelihood that this set of word counts would have been generated by random draws from Hamilton’s bag of words, compared to Madison’s or Jay’s? (What’s the chance that Hamilton would have written a paper with so few “upon”s?) To estimate, we’ll first compute the word vectors for each author and for the disputed paper.\r\n\r\n\r\n# get the frequencies of the interesting words in each author's corpus\r\nbags_of_words <- tidy_federalist |>\r\n  filter(author %in% c('Hamilton', 'Madison', 'Jay')) |>\r\n  # convert these to factors so count() doesn't drop the zero counts\r\n  mutate(author = factor(author),\r\n         word = factor(word)) |> \r\n  count(author, word, .drop = FALSE) |>\r\n  # sort the words in alphabetical order\r\n  arrange(author, word)\r\n\r\n# pull the vectors for Hamilton, Madison, and Jay\r\nhamilton_vector <- bags_of_words |>\r\n  filter(author == 'Hamilton') |>\r\n  pull(n) |>\r\n  # add names to make the vector more readable\r\n  set_names(interesting_words)\r\n\r\nhamilton_vector\r\n\r\n    although       always     commonly consequently considerable \r\n           1           62           23            4           46 \r\n  heretofore         upon       whilst \r\n          13          374            1 \r\n\r\nmadison_vector <- bags_of_words |>\r\n  filter(author == 'Madison') |>\r\n  pull(n) |>\r\n  # add names to make the vector more readable\r\n  set_names(interesting_words)\r\n\r\nmadison_vector\r\n\r\n    although       always     commonly consequently considerable \r\n           8            7            0           13            5 \r\n  heretofore         upon       whilst \r\n           1            7           12 \r\n\r\njay_vector <- bags_of_words |>\r\n  filter(author == 'Jay') |>\r\n  pull(n) |>\r\n  # add names to make the vector more readable\r\n  set_names(interesting_words)\r\n\r\njay_vector\r\n\r\n    although       always     commonly consequently considerable \r\n           5            8            1            4            1 \r\n  heretofore         upon       whilst \r\n           1            1            0 \r\n\r\n# now get the vector for Federalist No. 18\r\nfed18_vector <- tidy_federalist |>\r\n  mutate(word = factor(word)) |> \r\n  filter(title == 'No. XVIII.') |>\r\n  count(word, .drop = FALSE) |>\r\n  pull(n) |>\r\n  # add names to make the vector more readable\r\n  set_names(interesting_words)\r\n\r\nfed18_vector\r\n\r\n    although       always     commonly consequently considerable \r\n           0            1            0            0            1 \r\n  heretofore         upon       whilst \r\n           0            1            1 \r\n\r\nNext we’ll use the dmultinom() function to estimate the likelihood that the fed18_vector would have been drawn from each of the authors’ bags of words.\r\n\r\n\r\ndmultinom(x = fed18_vector,\r\n          prob = hamilton_vector)\r\n\r\n[1] 0.0003395527\r\n\r\ndmultinom(x = fed18_vector,\r\n          prob = madison_vector)\r\n\r\n[1] 0.008942421\r\n\r\ndmultinom(x = fed18_vector,\r\n          prob = jay_vector)\r\n\r\n[1] 0\r\n\r\nThe computation above makes a very strong assumption about Jay: because he never uses the word “whilst” in any of his Federalist papers, we assume that he would never ever use the word whilst in another paper. We can do better by regularizing our estimates, adding a small positive number to each vector (Laplace smoothing) to encode the possibility that Jay might someday use the word “whilst”, even if we’ve never seen him do it.\r\n\r\n\r\nhamilton_likelihood <- dmultinom(x = fed18_vector,\r\n                                 prob = hamilton_vector + 0.1)\r\n\r\nmadison_likelihood <- dmultinom(x = fed18_vector,\r\n                                prob = madison_vector + 0.1)\r\n\r\njay_likelihood <- dmultinom(x = fed18_vector,\r\n                            prob = jay_vector + 0.1)\r\n\r\n# likelihood ratios\r\nmadison_likelihood / hamilton_likelihood\r\n\r\n[1] 23.90813\r\n\r\nmadison_likelihood / jay_likelihood\r\n\r\n[1] 85.56551\r\n\r\nSince this paper is roughly 24 times more likely to have been generated from Madison’s bag of words over Hamilton’s (and roughly 86 times more likely than Jay’s), we can conclude with some degree of confidence that he was the author.\r\nVector Space Model\r\nAnother way to model the bag of words is to think of each set of word counts as a multidimensional vector. The angle between two such vectors gives us a sense of the two documents’ similarity to one another. If the angle is zero, then both documents have the exact same mix of words (though maybe one document is longer than the other). If the angle is 90 degrees, then the two documents are orthogonal – as different a mix of words as they possibly could be.\r\nCosine similarity captures this idea, because the cosine of 90 degrees is zero, and the cosine of 0 degrees is 1. Let’s compute the cosine similarity between Madison, Hamilton, and Jay’s known writings with the term vector from the disputed Federalist No. 18.\r\n\r\n\r\n# define cosine similarity\r\ncosine_similarity <- function(x1, x2){\r\n  sum(x1*x2) / sqrt(sum(x1^2)) / sqrt(sum(x2^2))\r\n}\r\n\r\n# get the cosine similarity for Federalist 18 with all the authors\r\ncosine_similarity(fed18_vector, hamilton_vector)\r\n\r\n[1] 0.630843\r\n\r\ncosine_similarity(fed18_vector, madison_vector)\r\n\r\n[1] 0.6924889\r\n\r\ncosine_similarity(fed18_vector, jay_vector)\r\n\r\n[1] 0.4789131\r\n\r\nThis yields a similar result to what we found with the multinomial model. The cosine similarity between the disputed paper and Madison’s other papers is largest, suggesting he is the author.\r\nValidation, Validation, Validation\r\nWhenever you develop a method to measure or predict some quantity of interest, it is imperative that you first assess its performance against a known benchmark before applying it to new data. This process is called validation, and Grimmer, Stewart, and Roberts (2021) repeatedly emphasize how central it is to the text-as-data workflow. So the procedure we just created predicts that Madison wrote Federalist No. 18. How much should we trust that prediction?\r\nTo gain confidence in our approach, let’s see what it predicts for papers where authorship is not in dispute. If it correctly predicts the authors of the known texts, then we can be more certain it’s doing a good job with the unknown texts.\r\nFor the validation test, we’ll repeat the same steps as before, except we hold out the validation set when training the model. If we’re trying to predict whether Madison wrote Federalist 10, then it would be cheating to include Federalist 10 in the vector of things we know about Madison’s writing style.\r\n\r\n\r\n# get the Federalist 10 word count vector\r\nfed10_vector <- tidy_federalist |>\r\n  mutate(word = factor(word)) |> \r\n  filter(title == 'No. X.') |>\r\n  count(word, .drop = FALSE) |>\r\n  pull(n) |>\r\n  # add names to make the vector more readable\r\n  set_names(interesting_words)\r\n\r\nfed10_vector\r\n\r\n    although       always     commonly consequently considerable \r\n           0            2            0            1            0 \r\n  heretofore         upon       whilst \r\n           0            0            0 \r\n\r\n# Recompute Madison's word count vector, omitting Federalist 10\r\nmadison_vector <- tidy_federalist |> \r\n  mutate(word = factor(word)) |> \r\n  filter(title != 'No. X.',\r\n         author == 'Madison') |> \r\n  count(word, .drop = FALSE) |> \r\n  pull(n) |> \r\n  set_names(interesting_words)\r\n\r\nmadison_vector\r\n\r\n    although       always     commonly consequently considerable \r\n           8            5            0           12            5 \r\n  heretofore         upon       whilst \r\n           1            7           12 \r\n\r\ndmultinom(x = fed10_vector,\r\n          prob = hamilton_vector)\r\n\r\n[1] 0.0003206053\r\n\r\ndmultinom(x = fed10_vector,\r\n          prob = madison_vector)\r\n\r\n[1] 0.0072\r\n\r\ndmultinom(x = fed10_vector,\r\n          prob = jay_vector)\r\n\r\n[1] 0.08292841\r\n\r\nAlready we can see a problem. The words we chose before may do a good job distinguishing between Hamilton and Madison (it’s inconceivable that Hamilton would have written an entire paper without a single use of the word “upon”, so the model correctly rules him out), but it struggles with distinguishing Jay’s style from Madison’s style, especially for a paper that only contains 3 of the chosen stop words. Because the word “always” appears the most frequently, the model incorrectly predicts that Jay wrote Federalist No. 10, not Madison.\r\nLet’s see if we can find a set of discriminating words that do a better job distinguishing between all three authors.2 To do so, I’ll start with the list of stop words from Mosteller and Wallace (1964) and add in the list of stop words from the tidytext package.\r\n\r\n\r\nmw1964_words <- c(\"a\", \"all\", \"also\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"been\", \"but\", \"by\", \"can\", \"do\", \"down\",\r\n                  \"even\", \"every\", \"for\", \"from\", \"had\", \"has\", \"have\", \"her\", \"his\", \"if\", \"in\", \"into\", \"is\", \"it\", \"its\",\r\n                  \"may\", \"more\", \"must\", \"my\", \"no\", \"not\", \"now\", \"of\", \"on\", \"one\", \"only\", \"or\", \"our\", \"shall\", \"should\",\r\n                  \"so\", \"some\", \"such\", \"than\", \"that\", \"the\", \"their\", \"then\", \"there\", \"things\", \"this\", \"to\", \"up\", \"upon\",\r\n                  \"was\", \"were\", \"what\", \"when\", \"which\", \"who\", \"will\", \"with\", \"would\", \"your\")\r\n\r\nall_stopwords <- union(mw1964_words, get_stopwords()$word)\r\n\r\n\r\nThis yields a list of 186 potential words. Next, we’ll count up how frequently each author used each word, keeping only the words that one author used three times more frequently than another auhor (the number three is arbitrary, but as we’ll see it yields a manageable list of distinctive words).\r\n\r\n\r\ntidy_federalist <- d |>\r\n  # tokenize to the word level\r\n  unnest_tokens(input = 'text',\r\n                output = 'word') |>\r\n  filter(word %in% all_stopwords) |>\r\n  mutate(author = factor(author),\r\n         word = factor(word))\r\n\r\nfrequency_table <- tidy_federalist |>\r\n  filter(author %in% c('Hamilton', 'Jay', 'Madison')) |>\r\n  count(author, word, .drop = FALSE) |>\r\n  pivot_wider(names_from = 'author',\r\n              values_from = 'n') |>\r\n  # normalize by each author's number of words\r\n  mutate(Hamilton = Hamilton / sum(Hamilton),\r\n         Jay = Jay / sum(Jay),\r\n         Madison = Madison / sum(Madison)) |>\r\n  mutate(Hamilton_Jay = Hamilton / Jay,\r\n         Hamilton_Madison = Hamilton / Madison,\r\n         Jay_Madison = Jay / Madison) |>\r\n  # just keep the words that one author uses 3 times more often than another\r\n  filter(Hamilton_Jay > 3 |\r\n           Hamilton_Jay < 0.33333 |\r\n           Hamilton_Madison > 3 |\r\n           Hamilton_Madison < 0.33333 |\r\n           Jay_Madison > 3 |\r\n           Jay_Madison < 0.33333)\r\n\r\n\r\nThis leaves us with 38 words to include in our multinomial model / document vectors.\r\n\r\n\r\ninteresting_words <- factor(frequency_table$word)\r\n\r\ninteresting_words\r\n\r\n [1] about      above      again      also       before     below     \r\n [7] did        down       during     every      further    having    \r\n[13] here       hers       herself    himself    his        how       \r\n[19] itself     me         my         myself     off        ought     \r\n[25] our        ours       ourselves  over       she        theirs    \r\n[31] there      through    up         upon       when       where     \r\n[37] while      whom       yourselves\r\n39 Levels: about above again also before below did down ... yourselves\r\n\r\nLet’s see how the modified list performs on the validation test.\r\n\r\n\r\n# keep only the new list of words\r\ntidy_federalist <-\r\n  tidy_federalist |>\r\n  filter(word %in% interesting_words) |> \r\n  mutate(word = factor(word))\r\n\r\n# compute the new Federalist 10 vector\r\nfed10_vector <- tidy_federalist |>\r\n  filter(title == 'No. X.') |>\r\n  count(word, .drop = FALSE) |>\r\n  pull(n) |>\r\n  # add names to make the vector more readable\r\n  set_names(interesting_words)\r\n\r\nfed10_vector\r\n\r\n     about      above      again       also     before      below \r\n         0          0          2          0          0          0 \r\n       did       down     during      every    further     having \r\n         0          0          0          3          0          1 \r\n      here       hers    herself    himself        his        how \r\n         1          0          0          1          8          0 \r\n    itself         me         my     myself        off      ought \r\n         2          1          0          0          0          2 \r\n       our       ours  ourselves       over        she     theirs \r\n         8          0          0          6          0          0 \r\n     there    through         up       upon       when      where \r\n         6          2          1          0          2          2 \r\n     while       whom yourselves \r\n         0          0          0 \r\n\r\n# get word count vectors for each author\r\nmadison_vector <- tidy_federalist |> \r\n  filter(title != 'No. X.',\r\n         author == 'Madison') |> \r\n  count(word, .drop = FALSE) |> \r\n  pull(n) |> \r\n  set_names(interesting_words)\r\n\r\nmadison_vector\r\n\r\n     about      above      again       also     before      below \r\n         1          2         11         31         13          2 \r\n       did       down     during      every    further     having \r\n         3          3         11         91         18          7 \r\n      here       hers    herself    himself        his        how \r\n        23          1          2          6         49         13 \r\n    itself         me         my     myself        off      ought \r\n        27          3          4          4          1         59 \r\n       our       ours  ourselves       over        she     theirs \r\n        41          0          3         37          3          2 \r\n     there    through         up       upon       when      where \r\n        29          6          2          7         20         35 \r\n     while       whom yourselves \r\n         0          9          0 \r\n\r\nhamilton_vector <- tidy_federalist |> \r\n  filter(author == 'Hamilton') |> \r\n  count(word, .drop = FALSE) |> \r\n  pull(n) |> \r\n  set_names(interesting_words)\r\n\r\nhamilton_vector\r\n\r\n     about      above      again       also     before      below \r\n        20          5          5         36         31          2 \r\n       did       down     during      every    further     having \r\n        12         14         17        179         33         32 \r\n      here       hers    herself    himself        his        how \r\n        33          0          5         34        239         53 \r\n    itself         me         my     myself        off      ought \r\n        81         15         39         15          3        159 \r\n       our       ours  ourselves       over        she     theirs \r\n       191          7         21         65         16          1 \r\n     there    through         up       upon       when      where \r\n       379         27         34        374        110         86 \r\n     while       whom yourselves \r\n        36         34          0 \r\n\r\njay_vector <- tidy_federalist |> \r\n  filter(author == 'Jay') |> \r\n  count(word, .drop = FALSE) |> \r\n  pull(n) |> \r\n  set_names(interesting_words)\r\n\r\njay_vector\r\n\r\n     about      above      again       also     before      below \r\n         0          2          1         11          0          0 \r\n       did       down     during      every    further     having \r\n         6          0          0          5          0          5 \r\n      here       hers    herself    himself        his        how \r\n         1          0          0          0          5          9 \r\n    itself         me         my     myself        off      ought \r\n         1          3          3          0          1          2 \r\n       our       ours  ourselves       over        she     theirs \r\n        38          0          3          2          4          1 \r\n     there    through         up       upon       when      where \r\n        10          0          0          1         15          2 \r\n     while       whom yourselves \r\n         2         10          1 \r\n\r\ndmultinom(x = fed10_vector,\r\n          prob = madison_vector + 0.1) /\r\ndmultinom(x = fed10_vector,\r\n          prob = hamilton_vector + 0.1) \r\n\r\n[1] 76.72475\r\n\r\ndmultinom(x = fed10_vector,\r\n          prob = madison_vector + 0.1) /\r\ndmultinom(x = fed10_vector,\r\n          prob = jay_vector + 0.1)\r\n\r\n[1] 1.164301e+12\r\n\r\ncosine_similarity(madison_vector, fed10_vector)\r\n\r\n[1] 0.7437931\r\n\r\ncosine_similarity(hamilton_vector, fed10_vector)\r\n\r\n[1] 0.7210126\r\n\r\ncosine_similarity(jay_vector, fed10_vector)\r\n\r\n[1] 0.6583766\r\n\r\nThis is much nicer. Both methods now correctly identify Madison as the author of Federalist 10. A more thorough model-development loop might iterate through validation and refinement a few more times, holding out a different validation set each time. But this is the basic workflow.\r\nPractice Problems\r\nConduct more validation tests on undisputed Federalist Papers to see if the list of words we came up with in the last section does a good job.\r\nSee if you can create a model that accurately classifies whether a State of the Union speech was delivered in the 19th or 20th century.\r\n\r\n\r\n\r\nGrimmer, Justin, Brandon M. Stewart, and Margaret E. Roberts. 2021. Text as Data: A New Framework for Machine Learning and the Social Sciences. S.l.: Princeton University Press.\r\n\r\n\r\nImai, Kosuke. 2017. Quantitative Social Science: An Introduction. Princeton: Princeton University Press.\r\n\r\n\r\nMosteller, Frederick, and David L. Wallace. 1964. Inference and Disputed Authorship: The Federalist. Addison-Wesley.\r\n\r\n\r\nThis list was inspired by Chapter 5 of Imai (2017). More on how to identify discriminating words in a later section.↩︎\r\nSee Grimmer, Stewart, and Roberts (2021) Chapter 11 for more on this process.↩︎\r\n",
      "last_modified": "2025-06-13T13:59:08-04:00"
    },
    {
      "path": "index.html",
      "title": "Text As Data",
      "description": "A course on analyzing political texts using the `R` programming language\n",
      "author": [
        {
          "name": "Joe Ornstein",
          "url": "https://joeornstein.github.io/"
        }
      ],
      "date": "`r Sys.Date()`",
      "contents": "\r\n\r\nContents\r\nOverview\r\n\r\nOverview\r\nThis site is intended to serve as a companion to Grimmer, Stewart, and Roberts (2021), an excellent book on how to think about text as data, which makes a deliberate choice to omit code when describing their examples.1 Thus the need for this R code supplement, which was developed during my Summer 2022 graduate-level Text As Data course at the University of Georgia. All the code and data necessary to replicate the results on this site are available at the GitHub link on the upper right.\r\nThe site is divided into three sections, corresponding to the three stages of any text-as-data workflow:\r\nHarvest the Text: How to carefully choose what texts to include in your corpus, and how to get them from some messy format like HTML or PDF into a plaintext dataframe.\r\nTidy the Text: How to represent large amounts of text quantitatively, and what choices you need to make during the preprocessing stage.\r\nModel the Text: How to build a model to meet your objective, be it prediction, classification, causal inference, or exploration.\r\nFor each stage in the workflow, there are a number of useful R packages that can help accomplish these tasks, including webscraping (rvest), optical character recognition (tesseract), tidying (tidytext), topic modeling (topicmodels), sentiment analysis (sentimentR), and many others. On this site, we will walk through several tutorials of these packages – motivated by political science applications – with links to more detailed documentation for those interested in exploring further.\r\n\r\n\r\n\r\nGrimmer, Justin, Brandon M. Stewart, and Margaret E. Roberts. 2021. Text as Data: A New Framework for Machine Learning and the Social Sciences. S.l.: Princeton University Press.\r\n\r\n\r\nWisely, in my view, as books with code can quickly become dated.↩︎\r\n",
      "last_modified": "2025-06-13T13:59:10-04:00"
    },
    {
      "path": "LDA.html",
      "title": "Topic Models",
      "description": "A bag filled with bags of words.\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nIntuition\r\nStep 1: Load the Documents and Tidy Up\r\nStep 2: Convert to a Document-Term Matrix\r\nStep 3: Fit the Model\r\nStep 4: Interpret the Topic-Level Probability Vectors\r\nStep 5: Interpret the Document-Level Probability Vectors\r\nPractice Problems\r\nFurther Reading\r\n\r\nIntuition\r\nThe workhorse model for assigning topics to texts is the Latent Dirichlet Allocation (LDA), which is a sort of mix between the bag of words model and clustering. I like to think of it as a “bag of bags of words”. Imagine that, rather than drawing from a single bag of words, authors first draw a topic, which has its own special bag of words. This approach is particularly useful when we think that a document may be about more than one topic, and we don’t want to impose just one classification for each text like we do with k-means.\r\nTo demonstrate the workflow in R, let’s take the set of Senator Lautenberg’s press releases from the clustering tutorial and fit an LDA using the topicmodels package.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(tidytext)\r\nlibrary(topicmodels)\r\nlibrary(SnowballC)\r\n\r\n\r\nStep 1: Load the Documents and Tidy Up\r\n\r\n\r\nload('data/press-releases/lautenberg-press-releases.RData')\r\n\r\n\r\ntidy_press_releases <- df |>\r\n  # remove a common preamble to each press release\r\n  mutate(text = str_replace_all(text,\r\n                                pattern = '     Senator Frank R  Lautenberg                                                                                                                      Press Release        of        Senator Lautenberg                                                                                ',\r\n                                replacement = '')) |>\r\n  # tokenize to the word level\r\n  unnest_tokens(input = 'text',\r\n                output = 'word') |>\r\n  # remove stop words\r\n  anti_join(get_stopwords()) |>\r\n  # remove numerals\r\n  filter(str_detect(word, '[0-9]', negate = TRUE)) |>\r\n  # generate word stems\r\n  mutate(word_stem = wordStem(word)) |>\r\n  # count up the word stems in each document\r\n  count(id, word_stem) |> \r\n  # remove empty strings\r\n  filter(word_stem != '')\r\n\r\nhead(tidy_press_releases)\r\n\r\n# A tibble: 6 × 3\r\n     id word_stem     n\r\n  <int> <chr>     <int>\r\n1     1 account       2\r\n2     1 also          2\r\n3     1 america       2\r\n4     1 american      1\r\n5     1 answer        1\r\n6     1 apologi       1\r\n\r\nStep 2: Convert to a Document-Term Matrix\r\nNote LDA requires a matrix of counts, just like the multinomial bag of words model.\r\n\r\n\r\nlautenberg_dtm <- cast_dtm(data = tidy_press_releases,\r\n                           document = 'id',\r\n                           term = 'word_stem',\r\n                           value = 'n')\r\nlautenberg_dtm\r\n\r\n<<DocumentTermMatrix (documents: 558, terms: 7073)>>\r\nNon-/sparse entries: 81504/3865230\r\nSparsity           : 98%\r\nMaximal term length: 33\r\nWeighting          : term frequency (tf)\r\n\r\nStep 3: Fit the Model\r\nFitting an LDA is just one line of code. It’s the interpretation, evaluation, and refinement that’s the tricky part.\r\n\r\n\r\nlautenberg_lda <- LDA(lautenberg_dtm, \r\n                      k = 30, \r\n                      control = list(seed = 42))\r\n\r\n\r\nStep 4: Interpret the Topic-Level Probability Vectors\r\nLet’s look at the most common terms by topic.\r\n\r\n\r\n# use the tidy() function from tidytext to extract the beta vector\r\nlautenberg_topics <- tidy(lautenberg_lda, matrix = 'beta')\r\n\r\nlautenberg_topics |>\r\n  group_by(topic) |>\r\n  slice_max(beta, n=10) |>\r\n  arrange(topic, -beta)\r\n\r\n# A tibble: 300 × 3\r\n# Groups:   topic [30]\r\n   topic term         beta\r\n   <int> <chr>       <dbl>\r\n 1     1 program    0.0203\r\n 2     1 grant      0.0194\r\n 3     1 lautenberg 0.0144\r\n 4     1 safeti     0.0143\r\n 5     1 d          0.0136\r\n 6     1 educ       0.0127\r\n 7     1 school     0.0117\r\n 8     1 nj         0.0115\r\n 9     1 fund       0.0112\r\n10     1 provid     0.0110\r\n# ℹ 290 more rows\r\n\r\nSurprise, surprise. The most common term in each topic is often “Lautenberg”. Instead of looking at the terms with the highest probability in each bag, let’s look at the terms that are the most over-represented, compared to their probability in the average topic.\r\n\r\n\r\nlautenberg_topics |>\r\n  # get each word's average beta across topics\r\n  group_by(term) |>\r\n  mutate(average_beta = mean(beta)) |>\r\n  ungroup() |>\r\n  # compare beta in that topic with the average beta\r\n  mutate(delta = beta - average_beta) |>\r\n  # get the words with the largest difference in each topic\r\n  group_by(topic) |>\r\n  slice_max(delta, n = 10) |>\r\n  # plot it\r\n  ggplot(mapping = aes(x=delta, y=reorder(term, delta))) +\r\n  geom_col() +\r\n  theme_minimal() +\r\n  facet_wrap(~topic, scales = 'free') +\r\n  labs(x = 'Term Probability Compared to Average',\r\n       y = 'Term')\r\n\r\n\r\n\r\nTopics 6 and 9 appear to involve words related to transportation infrastructure, while topics 2, 5, 8, 17, 21, 23, 27, and 30 appear to be about security, the miltary, and foreign affairs. Topics 3, 7, 10, 13, 15, 19, 24, and 26 are all related to the environment. This all seems consistent with Senator Lautenberg’s work as chairman of the Senate subcommittees on Homeland Security, Surface Transportation Security, and Superfund, Toxics, and Environmental Health – which should give us some confidence in the results. Topics 28 and 29 look like the “partisan taunting” category identified in the book.\r\nStep 5: Interpret the Document-Level Probability Vectors\r\nIf these are roughly how we would categorize each topic…\r\n\r\n\r\ntopic_labels <- tribble(~topic, ~label,\r\n                        1, 'Programs',\r\n                        2, 'Military',\r\n                        3, 'Environment',\r\n                        4, 'Health',\r\n                        5, 'Security',\r\n                        6, 'Transportation',\r\n                        7, 'Environment',\r\n                        8, 'Security',\r\n                        9, 'Transportation',\r\n                        10, 'Environment',\r\n                        11, 'Crime and Courts',\r\n                        12, 'Health',\r\n                        13, 'Environment',\r\n                        14, 'Programs',\r\n                        15, 'Environment',\r\n                        16, 'Health',\r\n                        17, 'Military',\r\n                        18, 'Health',\r\n                        19, 'Environment',\r\n                        20, 'Health',\r\n                        21, 'Military',\r\n                        22, 'Crime and Courts',\r\n                        23, 'Oil',\r\n                        24, 'Environment',\r\n                        25, 'New Jersey',\r\n                        26, 'Environment',\r\n                        27, 'Security',\r\n                        28, 'Partisan Taunting',\r\n                        29, 'Partisan Taunting',\r\n                        30, 'Security')\r\n\r\n\r\n…then here’s what the breakdown in topics across the 558 press releases looks like.\r\n\r\n\r\nlautenberg_documents <- tidy(lautenberg_lda, matrix = 'gamma')\r\n\r\nlautenberg_documents |> \r\n  # join with topic labels\r\n  mutate(document = as.numeric(document)) |>\r\n  left_join(topic_labels, by = 'topic') |> \r\n  # get the most probable document labels\r\n  filter(gamma > 0.3) |> \r\n  arrange(document, -gamma) |> \r\n  head(20)\r\n\r\n# A tibble: 20 × 4\r\n   document topic gamma label            \r\n      <dbl> <dbl> <dbl> <chr>            \r\n 1        1    22 0.999 Crime and Courts \r\n 2        2    18 0.999 Health           \r\n 3        3    23 0.999 Oil              \r\n 4        4     7 0.976 Environment      \r\n 5        5    11 0.693 Crime and Courts \r\n 6        5    29 0.302 Partisan Taunting\r\n 7        6    26 0.912 Environment      \r\n 8        7     6 0.936 Transportation   \r\n 9        8    11 0.897 Crime and Courts \r\n10        9    16 0.991 Health           \r\n11       10    18 0.996 Health           \r\n12       11    13 0.520 Environment      \r\n13       11    17 0.382 Military         \r\n14       12    10 0.477 Environment      \r\n15       12     7 0.363 Environment      \r\n16       13     9 0.403 Transportation   \r\n17       13     6 0.318 Transportation   \r\n18       14    24 0.705 Environment      \r\n19       15    27 0.999 Security         \r\n20       16    21 0.998 Military         \r\n\r\nDocument 1 should be about Crime/Courts.\r\n\r\n\r\nprint_text <- function(text){\r\n  cat(str_wrap(text), sep = '\\n')\r\n}\r\n\r\nprint_text(df$text[1])\r\n\r\nSenator Frank R Lautenberg Press Release of Senator Lautenberg Lautenberg Cites\r\nCriminal Laws DeLay May Have Broken in Threat Against Federal Judges Friday\r\nApril 1 2005 WASHINGTON DC Responding to possible violations of criminal law\r\nby House Majority Leader Tom DeLay when he directed threatening remarks toward\r\nfederal judges involved in the Terri Schiavo case Untied Stated Senator Frank R\r\nLautenberg today called on Mr DeLay to renounce his comments In a letter to Mr\r\nDeLay Senator Lautenberg said the remarks could incite violence against judges\r\nand noted that federal statutes provide for prison terms up to six years for\r\nthreatening members of the court Threats against specific Federal judges are\r\nnot only a serious crime but also beneath a Member of Congress In my view the\r\ntrue measure of democracy is how it dispenses justice Your attempt to intimidate\r\njudges in America not only threatens our courts but our fundamental democracy\r\nas well wrote Lautenberg in his letter to Mr DeLay Majority Leader DeLay s\r\ncomments yesterday may violate a Federal criminal statute 18 U S C 115 a 1 B\r\nThat law states Whoever threatens to assault or murder a United States judge\r\nwith intent to retaliate against such judge on account of the performance of\r\nofficial duties shall be punished by up to six years in prison A copy of the\r\nentire letter is attached to this release April 1 2005 Tom DeLay Majority Leader\r\nHouse of Representatives Washington DC 20515 Dear Majority Leader DeLay I was\r\nstunned to read the threatening comments you made yesterday against Federal\r\njudges and our nation s courts of law in general In reference to certain Federal\r\njudges you stated The time will come for the men responsible for this to answer\r\nfor their behavior As you are surely aware the family of Federal Judge Joan H\r\nLefkow of Illinois was recently murdered in their home And at the state level\r\nJudge Rowland W Barnes and others in his courtroom were gunned down in Georgia\r\nOur nation s judges must be concerned for their safety and security when they\r\nare asked to make difficult decisions every day That s why comments like those\r\nyou made are not only irresponsible but downright dangerous To make matters\r\nworse is it appropriate to make threats directed at specific Federal and state\r\njudges You should be aware that your comments yesterday may violate a Federal\r\ncriminal statute 18 U S C 115 a 1 B That law states Whoever threatens to\r\nassault or murder a United States judge with intent to retaliate against such\r\njudge on account of the performance of official duties shall be punished by up\r\nto six years in prison Threats against specific Federal judges are not only a\r\nserious crime but also beneath a Member of Congress In my view the true measure\r\nof democracy is how it dispenses justice Your attempt to intimidate judges in\r\nAmerica not only threatens our courts but our fundamental democracy as well\r\nFederal judges as well as state and local judges in our nation are honorable\r\npublic servants who make difficult decisions every day You owe them and all\r\nAmericans an apology for your reckless statements Sincerely Frank R Lautenberg\r\nQuestions or Comments\r\n\r\nDocument 2 should be about Health.\r\n\r\n\r\nprint_text(df$text[2])\r\n\r\nSenator Frank R Lautenberg Press Release of Senator Lautenberg Sens Lautenberg\r\nand Menendez Lead Defeat of Amendment Specifically Targeting NJ s Children\r\nHealth Coverage Bunning Amendment Would Cast Thousands of NJ Children Into The\r\nRanks of The Uninsured Contact Press Office 202 224 3224 Wednesday August 1 2007\r\nWASHINGTON New Jersey Senators Frank R Lautenberg D NJ and Robert Menendez D NJ\r\nled the effort that tonight resulted in the defeat of an amendment specifically\r\ntargeting childrens health insurance in New Jersey The Bunning amendment to\r\nthe Childrens Health Insurance Program CHIP reauthorization bill was tabled by\r\na 53 43 vote The amendment was a direct shot at New Jerseys FamilyCare program\r\nwhich covers children from families that make up to 350 of the federal poverty\r\nlevel working and low income families that dont qualify for Medicaid but cannot\r\nafford health insurance in a high cost of living state like New Jersey Had\r\nthe amendment passed only children in New Jersey would have been immediately\r\naffected Lautenberg and Menendez helped persuade colleagues to oppose the\r\namendment and spoke vehemently in opposition Today the U S Senate defeated an\r\nattack on the health of New Jerseys children said Lautenberg We stood strong\r\nagainst right wing efforts to take away the health insurance of 3 000 children\r\nin New Jersey This vote means we can continue to provide quality affordable\r\nhealth care to children in New Jersey and nationwide This was a rifle shot at\r\nNew Jersey and we worked hard to make our colleagues understand what it meant\r\nfor our states children and why it had to be deflected said Menendez Without\r\nthis level of coverage thousands of New Jersey children would have been dropped\r\ninto the ocean of the uninsured Throughout the debate on this bill we have\r\nbeen repeatedly confronted with amendments attacking coverage for children and\r\nfamilies in New Jersey and we have repeatedly held our ground and rejected them\r\nTodays action brings us one step closer to a major victory for working and low\r\nincome children and families in our state Among the amendments offered to this\r\npoint during Senate debate of CHIP three in particular have taken aim at New\r\nJerseys strong health coverage program and all three have been defeated Bunning\r\nAmendment Motion to Table Passed 53 43 This amendment would have reduced the\r\nreimbursement rate for CHIP covered children above 300 of poverty in all states\r\nto the Medicaid matching rate including states that already cover these kids\r\nunder CHIP Only New Jersey has an eligibility level above 300 now in effect New\r\nYork has enacted legislation increasing its eligibility to 400 but has not yet\r\ngotten approval from the Secretary of HHS for its state plan amendment to make\r\nthe change This amendment unfairly targeted a small percentage of CHIP covered\r\nchildren in New Jersey This amendment would have pushed 3 000 New Jersey kids\r\noff the CHIP program Gregg Amendment Failed 42 53 This amendment would have\r\npushed all parents covered under CHIP into Medicaid Over 80 000 parents would\r\nhave lost coverage in NJ Allard Amendment Failed 37 59 The amendment would\r\nhave disallowed states from using any type of income disregards to determine\r\neligibility in CHIP Under current law states are permitted to disregard types\r\nof income or blocks of income and most states use this flexibility to disregard\r\nwages child support payments and child care expenses to enable working families\r\nto earn a living wage and still be eligible for CHIP This amendment would have\r\ndisrupted NJs ability to enroll children at a higher income level in CHIP It\r\nwould have prevented us from covering kids above 200 of the federal poverty\r\nlevel and would have jeopardized coverage for over 30 000 New Jersey children\r\nQuestions or Comments\r\n\r\nDocument 5 seems to be some combination of Crime/Courts and Partisan Taunting.\r\n\r\n\r\nprint_text(df$text[5])\r\n\r\nSenator Frank R Lautenberg Press Release of Senator Lautenberg Statement by\r\nSenator Lautenberg on the Retirement of Justice Sandra Day O Connor Friday\r\nJuly 1 2005 WASHINGTON D C United States Senator Frank R Lautenberg issued\r\nthe following statement today regarding the retirement of Justice Sandra\r\nDay O Connor Justice O Connor has earned a place in history not only as the\r\nfirst woman to serve on the Supreme Court but also as an independent thinker\r\nwho avoided extreme positions The American people want fair moderate judges\r\nprotecting our rights and I strongly urge President Bush to send us a nominee\r\nwho reflects mainstream legal views not partisan extremes Questions or Comments\r\n\r\nNot bad! It’s a press release that is mostly honoring Sandra Day O’Connor, but the last sentence is a dig at President Bush.\r\nPractice Problems\r\nFit an LDA to the Federalist Paper corpus (instead of focusing on stop words as in the authorship prediction task, I’d advice removing stop words and focusing on the substantive terms). What sorts of topics does the model produce? What value of \\(k\\) yields the most sensible set of topics?\r\nFit an LDA to the UN Security Council speeches about Afghanistan (Schoenfeld et al. 2018), available at data/un-security-council/UNSC_Afghan_Spchs_Meta.RData on the repository.\r\nFurther Reading\r\nGrimmer, Stewart, and Roberts (2021) Chapter 13\r\nText Ming With R Chapter 6\r\nFor a principled procedure for varying \\(k\\) to identify the best set of topics, see Wilkerson and Casas (2017) .\r\n\r\n\r\n\r\nGrimmer, Justin, Brandon M. Stewart, and Margaret E. Roberts. 2021. Text as Data: A New Framework for Machine Learning and the Social Sciences. S.l.: Princeton University Press.\r\n\r\n\r\nSchoenfeld, Mirco, Steffen Eckhard, Ronny Patz, and Hilde van Meegdenburg. 2018. “Discursive Landscapes and Unsupervised Topic Modeling in IR: A Validation of Text-as-Data Approaches Through a New Corpus of UN Security Council Speeches on Afghanistan.” https://doi.org/10.48550/arXiv.1810.05572.\r\n\r\n\r\nWilkerson, John, and Andreu Casas. 2017. “Large-Scale Computerized Text Analysis in Political Science: Opportunities and Challenges.” Annual Review of Political Science 20 (1): 529–44. https://doi.org/10.1146/annurev-polisci-052615-025542.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-06-13T13:59:23-04:00"
    },
    {
      "path": "LLMs.html",
      "title": "Large Language Models",
      "description": "A dumb auto-complete model -- trained on the entire Internet -- can accomplish a remarkable number of tasks if you ask it nicely.\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nSetting Up The promptr Package\r\nCompleting Prompts\r\nFormatting Prompts\r\nClassifying Documents\r\nClassifiation Performance\r\nCleaning Up OCR\r\nText To Data\r\nPractice Problems\r\n\r\nLarge language models (LLMs) have transformed the way computer scientists approach natural language processing over the past decade. These models, trained to predict the next word in a sequence, make use of a massive quantity of text data from the Internet and digitized books. In this tutorial, I will hand-wave over exactly how LLMs perform this task, focusing instead on how to adapt such models for use in social science applications. If you are interested in what’s going on under the hood, I highly recommend the following two blog posts for not-too-technical introductions:\r\nThe GPT-3 Architecture, on a Napkin\r\nLarge language models, explained with a minimum of math and jargon\r\nIn a nutshell, LLMs represent words using embeddings, and are trained to predict the most likely next word in a sequence using a model architecture called the transformer (Vaswani et al. 2017). A powerful feature of this type of model is that the embeddings representing the input sequence are iteratively updated based on which words appear nearby (a process called self-attention). This allows an LLM to flexibly represent words based on their context, which is useful in cases where the same word can mean different things in different contexts. For example, an LLM will represent the word “bill” differently depending on whether it appears in the phrase “sign the bill”, “foot the bill”, or “Hillary and Bill”.\r\nWhat’s remarkable is that if we have a model that is sufficiently good at predicting the next word in a sequence, we can adapt it to perform all sorts of text-as-data tasks, by creating a prompt that converts our desired task into a next-word prediction problem (Ornstein, Blasingame, and Truscott 2025). To show you how, we will use my promptr R package to create LLM prompts and submit them to OpenAI’s language models.1 Let’s start by getting the R package set up.\r\nSetting Up The promptr Package\r\nThe package is currently available on CRAN. You can install with the following line of code:\r\n\r\n\r\ninstall.packages('promptr')\r\n\r\n\r\nNext, you will need an account with OpenAI. You can sign up for one here, after which you will need to generate an API key here. I recommend adding this API key as a variable in your operating system environment called OPENAI_API_KEY; that way you won’t risk leaking it by hard-coding it into your R scripts. The promptr package will automatically look for your API key under that variable name, and will prompt you to enter the API key manually if it can’t find one there. The easiest way to do so is by copy-pasting your API key into the following line of code:\r\npromptr::openai_api_key('<YOUR KEY GOES HERE>', install = TRUE)\r\nOnce you’ve done this you may need to restart your R session. Once you’ve done that, we can begin.\r\nCompleting Prompts\r\nThe workhorse function of the promptr package is complete_prompt(). This function submits a sequence of words (the prompt) to the OpenAI API, and returns a dataframe with the five highest-probability next word predictions and their associated probabilities.2\r\n\r\n\r\nlibrary(promptr)\r\n\r\ncomplete_prompt(prompt = 'My favorite food is')\r\n\r\n\r\n\r\n\r\n\r\n\r\n  token probability\r\n1 pizza  0.21228811\r\n2 sushi  0.04108451\r\n3 pasta  0.03349724\r\n4        0.02689665\r\n5     a  0.02677079\r\n\r\nIf you prefer the model to auto-regressively generate sequences of text instead of outputting the next-word probabilities, set the max_tokens argument greater than 1. The function will return a character object with the most likely completion at each point in the sequence.\r\n\r\n\r\n\r\n\r\n\r\ncomplete_prompt(prompt = 'My favorite food is', \r\n                max_tokens = 6)\r\n\r\n\r\n\r\n[1] \" pizza. I love the combination\"\r\n\r\nIf we want thr LLM to perform a classification task, we can structure the prompt so that the best next-word prediction is the classification we want (a process called adaptation). Consider, for example, the following prompt.\r\n\r\n\r\nprompt <- 'Decide whether the following statement is happy, sad, or neither.\\n\\nText: I feel happy.\\nClassification:'\r\n\r\ncat(prompt)\r\n\r\nDecide whether the following statement is happy, sad, or neither.\r\n\r\nText: I feel happy.\r\nClassification:\r\n\r\n\r\n\r\ncomplete_prompt(prompt)\r\n\r\n\r\n\r\n\r\n\r\n\r\n  token probability\r\n1 Happy  0.43092548\r\n2 happy  0.36317128\r\n3        0.12109015\r\n4 Happy  0.03856193\r\n5 happy  0.01665111\r\n\r\nThe result is a probability vector with the most likely completions. The correct classification – happy – is assigned the highest probability, though note that some post-processing is necessary to combine the “happy” and “Happy” responses.\r\nA few-shot prompt includes several completed examples in the text of the prompt to demonstrate the desired output. Prompts structured this way tend perform significantly better than zero-shot prompts with no examples (Brown et al. 2020).\r\n\r\n\r\nprompt <- 'Decide whether the following statement is happy, sad, or neither.\\n\\nText: What should we do today?.\\nClassification: Neither\\n\\nText: My puppy is so cute today.\\nClassification: Happy\\n\\nText: The news is bumming me out.\\nClassification: Sad\\n\\nText: I feel happy.\\nClassification:'\r\n\r\ncat(prompt)\r\n\r\nDecide whether the following statement is happy, sad, or neither.\r\n\r\nText: What should we do today?.\r\nClassification: Neither\r\n\r\nText: My puppy is so cute today.\r\nClassification: Happy\r\n\r\nText: The news is bumming me out.\r\nClassification: Sad\r\n\r\nText: I feel happy.\r\nClassification:\r\n\r\n\r\n\r\ncomplete_prompt(prompt)\r\n\r\n\r\n\r\n\r\n\r\n\r\n      token  probability\r\n1     Happy 0.9878519141\r\n2     Happy 0.0089504721\r\n3   Neither 0.0015561093\r\n4     happy 0.0003720904\r\n5 Happiness 0.0002116472\r\n\r\nFormatting Prompts\r\nManually typing prompts with multiple few-shot examples can be tedious and error-prone, particularly when performing the sort of context-specific prompting we recommend in our paper (Ornstein, Blasingame, and Truscott 2025). The format_prompt() function is a useful tool to aid in that process.\r\nThe function is designed with classification problems in mind. If you input the text you would like to classify along with a set of instructions, the default prompt template looks like this:\r\n\r\n\r\nlibrary(promptr)\r\n\r\nformat_prompt(text = 'I am feeling happy today.',\r\n              instructions = 'Decide whether this statment is happy, sad, or neither.')\r\n\r\nDecide whether this statment is happy, sad, or neither.\r\n\r\nText: I am feeling happy today.\r\nClassification:\r\n\r\nYou can customize the template using glue syntax, with placeholders for the text you want to classify {text} and the desired label {label}.\r\n\r\n\r\nformat_prompt(text = 'I am feeling happy today.',\r\n              instructions = 'Decide whether this statment is happy or sad.',\r\n              template = 'Statement: {text}\\nSentiment: {label}')\r\n\r\nDecide whether this statment is happy or sad.\r\n\r\nStatement: I am feeling happy today.\r\nSentiment:\r\n\r\nThis is particularly useful when including few-shot examples in the prompt. If you input these examples as a tidy dataframe with the columns text and label, the format_prompt() function will paste them into the prompt them according to the template. To illustrate, let’s classify the sentiment of a set of tweets about the Supreme Court of the United States, a dataset which is included with the promptr package.\r\nClassifying Documents\r\n\r\n\r\ndata(scotus_tweets) # the full dataset\r\ndata(scotus_tweets_examples) # a sample of labeled examples\r\n\r\n\r\nWe can format our few-shot prompt template using format_prompt(), leaving the {TWEET} placeholder for the text we want to classify:\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(glue)\r\n\r\nprompt <- format_prompt(text = '{TWEET}',\r\n              instructions = 'Classify the sentiment of these tweets as Positive, Neutral, or Negative.',\r\n              examples = scotus_tweets_examples |> \r\n                filter(case == 'masterpiece'),\r\n              template = 'Tweet: {text}\\nSentiment: {label}')\r\n\r\nprompt\r\n\r\nClassify the sentiment of these tweets as Positive, Neutral, or Negative.\r\n\r\nTweet: Thank you Supreme Court I take pride in your decision!!!!✝️ #SCOTUS\r\nSentiment: Positive\r\n\r\nTweet: Supreme Court rules in favor of Colorado baker! This day is getting better by the minute!\r\nSentiment: Positive\r\n\r\nTweet: Can’t escape the awful irony of someone allowed to use religion to discriminate against people in love. \r\nNot my Jesus. \r\n#opentoall #SCOTUS #Hypocrisy #MasterpieceCakeshop\r\nSentiment: Negative\r\n\r\nTweet: I can’t believe this cake case went all the way to #SCOTUS . Can someone let me know what cake was ultimately served at the wedding? Are they married and living happily ever after?\r\nSentiment: Neutral\r\n\r\nTweet: Supreme Court rules in favor of baker who would not make wedding cake for gay couple\r\nSentiment: Neutral\r\n\r\nTweet: #SCOTUS set a dangerous precedent today. Although the Court limited the scope to which a business owner could deny services to patrons, the legal argument has been legitimized that one's subjective religious convictions trump (no pun intended) #humanrights. #LGBTQRights\r\nSentiment: Negative\r\n\r\nTweet: {TWEET}\r\nSentiment:\r\n\r\nUsing the glue() function, we can insert tweets into that template.\r\n\r\n\r\nTWEET <- scotus_tweets$text[42]\r\nTWEET\r\n\r\n[1] \"This Supreme Court ruling highlights why there needs to be term limits for scotus, healthcare needs to uncoupled from employment, Christianity brings nothing but evil but, most importantly it shows you why voting at every level matters\"\r\n\r\nglue(prompt)\r\n\r\nClassify the sentiment of these tweets as Positive, Neutral, or Negative.\r\n\r\nTweet: Thank you Supreme Court I take pride in your decision!!!!✝️ #SCOTUS\r\nSentiment: Positive\r\n\r\nTweet: Supreme Court rules in favor of Colorado baker! This day is getting better by the minute!\r\nSentiment: Positive\r\n\r\nTweet: Can’t escape the awful irony of someone allowed to use religion to discriminate against people in love. \r\nNot my Jesus. \r\n#opentoall #SCOTUS #Hypocrisy #MasterpieceCakeshop\r\nSentiment: Negative\r\n\r\nTweet: I can’t believe this cake case went all the way to #SCOTUS . Can someone let me know what cake was ultimately served at the wedding? Are they married and living happily ever after?\r\nSentiment: Neutral\r\n\r\nTweet: Supreme Court rules in favor of baker who would not make wedding cake for gay couple\r\nSentiment: Neutral\r\n\r\nTweet: #SCOTUS set a dangerous precedent today. Although the Court limited the scope to which a business owner could deny services to patrons, the legal argument has been legitimized that one's subjective religious convictions trump (no pun intended) #humanrights. #LGBTQRights\r\nSentiment: Negative\r\n\r\nTweet: This Supreme Court ruling highlights why there needs to be term limits for scotus, healthcare needs to uncoupled from employment, Christianity brings nothing but evil but, most importantly it shows you why voting at every level matters\r\nSentiment:\r\n\r\nWe can then pipe that prompt into complete_prompt() to output the desired classification:\r\n\r\n\r\nprompt |> \r\n  glue() |> \r\n  complete_prompt()\r\n\r\n\r\n\r\n\r\n\r\n\r\n     token  probability\r\n1 Negative 0.9034858269\r\n2  Neutral 0.0913403445\r\n3 Positive 0.0022436775\r\n4 Negative 0.0020078616\r\n5  Neutral 0.0005211055\r\n\r\nClassifiation Performance\r\nAs we saw in the sentiment analysis tutorial, conventional methods for classifying sentiment perform pretty poorly on text from social media. Does this approach perform any better? To find out, let’s complete the prompt for each of the tweets in the scotus_tweets dataframe related to the Masterpiece Cakeshop ruling, create a measure of sentiment, and compare it against the human coders.\r\nFirst, create our prompt template with format_prompt(), this time with a bit more detail in the instructions. For few-shot examples, we’ll use the ‘masterpiece’ tweets in scotus_tweets_examples. These are six tweets that were unanimously coded by three human annotators as Positive, Negative, or Neutral (two per category).\r\n\r\n\r\nprompt <- format_prompt(text = '{TWEET}',\r\n              instructions = 'Read these tweets posted the day after the US Supreme Court ruled in \r\n              favor of a baker who refused to bake a wedding cake for a same-sex couple. \r\n              For each tweet, decide whether its sentiment is Positive, Neutral, or Negative.',\r\n              examples = scotus_tweets_examples |> \r\n                filter(case == 'masterpiece'),\r\n              template = 'Tweet: {text}\\nSentiment: {label}')\r\n\r\ncat(prompt)\r\n\r\n\r\n\r\nRead these tweets posted the day after the US Supreme Court ruled in favor of a baker who refused to bake a wedding cake for a same-sex couple. For each tweet, decide whether its sentiment is Positive, Neutral, or Negative.\r\n\r\nTweet: Thank you Supreme Court I take pride in your decision!!!!✝️ #SCOTUS\r\nSentiment: Positive\r\n\r\nTweet: Supreme Court rules in favor of Colorado baker! This day is getting better by the minute!\r\nSentiment: Positive\r\n\r\nTweet: Can’t escape the awful irony of someone allowed to use religion to discriminate against people in love. \r\nNot my Jesus. \r\n#opentoall #SCOTUS #Hypocrisy #MasterpieceCakeshop\r\nSentiment: Negative\r\n\r\nTweet: I can’t believe this cake case went all the way to #SCOTUS . Can someone let me know what cake was ultimately served at the wedding? Are they married and living happily ever after?\r\nSentiment: Neutral\r\n\r\nTweet: Supreme Court rules in favor of baker who would not make wedding cake for gay couple\r\nSentiment: Neutral\r\n\r\nTweet: #SCOTUS set a dangerous precedent today. Although the Court limited the scope to which a business owner could deny services to patrons, the legal argument has been legitimized that one's subjective religious convictions trump (no pun intended) #humanrights. #LGBTQRights\r\nSentiment: Negative\r\n\r\nTweet: {TWEET}\r\nSentiment:\r\n\r\nNext, we’ll create a function that takes the dataframe of next-word predictions from GPT-3 and converts it into a measure of sentiment. For this tutorial, our measure will be \\(P(\\text{positive}) - P(\\text{negative})\\).\r\n\r\n\r\nsentiment_score <- function(df){\r\n  \r\n  p_positive <- df |> \r\n    # put responses in all caps\r\n    mutate(response = str_to_upper(token)) |> \r\n    # keep and sum probabilities assigned to \"POS\"\r\n    filter(str_detect(response, 'POS')) |> \r\n    pull(probability) |> \r\n    sum()\r\n  \r\n  p_negative <- df |> \r\n    # put responses in all caps\r\n    mutate(response = str_to_upper(token)) |> \r\n    # keep and sum probabilities assigned to \"NEG\"\r\n    filter(str_detect(response, 'NEG')) |> \r\n    pull(probability) |> \r\n    sum()\r\n  \r\n  return(p_positive - p_negative)\r\n}\r\n\r\n\r\nWe can add this function to the end of the pipeline we developed before.\r\n\r\n\r\nprompt |> \r\n  glue() |> \r\n  complete_prompt() |> \r\n  sentiment_score()\r\n\r\n\r\n\r\n\r\n\r\n\r\n[1] -0.9355278\r\n\r\nWith these elements in place, let’s loop through the scotus_tweets dataset and estimate sentiment scores for each tweet referencing Masterpiece Cakeshop. Be mindful before you run this code. At current prices, OpenAI will charge $1.50 per million input toikens, which works out to approximately 1/30 of a cent per prompt, for a total of $0.30 if you classify all 945 tweets.\r\nLet’s create a formatted few-shot prompt for each tweet about the Masterpiece Cakeshop decision, and return the sentiment score for each.\r\n\r\n\r\nmasterpiece_tweets <- scotus_tweets |> \r\n  filter(case == 'masterpiece')\r\n\r\ninstructions <- 'Read these tweets posted the day after the US Supreme Court ruled in favor of a baker who refused to bake a wedding cake for a same-sex couple (Masterpiece Cakeshop, 2018). For each tweet, decide whether its sentiment is Positive, Neutral, or Negative.'\r\n\r\nmasterpiece_examples <- scotus_tweets_examples |> \r\n  filter(case == 'masterpiece')\r\n\r\nmasterpiece_tweets$prompt <- format_prompt(text = masterpiece_tweets$text,\r\n                                           instructions = instructions,\r\n                                           examples = masterpiece_examples)\r\n\r\nmasterpiece_tweets$prompt[3]\r\n\r\n\r\nNow submit the entire list of prompts to complete_prompt():\r\n\r\n\r\nmasterpiece_tweets$out <- complete_prompt(masterpiece_tweets$prompt)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nThe estimated probability distribution for each completion is now a list of dataframes in the out column. We can compute our sentiment score for each one:\r\n\r\n\r\nmasterpiece_tweets$score <- masterpiece_tweets$out |> \r\n  lapply(mutate, token = str_to_lower(token)) |> \r\n  lapply(summarize, \r\n         positive = sum(probability[token=='positive']), \r\n         negative = sum(probability[token=='negative'])) |>\r\n  lapply(summarize,score=positive-negative) |> \r\n  unlist()\r\n\r\n\r\nPlotting those sentiment scores against the average of the hand-coded scores, we can see that this measure is much better than the one from the dictionary method we tried before. The correlation between the two scores is 0.79.\r\n\r\n\r\nggplot(data = masterpiece_tweets,\r\n       mapping = aes(x = (expert1 + expert2 + expert3) / 3,\r\n                     y = score)) +\r\n  geom_jitter(width = 0.1) +\r\n  labs(x = 'Hand-Coded Sentiment Score',\r\n       y = 'GPT-3.5 Sentiment Score') +\r\n  theme_minimal()\r\n\r\n\r\n\r\nAll in all, few-shot prompting an LLM is a powerful method for classifying documents without the need for extensive fine-tuning or large sets of training data, as with supervised learning methods.\r\nCleaning Up OCR\r\nIn the OCR tutorial, we worked with a newspaper clipping about the sinking of the Titanic.\r\n\r\n\r\nlibrary(tesseract)\r\nlibrary(magick)\r\nlibrary(promptr)\r\n\r\nimage <- image_read('img/titanic.png')\r\nimage\r\n\r\n\r\n\r\nLet’s focus for now on the first column.\r\n\r\n\r\nfirst_column <- image_crop(image,\r\n                           geometry = '336 x 660 + 0 + 0')\r\n\r\nfirst_column\r\n\r\n\r\n\r\nThough a human can easily read and interpret this text, converting the image to plain text is a non-trivial problem in the field of computer vision. Note that the text is slightly tilted in places, and some lines are squished or cut off. A smudge obscures some letters in the lower left corner.\r\nHow well does OCR capture the text from that image?\r\n\r\n\r\ntext <- ocr(first_column)\r\n\r\ncat(text)\r\n\r\nTitanic Sank at 2:20 A. M. Monday.\r\nIn the White Star offices the hope\r\nwas held out all day that the Parisian\r\nond the Virginian had taken off some\r\n-{ the Titanic's passengers, and efforts\r\nwere made to get into communication\r\nwith these liners, Until such commu-\r\nnication was established the White\r\nStar officials reused tu recusiiee ce\r\npossibility that there were none of the\r\nTitanic’s passengers aboard them.\r\n\r\nBut by nightfall came the message\r\nfrom Capt. Haddock of the Olympic to\r\nCape Race,’ Newfoundland, telling of\r\nthe foundering of the Titanic and of\r\nthe rescue of 655 of her passengers by\r\nthe Cunarder Carpathia, which, the\r\nWireless message waid, reached the pos!-\r\ntion of the Titanic at daybreak. All\r\nthey found there, however, was lif¢-\r\nboats and wreckage. The biggest ship\r\nin the world had sunk at 2:20 o'clock\r\nyesterday morning.\r\n\r\nMr, Franklin admitted late last ulght\r\nthet the Parisian and the Virginian,\r\nthough they were among the first to\r\nanswer the Titanic’s calls for help,\r\ncould not have reached the scene before\r\n10 o'clock yesterday morning, seven\r\nand a half hours after the big Titanic\r\nburied her nese beneath the waves and\r\nPitched downward out of sight. The\r\nCarpathia, so the wireless dispatch\r\n\r\nm Capt. Haddock to Cape Race an-.\r\njounced, reached the scene of the Ti-,\r\n‘sanic's foundering at daybreak, several\r\n\r\nAs is common with OCR, the result is generally quite good, but not perfect. Notice, for example, the phrases “reused tu recusiiee ce”, “lif¢-boats”, and “Ti-,’sanic’s”. Look closely at the letters in the image above to see how the OCR algorithm may have made those mistakes. When you consider the image letter-by-letter, ignoring the semantic context in which those letters are placed, it is easy to mistake some letters for others. But when humans read a passage like this, they’re not reading it letter-by-letter. Instead, fluent readers learn to recognize whole words at a time, using their knowledge of the language to “predict” what the constituent letters of a word must be, even when they are difficult to make out on the page. In the same way, we can make use of the fact that LLMs are very good at predicting words in sequences to impute what the phrase “reused tu recusiiee ce” is likely to have been, given the context.\r\nTo do so, we can prompt the LLM like so:\r\n\r\n\r\nprompt <- glue('Correct OCR errors in the following passage.\\n---\\nOriginal Passage:\\n\\n{text}\\n---\\nCorrected Passage:\\n\\n')\r\n\r\ncat(prompt)\r\n\r\nCorrect OCR errors in the following passage.\r\n---\r\nOriginal Passage:\r\n\r\nTitanic Sank at 2:20 A. M. Monday.\r\nIn the White Star offices the hope\r\nwas held out all day that the Parisian\r\nond the Virginian had taken off some\r\n-{ the Titanic's passengers, and efforts\r\nwere made to get into communication\r\nwith these liners, Until such commu-\r\nnication was established the White\r\nStar officials reused tu recusiiee ce\r\npossibility that there were none of the\r\nTitanic’s passengers aboard them.\r\n\r\nBut by nightfall came the message\r\nfrom Capt. Haddock of the Olympic to\r\nCape Race,’ Newfoundland, telling of\r\nthe foundering of the Titanic and of\r\nthe rescue of 655 of her passengers by\r\nthe Cunarder Carpathia, which, the\r\nWireless message waid, reached the pos!-\r\ntion of the Titanic at daybreak. All\r\nthey found there, however, was lif¢-\r\nboats and wreckage. The biggest ship\r\nin the world had sunk at 2:20 o'clock\r\nyesterday morning.\r\n\r\nMr, Franklin admitted late last ulght\r\nthet the Parisian and the Virginian,\r\nthough they were among the first to\r\nanswer the Titanic’s calls for help,\r\ncould not have reached the scene before\r\n10 o'clock yesterday morning, seven\r\nand a half hours after the big Titanic\r\nburied her nese beneath the waves and\r\nPitched downward out of sight. The\r\nCarpathia, so the wireless dispatch\r\n\r\nm Capt. Haddock to Cape Race an-.\r\njounced, reached the scene of the Ti-,\r\n‘sanic's foundering at daybreak, several\r\n\r\n---\r\nCorrected Passage:\r\n\r\n\r\n\r\ncleaned_text <- complete_prompt(\r\n  prompt = prompt,\r\n  max_tokens = nchar(text))\r\n\r\ncat(cleaned_text)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nTitanic sank at 2:20 A.M. Monday.\r\nIn the White Star offices, the hope\r\nwas held out all day that the Parisian\r\nand the Virginian had taken off some\r\nof the Titanic's passengers, and efforts\r\nwere made to get into communication\r\nwith these liners. Until such communication was established, the White\r\nStar officials refused to acknowledge the possibility that there were none of the Titanic's passengers aboard them.\r\n\r\nBut by nightfall, the message came\r\nfrom Capt. Haddock of the Olympic to\r\nCape Race, Newfoundland, telling of\r\nthe foundering of the Titanic and of\r\nthe rescue of 655 of her passengers by\r\nthe Cunarder Carpathia, which, the\r\nwireless message said, reached the position of the Titanic at daybreak. All\r\nthey found there, however, were lifeboats and wreckage. The biggest ship in the world had sunk at 2:20 o'clock yesterday morning.\r\n\r\nMr. Franklin admitted late last night\r\nthat the Parisian and the Virginian,\r\nthough they were among the first to\r\nanswer the Titanic's calls for help,\r\ncould not have reached the scene before\r\n10 o'clock yesterday morning, seven\r\nand a half hours after the big Titanic\r\nburied her nose beneath the waves and\r\npitched downward out of sight. The\r\nCarpathia, according to the wireless dispatch from Capt. Haddock to Cape Race,\r\nreached the scene of the Titanic's foundering at daybreak, several hours after the sinking.\r\n\r\nThe resulting text is a nearly perfect transcription, despite the garbled inputs!\r\nText To Data\r\nOne of the most labor-intensive tasks in a research workflow involves converting unstructured text to structured datasets. Traditionally, this is a task that has only been suitable for human research assistants, but with LLMs, a truly automated workflow is feasible. Consider the following prompt:\r\n\r\nCreate a data table from the following passage.\r\n---\r\nThe little dog laughed to see such fun, and the dish ran away with the spoon.\r\n---\r\nData Table:\r\nCharacter | What They Did \r\n---|---\r\n\r\nWhen we submit this prompt to ChatGPT, it yields a data table delimited by vertical bars, which can then be read into a dataframe.\r\n\r\n\r\nprompt <- 'Create a data table from the following passage.\\n---\\nThe little dog laughed to see such fun, and the dish ran away with the spoon.\\n---\\nData Table:\\nCharacter | What They Did \\n---|---\\n'\r\n\r\nresponse <- complete_prompt(prompt, \r\n                            max_tokens = 100)\r\n\r\nresponse\r\n\r\n\r\n\r\n\r\n\r\n\r\n[1] \"Little Dog | Laughed \\nDish | Ran away \\nSpoon | Ran away\"\r\n\r\n\r\n\r\ndf <- read_delim(response,\r\n                 delim = '|',\r\n                 col_names = FALSE)\r\n\r\ndf\r\n\r\n# A tibble: 3 × 2\r\n  X1            X2          \r\n  <chr>         <chr>       \r\n1 \"Little Dog \" \" Laughed \" \r\n2 \"Dish \"       \" Ran away \"\r\n3 \"Spoon \"      \" Ran away\" \r\n\r\nPractice Problems\r\nTake a sample of the Senate press releases from the clustering tutorial. Format a few-shot ChatGPT prompt that returns a list of topics. Are the topic labels sensible? Are they similar to what we came up with using unsupervised methods?\r\nAsk ChatGPT to summarize the remarks on pages 4-5 of the PDF that you imported in the OCR practice problems.\r\n\r\n\r\n\r\nBrown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. “Language Models Are Few-Shot Learners.” arXiv:2005.14165 [Cs], July. http://arxiv.org/abs/2005.14165.\r\n\r\n\r\nOrnstein, Joseph T., Elise N. Blasingame, and Jake S. Truscott. 2025. “How to Train Your Stochastic Parrot: Large Language Models for Political Texts.” Political Science Research and Methods, January, 1–18. https://doi.org/10.1017/psrm.2024.64.\r\n\r\n\r\nSpirling, Arthur. 2023. “Why Open-Source Generative AI Models Are an Ethical Way Forward for Science.” Nature 616 (7957): 413–13. https://doi.org/10.1038/d41586-023-01295-4.\r\n\r\n\r\nVaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. “Attention Is All You Need.” arXiv:1706.03762 [Cs], December. https://arxiv.org/abs/1706.03762.\r\n\r\n\r\nLike many others, I have qualms about using proprietary, closed-source models for scientific research (Spirling 2023). But as of summer 2025 the ease-of-use and capabilities of OpenAI’s models are sufficiently beyond those of similar open-source models that it makes sense to start here.↩︎\r\nNote that the default model used by complete_prompt() is “gpt-3.5-turbo-instruct”, essentially the model underlying the original ChatGPT. You can prompt different model variants using the model argument.↩︎\r\n",
      "last_modified": "2025-06-13T15:32:10-04:00"
    },
    {
      "path": "OCR.html",
      "title": "Optical Character Recognition (OCR)",
      "description": "What to do when someone asks you to type up 100 pages of text from clippings of old newspapers.\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nOptical Character Recognition\r\nImage Pre-Processing\r\nPractice Problems\r\nFurther Reading\r\n\r\nIn the webscraping and Twitter API tutorials, we worked with texts that are already stored in digital form, so that getting them into R is just a matter of removing all the HTML code. But other texts (lots of texts) are not so digitally accessible. Maybe you’re interested in historical archives living in a dark basement. Or old press releases living in a PDF. In either case, we need a method that can recognize text in images, and convert it into plain text. This is a job for Optical Character Recognition (OCR).\r\nOptical Character Recognition\r\nOCR is a notoriously difficult task for computers, which is why the “are you a human” tests on some websites might ask you to type a bunch of numbers and letters within a blurry or distorted image.\r\n\r\nBut if the text is in straight lines on a white background, off-the-shelf OCR packages do a pretty good job. The workhorse OCR engine is called Tesseract, and it’s available in R through a package called tesseract.\r\nLet’s see if it can recognize the text in that xkcd comic above, using the ocr() function.\r\n\r\n\r\nlibrary(tesseract)\r\n\r\nxkcd <- ocr(image = 'img/suspicion.png')\r\n\r\nxkcd\r\n\r\n[1] \"Fie, HED UR 1S JUST... NOW AND THEN | BEFORE THIS GOES ANY FURTHER,\\nONLINE CHATS You MENTION PRODUCTS YOU | T THINK WE SHOULD GO GET TESTED,\\nTHESE. PAST FEW LIKE, AND... I UORRY. | YOUKNOU, TOGETHER. VK Coupes Tene\\nONTHS, I = PROVES Cape.\\nUSA. \\\\ ROM KE. WHAT? HONEY... \\\\ You Dont Taist mee\\nYOU, ROB. I. JUST WANT To BE\\n4 SURE. O S\\nio) #) OKAY, PINE SANS Uy\\nd z PUBRARY: YOURS? \\\"5\\n\\\\ iS TH MORE THAN A\\n4) WE OCOD. SeAMBOT! OUR LOVE\\nVe = Goooere, usa, 4 WAS REAL!\\nana VC\\n\"\r\n\r\nClearly it cannot make out “Library” and “Kittens”, but by my count it reads about 65% of these handwritten words correctly. They’re not in the right order though. Tesseract reads from left to right, top to bottom, and does not understand things like comic panels or speech bubbles. If we’re just using a bag of words representation and we don’t care about word order, then we can use the ocr_data() function, which splits the input into a dataframe with one row for each word. It even includes a handy confidence column, which tells you how confident the model is in its prediction.\r\n\r\n\r\nxkcd <- ocr_data(image = 'img/suspicion.png')\r\n\r\nhead(xkcd)\r\n\r\n# A tibble: 6 × 3\r\n  word    confidence bbox        \r\n  <chr>        <dbl> <chr>       \r\n1 Fie,           0   4,6,37,41   \r\n2 HED           41.0 50,6,74,41  \r\n3 UR            48.8 85,6,107,41 \r\n4 1S            55.7 170,9,185,21\r\n5 JUST...       82.5 191,9,318,23\r\n6 NOW           65.9 238,5,260,33\r\n\r\nBut if we do care about word order, then we’ll need to be more careful about pre-processing the image before conducting OCR. For example, let’s try to read in the text on page 3 of this document about the California Supreme Court. The pdftools package can convert the page to an image, when we can then OCR.\r\n\r\n\r\nlibrary(pdftools)\r\n\r\npdf_convert('img/SOJ.pdf', pages = 3, dpi = 600, filenames = 'img/SOJ.png')\r\n\r\nConverting page 3 to img/SOJ.png... done!\r\n[1] \"img/SOJ.png\"\r\n\r\ntext <- ocr('img/SOJ.png')\r\n\r\ntext\r\n\r\n[1] \"Remarks  . ~~\\n_ By Chief Justice Rose Elizabeth Bird*  - a,\\nIt is a pleasure to be here this afternoon. I own making. Our court system is an indepen-\\nwould like to thank the Conference of dent branch of government, and there is\\nDelegates for affording me this opportunity to strength to be derived from thai unity. But un-\\nshare with you some thoughts about issues til we judges begin to see ourselves as part of :\\nwhich judges, lawyers, and citizens of Califor- an organic whole, that strength will be |\\nnia willbe facing during thecoming year. _ . dissipated and wasted. .\\nOur democratic form of government is Sadly, our justice system is marred by\\nblessed with a court system that is particular- fractionization and segmentation at all levels.\\nly well designed to resolve the disputes that Judging is by its nature often a solitary and\\narise in a heterogeneous society. There is time-consuming task. Its demands tend to\\nstrength in the diversity of views found in our isolate judges from one another, even though\\nsociety, but that strength cannot be drawn they may serve on the same court. This isola-\\nupon unless conflicting views are moderated tion is intensified when judges are sitting at\\nand balanced and excesses checked. different levels and is sometimes characteriz-\\nThe courts hold a unique position among —_ ed by feelings of elitism and of superiority\\nour democratic institutions. In a sense, they over judges of “lower courts,” __ |\\nrepresent one of the last bastions of par- _ dn turn, these antagonistic feelings have 5\\nticipatory democracy in our society. They — often led judges to take a competitive, rather i\\nstand as a symbol of the great strength of our than a cooperative, view of one another ~- an .\\n- representative form of government. The in- attitude which only further deepens the sense\\n. dividual disputants go directly before a judge of isolation and fragmentation.\\nora jury to raise and resolve a specific issue. It is time for this cycle to stop. Our justice §\\nIn no other context within our governmental system is an interrelated whole, and the more\\n, system does an individual have the opportuni- that judges in one part of the system unders-\\nty to take a problem directly to the decision ._ tand how the other levels function, the more i\\nmaker who represents the full force and power effective we will be in meeting the complex i\\nof that particular branch of government. realities of the society we serve. The judges at i\\nThis direct interchange between the in- different levels of the system have different\\ndividual and the state is at the heart of the but equally important roles to play. :\\ndemocratic process. AS more barriers are. There are many things that can be done to\\nraised between the litigant and the decision- | promote the spirit of cooperation of which I\\nmaker, the participatory nature of the ex- speak. And this spirit can be achieved without i\\nperience is diminished. We must protect this imposing any constraints on the power of\\nunique heritage and strive to preserve the judges torun their own courtrooms or to make :\\nvalues it represents. local administrative decisions, which they are\\nThe barriers to which I refer are in part uniquely well situated to do. :\\nthe resuit of the increasingly complex society An important step toward this sense of\\nin which we live. However, I fear that to some common judicial venture could be taken by\\nextent these barriers are of the judiciary’s providing state funding for our trail courts.\\nnen This issue, though not a new one, was recently\\n* California Supreme Court. This is a speech given brought into sharp focus by the passage of pro-\\nbefore the Canference of Delegates at the State position 13 and the availability of local funding\\nBar Convention in San Francisco, Cal. on Septem- for the trial courts. As you may know, Califor-\\n, ber 10, 1978. nia ranks last among all states in the percen- |\\n4\\n\"\r\n\r\nNotice two things. First, ocr() performs much better with the typed text than it did with the handwritten comic. Second, all the words are out of order, because it reads left to right across the two columns on that page. So we need to first crop the image into two columns and read each column separately.\r\nFor that, we’ll turn to the magick package.\r\nImage Pre-Processing\r\n\r\n\r\nlibrary(magick)\r\n\r\n# First, read in the image with magick\r\npage3 <- image_read('img/SOJ.png')\r\npage3\r\n\r\n\r\n# Next, crop it into two images with image_crop()\r\n# syntax is width x height + left offset + top offset\r\npage3_left <- image_crop(page3, '2550 x 4300 + 0 + 1000')\r\npage3_left\r\n\r\n\r\npage3_right <- image_crop(page3, '2550 x 5000 + 2550 + 1000')\r\npage3_right\r\n\r\n\r\n# Finally, ocr() each column, then paste the results together\r\ntext_left <- ocr(page3_left)\r\ntext_right <- ocr(page3_right)\r\n\r\ntext <- paste(text_left, text_right)\r\n\r\ntext\r\n\r\n[1] \"It is a pleasure to be here this afternoon. I\\nwould like te thank the Conference of\\nDelegates for affording me this opportunity to\\nshare with you some thoughts about issues\\nwhich judges, lawyers, and citizens of Califor-\\nnia willbe facing during thecoming year. _\\n\\nOur democratic form of government is\\nblessed with a court system that is particular-\\nly well designed to resolve the disputes that\\narise in a heterogeneous society. There is\\nstrength in the diversity of views found in our\\nsociety, but that strength cannot be drawn\\nupon unless conflicting views are moderated\\nand balanced and excesses checked.\\n\\nThe courts hold a unique position among\\nour democratic institutions. In a sense, they\\nrepresent one of the last bastions of par-\\nticipatory democracy in our society. They\\nstand as a symbol of the great strength of our\\n\\n. representative form of government. The in-\\n\\n. dividual disputants go directly before a judge\\n\\nora jury to raise and resolve a specific issue.\\n\\nIn no other context within our governmental\\n\\n, system does an individual have the opportuni-\\nty to take a problem directly to the decision |\\n\\nmaker who represents the full force and power\\n\\nof that particular branch of government.\\n\\nThis direct interchange between the in-\\ndividual and the state is at the heart of the\\ndemocratic precess. AS more barriers are\\nraised between the litigant and the decision- _\\nmaker, the participatory nature of the ex-\\nperience is diminished. We must protect this\\nunique heritage and strive to preserve the\\nvalues it represents.\\n\\nThe barriers to which I refer are in part\\nthe result of the increasingly complex society\\nin which we live. However, I fear that to some\\nextent these barriers are of the judiciary’s\\n own making. Our court system is an indepen-\\ndent branch of government, and there is\\nstrength to be derived from thai unity. But un-\\ntil we judges begin to see ourselves as part of :\\nan organic whole, that strength will be |\\n. dissipated and wasted. ,\\nSadly, our justice system is marred by\\nfractionization and segmentation at all levels.\\nJudging is by its nature often a solitary and\\ntime-consuming task. Its demands tend to\\nisolate judges from one another, even though\\nthey may serve on the same court. This isola-\\ntion is intensified when judges are sitting at\\ndifferent levels and is sometimes characteriz-\\ned by feelings of elitism and of superiority\\nover judges of “lower courts,” __ }\\n_ dn turn, these antagonistic feelings have 5\\n_ often led judges to take a competitive, rather i\\nthan a cooperative, view of one another ~- an\\nattitude which only further deepens the sense\\nof isolation and fragmentation.\\n\\nIt is time for this cycle to stop. Our justice f\\nsystem is an interrelated whole, and the more\\nthat judges in one part of the system unders-\\ntand how the other levels function, the more |\\neffective we will be in meeting the complex i\\nrealities of the society we serve. The judges at\\ndifferent levels of the system have different P\\nbut equally important roles to play. :\\n\\n; There are many things that can be done to :\\npromote the spirit of cooperation of which I\\nspeak. And this spirit can be achieved without i\\nimposing any constraints on the power of\\njudges torun their own courtrooms or to make :\\nlocal administrative decisions, which they are\\nuniquely well situated to do. :\\n\\nAn important step toward this sense of\\ncommon judicial venture could be taken by\\nproviding state funding for our trail courts.\\n\\nThis issue, though not a new one, was recently\\nbrought into sharp focus by the passage of pro-\\nposition 13 and the availability of local funding\\nfor the trial courts. As you may know, Califor-\\nnia ranks last among all states in the percen- |\\n\"\r\n\r\nPractice Problems\r\nOCR the text on page 4 of SOJ.pdf.\r\nOCR the text in this newspaper clipping about the sinking of the Titanic.\r\nFurther Reading\r\nFor more tesseract features, see this vignette\r\nState of the art optical character recognition uses advances in convolutional neural networks to handle handwritten and other kinds of difficult-to-read texts. See Torres and Cantú (2021) for a primer.\r\n\r\n\r\n\r\nTorres, Michelle, and Francisco Cantú. 2021. “Learning to See: Convolutional Neural Networks for the Analysis of Social Science Data.” Political Analysis, April, 1–19. https://doi.org/10.1017/pan.2021.9.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-06-13T13:59:55-04:00"
    },
    {
      "path": "sentiment-analysis.html",
      "title": "Sentiment Analysis",
      "description": "Teaching the computer to understand feelings.\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nHand Coding\r\nDictionary Classification\r\nSupervised Learning\r\nPractice Problems\r\nFurther Reading\r\n\r\nFor unsupervised learning models like k-means and LDA, the objective is often discovery. We have a set of unlabeled data, and we want to get a sense of how we might organize the documents – how we might sort them into buckets. But frequently social scientists turn to text data because we’re interested in measuring some concept that is tough to quantify in other ways. For this, we’ll want a different set of tools.\r\nTo illustrate the process of measurement using text data, let’s consider the field of sentiment analysis. We have a set of documents, and we’re interested in classifying the sentiment/emotion the author is trying to convey – positive, negative, or neutral. Here is a dataset of 945 tweets about the Supreme Court that I compiled for a project with Jake Truscott and Elise Blasingame.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(tidytext)\r\n\r\n# load the tweets\r\ntweets <- read_csv('data/supreme-court-tweets.csv')\r\n\r\ntweets |> select(-tweet_id)\r\n\r\n# A tibble: 945 × 4\r\n   text                                        expert1 expert2 expert3\r\n   <chr>                                         <dbl>   <dbl>   <dbl>\r\n 1 \"Just in time for #PrideMonth #Pride2018 #…       1      -1      -1\r\n 2 \"The silliness of the day-long kerfuffle o…       1      -1      -1\r\n 3 \"The @Scotus ruling was a \\U0001f967 pie-i…       1      -1       1\r\n 4 \"Let’s be real, lame anti-gay cake probabl…       1       1      -1\r\n 5 \"#ReligiousFreedom #SCOTUS \\r\\nWould a Mus…       1      -1      -1\r\n 6 \"I’m happy SCOTUS ruled in favor of the ba…       1      -1      -1\r\n 7 \"Breaking: Supreme Court rules New York pr…       1      -1       0\r\n 8 \"SUPREME COURT: \\r\\n\\r\\nTRUMP IS NOT ABOVE…       1       1      -1\r\n 9 \"Not gonna lie....shocked Kavanaugh rules …      -1       1       1\r\n10 \"Gonna have a drink at “the low bar” to ce…      -1      -1       1\r\n# ℹ 935 more rows\r\n\r\nHand Coding\r\nThe dataset contains the text of the tweet, plus three “expert” ratings on a scale from -1 (negative), 0 (neutral), to 1 (positive). Each author independently read and coded each tweet1 then discussed the cases where we disagreed, going back for a second round of coding on those tweets where everyone produced a different measure. One way to assess how well we did at capturing sentiment is inter-coder reliability (aka Fleiss’ kappa), which measures how frequently the coders agreed relative to chance, on a scale from -1 (complete disagreement on everything) to 1 (perfect agreement on everything).\r\n\r\n\r\nlibrary(irr)\r\ntweets |>\r\n  select(expert1, expert2, expert3) |>\r\n  kappam.fleiss()\r\n\r\n Fleiss' Kappa for m Raters\r\n\r\n Subjects = 920 \r\n   Raters = 3 \r\n    Kappa = 0.688 \r\n\r\n        z = 48.9 \r\n  p-value = 0 \r\n\r\nManually labeling your documents has twin advantages of accuracy and transparency (when combined with a codebook describing why you coded things the way you did). But its main disadvantage is in scaling: it’s difficult, costly, and/or time-consuming to hand-code more than a few thousand documents this way. If we want to work with a larger corpus, we need an automated method. As a first pass, let’s consider dictionary classification.\r\nDictionary Classification\r\nThe dictionary method is pure bag of words. We count up the number of words with a positive sentiment and the number of words with a negative sentiment and take the difference. Tweets with more positive words than negative words are coded positive, and vice versa.\r\nTo do so, we’ll join the tokenized text data with a sentiment lexicon, a list of words paired with their associated sentiment. The tidytext package comes with four sentiment lexicons built in.\r\n\r\n\r\nget_sentiments('bing')\r\n\r\n# A tibble: 6,786 × 2\r\n   word        sentiment\r\n   <chr>       <chr>    \r\n 1 2-faces     negative \r\n 2 abnormal    negative \r\n 3 abolish     negative \r\n 4 abominable  negative \r\n 5 abominably  negative \r\n 6 abominate   negative \r\n 7 abomination negative \r\n 8 abort       negative \r\n 9 aborted     negative \r\n10 aborts      negative \r\n# ℹ 6,776 more rows\r\n\r\nget_sentiments('afinn')\r\n\r\n# A tibble: 2,477 × 2\r\n   word       value\r\n   <chr>      <dbl>\r\n 1 abandon       -2\r\n 2 abandoned     -2\r\n 3 abandons      -2\r\n 4 abducted      -2\r\n 5 abduction     -2\r\n 6 abductions    -2\r\n 7 abhor         -3\r\n 8 abhorred      -3\r\n 9 abhorrent     -3\r\n10 abhors        -3\r\n# ℹ 2,467 more rows\r\n\r\nSince it is the most extensive, we’ll work with the bing lexicon in this tutorial.\r\n\r\n\r\ntidy_tweets <- tweets |> \r\n  # tokenize to the word level\r\n  unnest_tokens(input = 'text',\r\n                output = 'word') |>\r\n  # join with the sentiment lexicon\r\n  inner_join(get_sentiments('bing'))\r\n\r\ntidy_tweets\r\n\r\n# A tibble: 2,489 × 6\r\n   tweet_id                    expert1 expert2 expert3 word  sentiment\r\n   <chr>                         <dbl>   <dbl>   <dbl> <chr> <chr>    \r\n 1 718152140305248257_2018-06…       1      -1      -1 favor positive \r\n 2 718152140305248257_2018-06…       1      -1      -1 mist… negative \r\n 3 718152140305248257_2018-06…       1      -1      -1 supp… positive \r\n 4 718152140305248257_2018-06…       1      -1      -1 supp… positive \r\n 5 718152140305248257_2018-06…       1      -1      -1 fake  negative \r\n 6 718152140305248257_2018-06…       1      -1      -1 rage  negative \r\n 7 718152140305248257_2018-06…       1      -1      -1 false negative \r\n 8 380268462_2018-06-05T04:54…       1      -1      -1 mast… positive \r\n 9 380268462_2018-06-05T04:54…       1      -1      -1 fair… positive \r\n10 380268462_2018-06-05T04:54…       1      -1      -1 exci… positive \r\n# ℹ 2,479 more rows\r\n\r\nNow we have a dataframe with 2489 words from the tweets and their associated sentiment. We create a score for each document by counting the number of positive words minus the number of negative words, scaling by the total number of words matched to the sentiment lexicon.\r\n\r\n\r\ntidy_tweets <- tidy_tweets |> \r\n  group_by(tweet_id) |> \r\n  summarize(positive_words = sum(sentiment == 'positive'),\r\n            negative_words = sum(sentiment == 'negative'),\r\n            sentiment_score = (positive_words - negative_words) /\r\n              (positive_words + negative_words))\r\n\r\nggplot(data = tidy_tweets,\r\n       mapping = aes(x = sentiment_score)) +\r\n  geom_histogram(color = 'black') +\r\n  theme_bw() +\r\n  labs(x = 'Dictionary Sentiment Score',\r\n       y = 'Number of Tweets')\r\n\r\n\r\n\r\nLooking at the histogram of results, it seems like the dictionary classifier is labeling a lot of these tweets as positive. A lot more than our expert coders did. What’s going on?\r\n\r\n\r\n# find a tweet the experts coded as negative\r\n# but the classifier coded as positive\r\ntweets |> \r\n  left_join(tidy_tweets, by = 'tweet_id') |> \r\n  filter(expert1 == -1, expert2 == -1, expert3 == -1,\r\n         sentiment_score == 1) |> \r\n  pull(text) |> \r\n  sample(3)\r\n\r\n[1] \"The NYS Supreme Court should hold their calendar and get Trump before Nov. That will make America great again. #TrumpTaxReturns \\r\\n#TrumpIsANationalDisgrace \\r\\n#TrumpMeltdown\"                                                                                                      \r\n[2] \"Thurgood Marshall’s successor on the Supreme Court was Clarence Thomas. I’ll never get over that.\"                                                                                                                                                                                     \r\n[3] \"If the supreme Court sides with Trump on his taxes we know it's all @senatemajldr doing for STACKING the court with bought and paid for judges like KAVANAUGH. We will have to increase pressure on @GOP up for re-election on their votes and hold them ACCOUNTABLE vote them all OUT\"\r\n\r\nAh. Well that’s embarrassing. Seems the bing lexicon codes the words “trump” and “supreme” as positive.\r\n\r\n\r\nget_sentiments('bing') |> \r\n  filter(word %in% c('trump','supreme'))\r\n\r\n# A tibble: 2 × 2\r\n  word    sentiment\r\n  <chr>   <chr>    \r\n1 supreme positive \r\n2 trump   positive \r\n\r\nPerhaps this is an appropriate choice for the English language writ large, but for our specific corpus (tweets about Supreme Court cases during the Trump administration), it’s definitely inappropriate. Let’s see how the dictionary scores compare with the hand-coded scores.\r\n\r\n\r\ntweets <- tweets |> \r\n  left_join(tidy_tweets, by = 'tweet_id') |> \r\n  mutate(expert_score = (expert1 + expert2 + expert3) / 3) \r\n\r\nggplot(data = tweets,\r\n       mapping = aes(x = expert_score,\r\n                       y = sentiment_score)) +\r\n  geom_jitter(alpha = 0.5, width = 0.05) +\r\n  theme_bw() +\r\n  labs(x = 'Hand-Coded Sentiment', \r\n       y = 'Dictionary Sentiment')\r\n\r\n\r\n\r\nOn the whole, it’s pretty bad (correlation = 0.333). When the tweets are genuinely positive, it seems that they contain a lot of positive words, so the dictionary method mostly gets it right. But when the tweets are negative, there may be a lot of sarcastic use of positive words, which trips up the classifier. For instance:\r\n\r\n\r\ntweets |> \r\n  filter(str_detect(text, 'sober')) |> \r\n  pull(text)\r\n\r\n[1] \"I’m sure the news media will provide sober, nuanced analysis of Masterpiece Cake Shop. #SCOTUS\"\r\n\r\nWe want an approach that better predicts which words are most strongly associated with negative/positive sentiment in our particular corpus. For that we’ll need…\r\nSupervised Learning\r\nBoth human coding and dictionary classification are examples of rule-based measurement. You decide in advance exactly what steps you will take to measure each document, and then you (or your computer) follow the rules you set out. The problem with such rules-based measures is that they are either:\r\nNot scalable (e.g. human-coding). For a dataset of 945 tweets, we were able to tackle it in relatively short order. But if we were interested in 100,000 tweets? Or a million tweets? There’s no way to scale that procedure, except with crowd coding on something like Amazon’s MTurk (Benoit et al. 2016; Carlson and Montgomery 2017), and that gets expensive quickly.\r\nScalable, but terrible (e.g. dictionary methods). With rules-based classification, it’s trivial to classify a million tweets. But the results, as we have seen, are often crummy.\r\nThe best alternative to rules-based classification is statistical classification, and that is the topic of the page on supervised learning.\r\nPractice Problems\r\nHow accurate does the dictionary classifier need to be until it’s “good enough”? A useful benchmark is to compare your model against a null model. For example, in the Twitter corpus, how accurate is the null model “predict every tweet will be negative”?\r\nHow accurate can you get the dictionary classifier to be, by varying the lexicon and modifying the word list to match our specific context (i.e. filtering out words whose dictionary meaning and context-specific meaning are different, like “Trump” and “Supreme”)?\r\nFurther Reading\r\nSilge & Robinson, Chapter 2\r\nGrimmer, Stewart & Roberts, Chapters 15-16\r\n\r\n\r\n\r\nBenoit, Kenneth, Drew Conway, Benjamin E. Lauderdale, Michael Laver, and Slava Mikhaylov. 2016. “Crowd-Sourced Text Analysis: Reproducible and Agile Production of Political Data.” American Political Science Review 110 (2): 278–95. https://doi.org/10.1017/S0003055416000058.\r\n\r\n\r\nCarlson, David, and Jacob M. Montgomery. 2017. “A Pairwise Comparison Framework for Fast, Flexible, and Reliable Human Coding of Political Texts.” American Political Science Review 111 (4): 835–43. https://doi.org/10.1017/S0003055417000302.\r\n\r\n\r\nYes, it was dreadful and I don’t recommend trying this at home.↩︎\r\n",
      "last_modified": "2025-06-13T14:00:04-04:00"
    },
    {
      "path": "supervised-learning.html",
      "title": "Supervised Learning",
      "description": "How to train a model that's good at predicting, but not...*too* good at predicting.\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nThe Data\r\nUnderfitting and Overfitting\r\nRegularization: Hitting the Sweet Spot\r\nPractice Problems\r\nFurther Reading\r\n\r\nAt the end of the page on sentiment analysis, we lamented that hand-coding is too costly to scale, and rules-based classifiers are too inflexible to handle the subtleties of human language. On this page, we’ll demonstrate a different approach: take a corpus of pre-labeled documents, train a model to predict the labels, then use the predictions from that model to label other documents. This is called a supervised learning approach, and to illustrate, let’s replicate the exercise from Chapter 23 of Grimmer, Roberts, and Stewart (2022), predicting whether a set of tweets during the 2016 presidential election were written by Donald Trump or his campaign staff.\r\nThe Data\r\nTo start, let’s load the training data compiled by David Robinson.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(tidytext)\r\nlibrary(tidymodels)\r\nlibrary(lubridate)\r\n\r\nload(url(\"http://varianceexplained.org/files/trump_tweets_df.rda\"))\r\n\r\nglimpse(trump_tweets_df)\r\n\r\nRows: 1,512\r\nColumns: 16\r\n$ text          <chr> \"My economic policy speech will be carried liv…\r\n$ favorited     <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\r\n$ favoriteCount <dbl> 9214, 6981, 15724, 19837, 34051, 29831, 19223,…\r\n$ replyToSN     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\r\n$ created       <dttm> 2016-08-08 15:20:44, 2016-08-08 13:28:20, 201…\r\n$ truncated     <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\r\n$ replyToSID    <lgl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\r\n$ id            <chr> \"762669882571980801\", \"762641595439190016\", \"7…\r\n$ replyToUID    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\r\n$ statusSource  <chr> \"<a href=\\\"http://twitter.com/download/android…\r\n$ screenName    <chr> \"realDonaldTrump\", \"realDonaldTrump\", \"realDon…\r\n$ retweetCount  <dbl> 3107, 2390, 6691, 6402, 11717, 9892, 5784, 793…\r\n$ isRetweet     <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\r\n$ retweeted     <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE, FALS…\r\n$ longitude     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\r\n$ latitude      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA…\r\n\r\nThroughout the 2016 presidential campaign, candidate Trump sent tweets from his personal Android phone, while staffers ghost-wrote tweets from an iPhone or web client. This provides us with the labels we need to build our model.\r\n\r\n\r\ntweets <- trump_tweets_df |>\r\n  select(.id = id,\r\n         .source = statusSource,\r\n         .text = text,\r\n         .created = created) |>\r\n  extract(.source, '.source', \"Twitter for (.*?)<\") |>\r\n  filter(.source %in% c('iPhone', 'Android')) |>\r\n  mutate(.source = factor(.source))\r\n\r\n# (notice that I'm putting a dot in front of all these\r\n# column names, on the off chance that words like \"source\"\r\n# or \"id\" appear in the corpus after we tokenize)\r\n\r\ntweets |>\r\n  count(.source, hour = hour(with_tz(.created, \"EST\"))) |>\r\n  mutate(percent = n / sum(n)) |>\r\n  ggplot(aes(hour, percent, color = .source)) +\r\n  geom_line() +\r\n  scale_y_continuous(labels = percent_format()) +\r\n  labs(x = \"Hour of day (EST)\",\r\n       y = \"% of tweets\",\r\n       color = \"\") +\r\n  theme_minimal()\r\n\r\n\r\n\r\nTrump is a very productive tweeter in the early morning and late evening. Next, let’s tokenize the tweets and convert into a document-term matrix. We’ll remove any stray HTML and rare words that only get used once or twice in the training set.\r\n\r\n\r\n# pick the words to keep as predictors\r\nwords_to_keep <- tweets |>\r\n  unnest_tokens(input = '.text',\r\n                output = 'word') |>\r\n  count(word) |>\r\n  # remove numerals, URLs\r\n  filter(str_detect(word, '.co|.com|.net|.edu|.gov|http', negate = TRUE)) |>\r\n  filter(str_detect(word, '[0-9]', negate = TRUE)) |>\r\n  # remove rare words\r\n  filter(n > 2) |>\r\n  pull(word)\r\n\r\n# tokenize\r\ntidy_tweets <- tweets |>\r\n  unnest_tokens(input = '.text',\r\n                output = 'word') |>\r\n  filter(word %in% words_to_keep) |>\r\n  count(.id, word) |>\r\n  # compute term frequencies\r\n  bind_tf_idf(term = 'word',\r\n              document = '.id',\r\n              n = 'n') |>\r\n  select(.id, word, tf) |>\r\n  # pivot wider into a document-term matrix\r\n  pivot_wider(id_cols = '.id',\r\n              names_from = 'word',\r\n              values_from = 'tf',\r\n              values_fill = 0)\r\n\r\n# join with the training labels\r\ntidy_tweets <- tweets |>\r\n  select(.id, .source, .created) |>\r\n  right_join(tidy_tweets, by = '.id')\r\n\r\ndim(tidy_tweets)\r\n\r\n[1] 1382 1156\r\n\r\ntidy_tweets[1:6, 1:5]\r\n\r\n# A tibble: 6 × 5\r\n  .id         .source .created            makeamericagreatagain     of\r\n  <chr>       <fct>   <dttm>                              <dbl>  <dbl>\r\n1 7626698825… Android 2016-08-08 15:20:44                     0 0     \r\n2 7626415954… iPhone  2016-08-08 13:28:20                     0 0     \r\n3 7624396589… iPhone  2016-08-08 00:05:54                     0 0     \r\n4 7624253718… Android 2016-08-07 23:09:08                     0 0.0556\r\n5 7624008698… Android 2016-08-07 21:31:46                     0 0     \r\n6 7622845333… Android 2016-08-07 13:49:29                     0 0.0476\r\n\r\nUnderfitting and Overfitting\r\nAll supervised learning, in a nutshell, is an effort to find the sweet spot between a model that is too simple (underfitting) and one that is too complex (overfitting). With 1382 documents and 1153 possible predictors, there are an enormous number of possible models that we could fit.\r\nTo discipline ourselves, it is good practice to split the dataset into two parts: the training set, which we use to fit the model, and the test set, which we use to evaluate the predictions and see whether we did a good job.\r\n\r\n\r\ntweet_split <- initial_split(tidy_tweets,\r\n                             prop = 0.8)\r\n\r\ntrain <- training(tweet_split)\r\ntest <- testing(tweet_split)\r\n\r\n\r\nFor our first stab at a model, consider what we remember about Trump’s tweeting style. Words and phrases that were distinctly Trump 2016, like “crooked”, “drain the swamp”, or “loser” might help predict whether it was him or a staffer doing the tweeting. Let’s fit a logistic regression including some of those keywords as predictors.\r\n\r\n\r\nmodel1 <- logistic_reg() |>\r\n  fit(formula = .source ~ crooked + dumb + emails +\r\n        crowds + hillary + winning + weak,\r\n      data = train)\r\n\r\ntidy(model1)\r\n\r\n# A tibble: 8 × 5\r\n  term        estimate  std.error statistic p.value\r\n  <chr>          <dbl>      <dbl>     <dbl>   <dbl>\r\n1 (Intercept)   -0.112     0.0646  -1.74     0.0820\r\n2 crooked      -10.6       5.61    -1.89     0.0587\r\n3 dumb        -341.    21260.      -0.0160   0.987 \r\n4 emails       310.    31433.       0.00986  0.992 \r\n5 crowds      -338.    20646.      -0.0164   0.987 \r\n6 hillary       -0.430     4.03    -0.107    0.915 \r\n7 winning       15.9      17.4      0.910    0.363 \r\n8 weak        -382.    17063.      -0.0224   0.982 \r\n\r\nThis is a good start. Many of the words we chose are statistically significant predictors. But…\r\n\r\n\r\n# out-of-sample fit\r\ntest |>\r\n  bind_cols(predict(model1, test)) |>\r\n  accuracy(truth = .source, estimate = .pred_class)\r\n\r\n# A tibble: 1 × 3\r\n  .metric  .estimator .estimate\r\n  <chr>    <chr>          <dbl>\r\n1 accuracy binary         0.574\r\n\r\ntest |>\r\n  bind_cols(predict(model1, test)) |>\r\n  conf_mat(truth = .source, estimate = .pred_class) |>\r\n  autoplot(type = 'heatmap')\r\n\r\n\r\n\r\nThe model does a terrible job at out-of-sample prediction. Without a lot of information to go on (most of the tweets don’t contain one of those seven words) it predicts that every tweet but one was written by Trump. This is the hallmark of an underfit model: it doesn’t do any better than a null model that just predicts the most common class for every document.\r\nWhat if we tried the opposite strategy, throwing every word into the model as a predictor? Would that perform better?\r\n\r\n\r\n# overfit\r\nmodel2 <- logistic_reg() |>\r\n  fit(formula = .source ~ .,\r\n      data = train |>\r\n        select(-.id, -.created))\r\n\r\ntidy(model2)\r\n\r\n# A tibble: 1,154 × 5\r\n   term                  estimate    std.error  statistic p.value\r\n   <chr>                    <dbl>        <dbl>      <dbl>   <dbl>\r\n 1 (Intercept)            3.90e15   428433735.   9094235.       0\r\n 2 makeamericagreatagain -8.86e13   429971626.   -206105.       0\r\n 3 of                    -7.64e15   448759429. -17030047.       0\r\n 4 another               -7.14e17 24267182028. -29417291.       0\r\n 5 best                   2.09e17 12899282154.  16201657.       0\r\n 6 `for`                 -1.10e16  7083387182.  -1555081.       0\r\n 7 golf                  -2.56e17 20103285575. -12727981.       0\r\n 8 great                  2.22e16   784001592.  28323501.       0\r\n 9 highly                 5.50e17 44774977456.  12278955.       0\r\n10 thank                  2.00e16  1292951204.  15481633.       0\r\n# ℹ 1,144 more rows\r\n\r\n# in-sample fit\r\ntrain |>\r\n  bind_cols(predict(model2, train)) |>\r\n  accuracy(truth = .source, estimate = .pred_class)\r\n\r\n# A tibble: 1 × 3\r\n  .metric  .estimator .estimate\r\n  <chr>    <chr>          <dbl>\r\n1 accuracy binary         0.995\r\n\r\nClearly, this 1154 parameter model does a great job predicting the training set. But how is the prediction accuracy on the held-out test set?\r\n\r\n\r\n# out-of-sample fit\r\ntest |>\r\n  bind_cols(predict(model2, test)) |>\r\n  accuracy(truth = .source, estimate = .pred_class)\r\n\r\n# A tibble: 1 × 3\r\n  .metric  .estimator .estimate\r\n  <chr>    <chr>          <dbl>\r\n1 accuracy binary         0.527\r\n\r\ntest |>\r\n  bind_cols(predict(model2, test)) |>\r\n  conf_mat(truth = .source, estimate = .pred_class) |>\r\n  autoplot(type = 'heatmap')\r\n\r\n\r\n\r\nThis is a hallmark of overfitting. The model is so complex that it is mistaking noise for signal, incorporating every random word that gets written by Trump of a staffer as a parameter estimate. For example, in the training set, there are 14 tweets that use the word “another”, 10 by Trump and the rest by staffers. The overfit model takes this as evidence that “another” is a Trumpy word. But that’s just a weird eccentricity of the training set; in the test set “another” is used more often by staffers. As a result, the overfit model actually performs worse out-of-sample than the underfit model.\r\nWhile we want the model to do a good job minimizing prediction error in the training data, we also want to impose some constraint on how many words it can assign nonzero coefficients to. This is a job for regularization.\r\nRegularization: Hitting the Sweet Spot\r\nOne way to impose a complexity constraint on our logistic regression model is with the LASSO. This approach estimates a set of coefficients that maximizes the likelihood of the data, subject to the constraint that \\(\\sum |\\beta| < \\frac{1}{\\lambda}\\). In other words, the sum total of the model’s coefficients can’t stray too far from zero. Let’s set that penalty term to 0.01 and see how we do.\r\n\r\n\r\n# fit a regularized model (LASSO)\r\nmodel3 <- logistic_reg(penalty = 0.01, mixture = 1) |>\r\n  set_engine('glmnet') |>\r\n  fit(formula = .source ~ .,\r\n      data = train |>\r\n        select(-.id, -.created))\r\n\r\ntidy(model3)\r\n\r\n# A tibble: 1,154 × 3\r\n   term                  estimate penalty\r\n   <chr>                    <dbl>   <dbl>\r\n 1 (Intercept)              0.501    0.01\r\n 2 makeamericagreatagain    2.66     0.01\r\n 3 of                       0        0.01\r\n 4 another                  0        0.01\r\n 5 best                     0        0.01\r\n 6 `for`                    0        0.01\r\n 7 golf                     0        0.01\r\n 8 great                   -0.527    0.01\r\n 9 highly                   0        0.01\r\n10 thank                    9.84     0.01\r\n# ℹ 1,144 more rows\r\n\r\n# in-sample fit\r\ntrain |>\r\n  bind_cols(predict(model3, train)) |>\r\n  accuracy(truth = .source, estimate = .pred_class)\r\n\r\n# A tibble: 1 × 3\r\n  .metric  .estimator .estimate\r\n  <chr>    <chr>          <dbl>\r\n1 accuracy binary         0.944\r\n\r\n# out-of-sample fit\r\ntest |>\r\n  bind_cols(predict(model3, test)) |>\r\n  accuracy(truth = .source, estimate = .pred_class)\r\n\r\n# A tibble: 1 × 3\r\n  .metric  .estimator .estimate\r\n  <chr>    <chr>          <dbl>\r\n1 accuracy binary         0.798\r\n\r\ntest |>\r\n  bind_cols(predict(model3, test)) |>\r\n  conf_mat(truth = .source, estimate = .pred_class) |>\r\n  autoplot(type = 'heatmap')\r\n\r\n\r\n\r\nRegularization is powerful stuff. Not only does the regularized model perform much better out-of-sample than the first two models, but it gives us a set of 347 nonzero coefficients that we can interpret as the most strongly predictive words for whether a tweet was written by Trump or not.\r\n\r\n\r\ntidy(model3) |> \r\n  filter(estimate != 0) |> \r\n  ggplot(mapping = aes(x = estimate,\r\n                       y = fct_reorder(term, estimate))) + \r\n  geom_col() +\r\n  labs(x = 'Most Trumpy < - > Most Staffer-Speak',\r\n       y = 'Term')\r\n\r\n\r\n\r\nPractice Problems\r\nPlay around with the penalty hyperparameter until you find a better value for than 0.01. See the file code/08_supervised-learning/predicting-trump-tweets-chap23.R in the code repository for instructions more on tuning models through cross-validation with the tidymodels package.\r\nFit a regularized logistic regression to predict whether the unattributed Federalist Papers were written by Hamilton or Madison, using the stop words document-term matrix we created earlier.\r\nFurther Reading\r\nDavid Robinson’s original post.\r\nHvitfeldt & Silge (2022), particularly Chapter 7\r\nGrimmer, Stewart & Roberts, Chapters 17-19\r\n\r\n\r\n\r\nGrimmer, Justin, Margaret E. Roberts, and Brandon M. Stewart. 2022. Text as Data: A New Framework for Machine Learning and the Social Sciences. Princeton, New Jersey Oxford: Princeton University Press.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2025-06-13T14:00:49-04:00"
    },
    {
      "path": "under-construction.html",
      "title": "Under Construction",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2025-06-13T14:00:50-04:00"
    },
    {
      "path": "webscraping.html",
      "title": "Webscraping Tutorial",
      "description": "What to do when you just want text, but the website where the text lives is trying to sell you prescription medications or something.",
      "author": [],
      "contents": "\r\n\r\nContents\r\nThe rvest package\r\nReading HTML\r\nGetting the Right Elements\r\nSelectorGadget\r\n\r\nBeing Polite\r\nPractice Problems\r\n\r\nThe central difficulty we face scraping text data from the web is that web pages are never just text. They come with a whole bunch of other junk to make the text look pretty. That junk is written in HTML (Hypertext Markup Language) code, and our first task as researchers is to separate the plain text we want from all the HTML code that’s making it look pretty.\r\nFor example, suppose for some reason I wanted to know what Tucker Carlson said on his television program on April 20, 2022. The transcript is here, but it’s cluttered. There are graphics, ads, pictures, links to other pages, fonts, and a bunch of other things we don’t need for our research. Fortunately, the plain text of the transcript is hiding in the page’s HTML code, if we know where to look.\r\nThe rvest package\r\nAs of writing, the most user-friendly R package for getting text data from web pages is rvest (read that name like “harvest”, as in harvesting data).\r\nLet’s begin by loading that package.\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(rvest)\r\n\r\n\r\nReading HTML\r\nTo read the HTML from a web page, we can use the read_html() function, just like we would read a data file from our computer. Just supply it with the web page’s URL.\r\n\r\n\r\npage <- read_html('https://www.foxnews.com/transcript/tucker-the-us-is-looking-at-a-grim-economic-picture')\r\n\r\n\r\nGetting the Right Elements\r\nEvery HTML page is divided into sections by tags. If you want to get deep into webscraping, it will be useful to be able to identify some of those tags, because that’s how we’re going to select which elements from a HTML page we want to keep.\r\nFor instance, there is an HTML tag called <p>, which denotes paragraphs of text. To get a list of all elements with the <p> tag on this webpage we loaded, we run the following line of code:\r\n\r\n\r\nparagraphs <- page |>\r\n  html_elements('p')\r\n\r\nparagraphs\r\n\r\n{xml_nodeset (9)}\r\n[1] <p class=\"more-copyright\">\\n        This material may not be pu ...\r\n[2] <p data-v-5f342d4c>Fox News host gives his take on how the U.S. ...\r\n[3] <p class=\"speakable\"><i>This is a rush transcript from \"Tucker  ...\r\n[4] <p class=\"speakable\">TUCKER CARLSON, FOX NEWS CHANNEL HOST, TUC ...\r\n[5] <p class=\"dek\">Get all the stories you need-to-know from the mo ...\r\n[6] <p>By entering your email and clicking the Subscribe button, yo ...\r\n[7] <p class=\"subscribed hide\">Subscribed<\/p>\r\n[8] <p class=\"success hide\">\\n      You've successfully subscribed  ...\r\n[9] <p class=\"copyright\">\\n        This material may not be publish ...\r\n\r\nThis gives us a list with all the raw HTML code. Notice that the 4th entry looks like it has the transcript text we want. To get the plain text from that line of HTML code, we’ll use the html_text() function.\r\n\r\n\r\ntext <- html_text(paragraphs[[4]])\r\n\r\ntext\r\n\r\n[1] \"TUCKER CARLSON, FOX NEWS CHANNEL HOST, TUCKER CARLSON TONIGHT: Good evening. Welcome to TUCKER CARLSON TONIGHT. Happy Monday.Knowing what we know about our current leadership class, the one thing we can be absolutely certain of is they always go too far. They always get over their skis. They just can't help themselves. That's who they are.So, in February, when the Russian military invaded Ukraine, there was always out there the chance that the Biden administration would find a way to turn what was a regional tragedy into something bigger, like a historical global catastrophe. That was always possible.So even before Russian forces entered into Ukraine, the White House promised us that would not happen, quote: \\\"There is no intention or interest or desire by the President to send troops to Ukraine.\\\" That was the word from Biden's publicist from the White House. She said the very same thing almost identically the next month.The month after that, she said it again, quote: \\\"Joe Biden does not have the intention of sending U.S. troops to Ukraine,\\\" Jen Psaki solemnly pledged to the nation. Why did Jen Psaki keep saying the same thing over and over? Well, because it wasn't true. She had to repeat it because it was a lie. That's how lying works. It's not believable so you have to say it again and again and again.If you want if someone is lying, count the times they assert something. The more often they assert it, the less likely it is to be true, but ultimately the truth does come out and this weekend it began to.Joe Biden's top surrogate in the Congress -- that would be Senator Chris Coons of Delaware, a former Biden intern -- appeared on CBS News and said the opposite of what the White House has been telling us for months. Coons demanded that the Pentagon deploy American troops to Ukraine to fight Russian soldiers. Watch.(BEGIN VIDEO CLIP)MARGARET BRENNAN, CBS ANCHOR: In some public remarks this week, you said the country needs to talk about when it might be willing to send troops to Ukraine.SEN. CHRIS COONS (D-DE): If Vladimir Putin, who has shown us how brutal he can be, is allowed to just continue to massacre civilians, to commit war crimes throughout Ukraine, without NATO, without the West coming more forcefully to his aid, I deeply worry that what is going to happen next is that we will see Ukraine turn into Syria.The American people cannot turn away from this tragedy in Ukraine. I think the history of the 21st Century turns on how fiercely we defend freedom in Ukraine and that Putin will only stop when we stop him.(END VIDEO CLIP)CARLSON: \\\"Without the West coming more forcefully to the aid of Ukraine.\\\" So, the Ukrainian military has been trained by NATO. It uses American arms. In some cases, it's being led by Americans. The Ukrainian government is advised directly moment-to-moment by Americans. There are many Americans in Ukraine right now doing that.So, what Chris Coons is calling for is land war with Russia. Now, that's not a small thing, given that once again, Chris Coons is Joe Biden's closest ally in the Senate. Chris Coons is an unfailing and faithful spokesman for the administration's policies, whatever those policies happen to be.So, when Chris Coons calls for war with Russia, he does not do it accidentally and in this case, the White House has not distanced itself from what Chris Coons said. Oh, why? Well, because war with Russia is the administration's actual policy.Leaders of the Democratic Party want to topple the Russian government by force and effect regime change in Russia. They have wanted this since the day that Hillary Clinton lost the 2016 presidential race. We know this because they've said so many, many times and the only reason the rest of us missed it is because we didn't take them seriously enough, but we should have.A Hot War with Vladimir Putin, using American troops, is the logical, maybe inevitable end stage of Russiagate. So, the whole thing began with Hillary Clinton complaining, then the pee tape and now it's moving toward nuclear war.So, what would that look like? A Hot War with Russia? How many Americans would die during that war? How likely is it to escalate to nuclear conflict? And if we succeed, if we remove Vladimir Putin from office, who will replace him as the head of Russia in charge of 6,000 nuclear weapons?Those are some of the first questions that jump to mind when a war with Russia is discussed. But the news reader on CBS, who was interviewing Chris Coons didn't bother to ask any of those questions, nor did she ask the one thing you would need to know if you were running a functioning democracy, which is how many Americans, how many voters, actually want war with Russia? What percentage of the American population believes that Ukraine's borders are worth dying for?That's a central question in a democracy, and as it happens we know the answer, because CBS itself ran a poll on that topic just a week ago, and they asked this question: Should the United States send troops to Ukraine?Answer? Fully 75 percent of Americans said no, the United States should not send troops to Ukraine. And yet, somehow the CBS News reader forgot to mention any of this to Chris Coons. Why? Well, you know why, because in Washington, what you think is irrelevant.Our foreign policy matters of life and death, decisions that destroy nations, are made entirely by people with no skin in the game, people who face no conceivable risk of injury, people like John Bolton, and Max Boot, and Toria Nuland. Your opinion doesn't factor into the equation at any point.So, if you bothered to ask American citizens what they think -- and if you cared about democracy, you would -- they'd likely tell you that their borders are more important to them than Ukraine's borders are. That makes sense because they're Americans, not Ukrainians.And if you ask deeper, you would find out that at the very top of their concerns is not Ukraine. They feel sympathy for the people of Ukraine, but they're not taking up too much disk space brooding about Ukraine moment to moment, because they have other things to worry about, starting with their own economy, especially the cost of food, energy, and housing. They're worried about these things and they're right to be worried.At this point, the United States is looking at a grim economic picture.(BEGIN VIDEO CLIP)NBC REPORTER: Before you pull out that credit card today, beware. If you don't pay it off in full, your interest rate is probably about to jump.The Federal Reserve, the nation's Central Bank, is expected to raise rates by a quarter point today as it tries to throw cold water on runaway inflation.UNIDENTIFIED FEMALE: Every time you go and shop, every, like a price of something has gone up by so much. It's insane.NBC REPORTER: Every American shopper has seen it firsthand. Clothing up 6.5 percent, food up 8.5 percent, electricity up nine percent, used cars up 41 percent, and gasoline up nearly $1.50 from a year ago.UNIDENTIFIED FEMALE: Milk, flour, sugar, cartons of oil, like frying oil - - that's been insane. That's like tripled in price. So, that's been crazy.NBC REPORTER: The highest inflation in 40 years.(END VIDEO CLIP)CARLSON: Highest inflation in 40 years. Those are the official numbers, which of course, bear no resemblance to the day-to-day reality. Everything is much more expensive and that's especially true of the big things. The big things are the most expensive of all. Why is that? Simple, the declining power of U.S. currency has created an unprecedented asset bubble. That means investors around the world are rushing to convert increasingly worthless U.S. dollars into objects that might hold value over time.So, anything tangible costs a lot more, a lot more than it did a year ago. There's no mystery in this. This is exactly what happens when you pump too much money into an economy. The money becomes worth less.So, where is this going? How is it going to unfold? Nobody believes the interest rate rises we're seeing will get inflation under control quickly. So, what happens? Well, at some point consumers will begin to run out of cash to spend. Assets will become too expensive to buy and the average person will have less money to buy them.At the same time that prices are rising, so are taxes. Property taxes are rising in many places in tandem with the real estate bubble. So even if you didn't buy a new house, you will suffer because of that. State income taxes have risen dramatically in places like New York.So, they're getting it from both ends and that means that some people, maybe a lot of people, will start to go broke and as they do go broke, they'll be forced to curtail what they buy.In an economy driven largely by consumer spending, this is a very scary trend. When people stop buying things, the crash comes. So, you can see very clearly where this is going. Everyone in Washington understands exactly where it's going, but instead of taking real steps to fix it, like stop writing these massive spending bills, they're taking everything they can. All the money is still on the table while there still is money.Janet Yellen, the secretary of the Treasury, declared last week, for example, that quote: \\\"We must redouble our efforts to decarbonize our economy.\\\" So, what does that mean exactly? How do you decarbonize an economy? Well, by spending trillions in new stimulus spending on renewable energy schemes that, by the way, are owned by the Chinese government and Democratic donors.See how that works? You pass the cash around while it still exists. Another name for this is looting. It cannot go on forever, by definition, because if the economy tanks, everything resets, not just the economic questions. There could be genuine social and political volatility.Our current conversation can only happen in a country that still believes itself to be rich, but once the country doesn't think it is rich, everything changes. This tells you exactly why our leaders seem so jumpy.It's why they're more determined than ever to move the conversation away from economics, \\\"No talking about economics.\\\" And toward questions of race and obscure sexual politics.Every new moral panic they create -- and they create them by the dozens -- diverts attention away from themselves. They've been doing this for quite a while, since at least the financial crisis.Since that time -- 2008-2009 -- our leaders have been telling us over and over and over again, many books have been written about it, that the central divide in America, the seeping wound, the original sin, is race.Consider the timing. At exactly the moment the U.S. government bailed out Wall Street, not a popular move, use of the terms \\\"race\\\" and \\\"racism\\\" in \\\"The Washington Post,\\\" \\\"The New York Times,\\\" and \\\"U.S.A. Today\\\" jumped by more than 700 percent.So, the official message was really clear: You've got problems and White men caused those problems. The White guys are taking all the money and the perks for themselves and they're holding everyone else down.Now to this day, you hear that constantly, including from Joe Biden. It's the most divisive possible message. It's also, factually speaking, a lie. According to Federal statistics, White men aren't even close to the richest group in the United States. Indian-Americans, Chinese-Americans, Filipinos, Koreans, Indonesians, among others, all have much higher median household incomes than Whites.So, the story is not only destructive of the social fabric, it's not even true. The actual fault line in American life is not color, it is money.The real problem isn't racism, it is wealth distribution. A small number of people, smaller every year, have become richer than anyone else in history. Meanwhile, the rest of the country has stagnated and if you don't believe that, drive out 20 miles from the city center and see how people are doing.So, if the population understood this -- that effectively it's an economics game, it's got nothing to do with racism or transgenders -- the population would be pretty mad about that. Joe Biden and his donors fear that. They don't want you to think about economics. They prefer to keep you paralyzed by guilt and shame and if that doesn't work, they'd rather you worried about Ukraine. \\\"Ukraine is the real scandal where economic problems are Putin's fault.\\\" Watch Joe Biden.(BEGIN VIDEO CLIP)JOE BIDEN (D), PRESIDENT OF THE UNITED STATES: I'm doing everything within my power by executive orders to bring down the price and address the Putin price hike. In fact, we've already made progress since March inflation data was collected.Your family budget, your ability to fill up your tank, none of it should hinge on whether a dictator declares war and commits genocide and a half a world away.(END VIDEO CLIP)CARLSON: So this is their last desperate talking point and it's highly familiar to anyone who's watched American politics for the last six years, \\\"Putin did it.\\\" But it's ridiculous and we feel it's always a moral obligation to rebut it with facts. This chart clearly shows it.Here are several core measures of inflation, they go back to 2011. You notice that all of those measures began spiking in what year -- 2021, right after Joe Biden took office. It was the spending that did it. He's not the only one who spent too much, but he spent the most.Now, Biden could claim the spike started this February and the media would probably protect him, but things have gotten so obvious, economic decline being the one thing you really can't hide because people feel it every single day, that the media are beginning to stop defending him. Watch this.(BEGIN VIDEO CLIP)ED O'KEEFE, CBS NEWS CORRESPONDENT: The White House says those price jumps are happening because of the war in what they call, quote, \\\"Putin's price hike,\\\" But remember, prices started spiking well before the war in Ukraine began.JONATHAN LEMIRE, WHITE HOUSE BUREAU CHIEF, POLITICO: And every time we talk about gas prices, Democrats do, President Biden does as always \\\"Putin's price hike.\\\" They're trying to blame, of course, the Russian President and the invasion of Ukraine for the jump in prices, but of course, as polling suggests, this President is going to take a lot of the blame here.ABC NEW REPORTER: Biden has called it a \\\"Putin price hike,\\\" but most Americans aren't buying it.DON LEMON, CNN ANCHOR: Despite what President Biden says, inflation was a major concern way before Putin's invasion.(END VIDEO CLIP)CARLSON: So, no one's buying it because everyone understands the most simple principle in all economics, which is supply and demand. If you create a lot more money, the money loses its value, obviously, and yet this administration proposes spending even more money at a scale that this country has never seen.The founder of FedEx, Fred Smith, summed it up this way, quote: \\\"Had we passed the Build Back Better bill that Biden wanted, my guess is that we would be Weimar Germany right now. We'd have 25 percent inflation rather than nine percent or 10 percent.\\\"That's all very obvious, and again, you don't need to be running the Fed to understand it. Joe Biden may be the only person who doesn't understand. In this case, he gets a pass because in Joe Biden's head, he's far away, he's somewhere else.Yesterday, for example, Biden was fumbling through questions about foreign policy when a staffer in an Easter Bunny costume appeared out of nowhere and led him away. It's that bad now? How bad is it? Here is Biden in one of the saddest moments of his or any other presidency.This is from last week. Watch.(BEGIN VIDEO CLIP)BIDEN: There's not a single thing America can't do when we do it together as the United States of America. God bless you all.(END VIDEO CLIP)CARLSON: Shaking imaginary hands, wandering off into the great distance. So the one thing we can say with certainty about the White House in the spring of 2022 is that Joe Biden is not running it. Joe Biden is gone. In his place are unelected ideologues, people who do not care what the price of gas is. They don't care if you can afford dinner at Applebee's with your kids. They don't care even if war with Russia could cause the destruction of entire populations. Those things are not interesting to them. They care about theories, not reality.So, improving the life of Americans, elevating the American population, doesn't even rate on their scale of concern. It's a pure afterthought.Now we've known that for a while. They've been in charge for a while and that's been sustainable as long as everyone's getting a check, as long as everyone feels like \\\"I've got enough money,\\\" but the second the economy turns south, the calculation changes completely. Everything is different in a country that believes it is becoming poor. The short-term effect is a peaceful revolt by voting.So, you can be certain of this: If there are free and fair elections this November, neo liberalism will be swept away entirely, revealed as the joke it is. So, the thing to worry about right now is not public opinion. Public opinion is settled. Nobody likes this.The thing to worry about right now is voting, the mechanics of voting. If the public is allowed to express its preference in the midterms, we're done, but will they be allowed? That should be the thing people are paying attention to.So as the Biden administration tells us, once again that the territorial integrity of Ukraine is worth dying for, our country's territorial integrity is not only an afterthought, but a historical footnote. It doesn't exist.Drug cartels, human traffickers, even terrorists are walking into the United States of America totally unimpeded. FOX's Bill Melugin broke this story, as he has so many, he is live on the border for us tonight. Hey, Bill.BILL MELUGIN, FOX NEWS CHANNEL NATIONAL CORRESPONDENT: Tucker, good evening to you.I was able to obtain a C.B.P. record through a Freedom of Information Act request that reveals at least 23 possible terror linked individuals were stopped here at the U.S. Southern border last year. Take a look at this graphic. We'll get right into the numbers.What you're looking at are hits on the T.S.D.B. that is the Terrorist Screening Database of known and suspected terrorists maintained by the F.B.I. and what you see are the different Border Patrol sectors where these hits happened. Four in San Diego sector, four in El Centro, two in Yuma, two in Tucson, three in El Paso sector, four in Del Rio sector and four in the Rio Grande Valley sector, again totaling up to 23.But keep in mind, those are only the ones they caught, only the ones they know about, Tucker.Back out here live, that is a major concern because C.B.P. officials tell us in the last six months alone here at the border, there have been more than 300,000 known gotaways.I'll send it back to you.CARLSON: Amazing. Bill, as you've chronicled for months now, millions of foreign nationals come over, they don't stay in the Rio Grande Valley. There is not the economy or the services to support them. An awful lot of them wind up in Southern California, and when they get there, it is very easy to break the law and not get punished for it.You were instrumental in the documentary we just finished on Los Angeles, it started streaming today, and you have news to report relevant to that story for us tonight. What is it?MELUGIN: Yes, Tucker. That's right. So look, ever since LA DA George Gascon was elected, it's no secret that criminals have been celebrating his soft on crime policies, but never have we seen such a blatant example of this as what your viewers are about to see and hear right now.FOX News has obtained exclusive jailhouse audio of a convicted gang murderer named Luis Angel Hernandez boasting that he is going to get George Gascon's name tattooed on his face and he calls George Gascon a champ for dropping his gang and gun enhancements. Take a listen.(BEGIN AUDIO CLIP)LUIS ANGEL HERNANDEZ, CONVICTED GANG MURDERED: That [bleep] looking real good. Now, we've got a new DA in LA, so they're going to -- I got caught on the 14th, fool.Right there in Compton on Thursday, so, they're going to drop the gang or like gun enhancement, my gang enhancement. My gang enhancement is 10 years, fool, for being a gang member. And then, the gun in the commission of crime.UNIDENTIFIED MALE: Whatever (INAUDIBLE) Gascon or whatever the [bleep].HERNANDEZ: I'm going to get [bleep] name on my face. That's a champ right there. [Bleep] Gascon.UNIDENTIFIED MALE: (INAUDIBLE) for misdemeanor and stuff.HERNANDEZ: That's the [bleep] right there, bro. He is making historic changes for all of us, fool. You know, so, I am just grateful, fool, like I've got good news off that [bleep].So, at least now, I know like, they're' like, \\\"You're coming home, blood.\\\" Like, they are already told me, my lawyer told me, \\\"You're coming home.\\\"(END AUDIO CLIP)MELUGIN: And Tucker, what you heard right there certainly is not an isolated incident. Your documentary also has another murderer from behind his cell in prison toasting one of his cellmates with prison moonshine smiling, saying, \\\"Hey, we're going home on this George Gascon directive.\\\"Your documentary also has jailhouse audio of a 26-year-old transgender child molester boasting that nothing is going to happen to him and he's not going to face any prison time because George Gascon refused to prosecute him as an adult.There is no denying that George Gascon's policies treat criminals with kiddy gloves sometimes, and prosecutors in his office tell me when it comes to George Gascon, DA stands for Defense Attorney.We'll send it back to you.CARLSON: That is effectively true. Bill Melugin, a big part of that documentary. Thanks so much for all the help you gave us.So as we said, we are premiering Season Two of our series, \\\"Tucker Carlson Originals.\\\" The first one came out today and it's really the story of democracy subverted.So you take the second biggest city in the country, LA, and a tiny group of people back, a truly radical prosecutor called George Gascon, the Black Lives Matter people, the defund the police people, airhead celebrities, George Soros -- this guy takes over and one man changes life for everybody in Los Angeles. It's beyond belief.The documentary called \\\"Suicide of LA.\\\" Part one is available right now. Here's a portion of it.(BEGIN VIDEO CLIP)CARLSON: So who exactly supports this? How could a sane person vote for a maniac like George Gascon who is so clearly intent on destroying what previous generations have built?MELUGIN: George Gascon's primary supporters were Black Lives Matter crowd.PATRISSE CULLORS, FOUNDER, BLACK LIVES MATTER: Why has this been called the second most important race in the country next to the Presidency?MELUGIN: George Gascon is supported by the crowd that wants to defund law enforcement.UNIDENTIFIED MALE: Defund the police.GEORGE GASCON, LOS ANGELES COUNTY DISTRICT ATTORNEY: This is really about moving funding around.MELUGIN: He is supported by a large swath of the celebrity crowd.GASCON: Please join me in welcoming the one and only, John Legend.SOPHIA BUSH, ACTRESS: The DA's races are so, so critical to how our cities function and especially here in LA.MELUGIN: And of course, George Soros who has been bankrolling progressive DAs all across the entire country.CARLSON: George Soros donated more than $2 million to George Gascon's campaign, but he wasn't alone. The CEO of Netflix, Reed Hastings and his wife Patty Quillin donated $2.1 million.ALEX VILLANUEVA, LOS ANGELES COUNTY SHERIFF: Oh, yes, this is all funded by Soros and company, and Reed Hastings, all the billionaires up in the Bay Area.CARLSON: The only significant elected official in Los Angeles who opposes George Gascon is the County Sheriff, Alex Villanueva.VILLANUEVA: The problem is here in LA, in city and county government, they occupy every single seat. There is no other point of view other than that woke ideology.You have to operate in the real world, not their fake fantasy. From 2019 to 2021, we saw 94 percent increase in homicides, which is a mind boggling increase. I can't get the Board of Supervisors to even admit that homicides have gone up 95 percent.MELUGIN: I think the understatement of the year would be to say that there is no love lost between George Gascon and LA County Sheriff, Alex Villanueva. They are polar opposites.VILLANUEVA: My lack of relationship with the DA is unprecedented. I've had one phone call with him since he has taken office. That is it.UNIDENTIFIED MALE: Let's start with the rise in crime in LA County. You are the Sheriff. Do you bear any responsibility for that?VILLANUEVA: Well, as I am being defunded and being discredited and delegitimized by our elected officials, it is kind of hard to put the blame on the people who is doing the most of the work.For six months, with Gascon's time in office, he rejected 5,932 cases. That means all those people just walk free.(END VIDEO CLIP)CARLSON: \\\"Suicide of Los Angeles\\\" sadly not an overstatement. Available now on FOX nation. Part Two out tomorrow. You can get a free account on tuckercarlson.com and use it at FOX Nation.So you may have noticed, it's hard to miss it, unequal justice under the law is now the rule. Your punishment depends on your political views.So January 6 defendants been rotting in jail for over a year without bail for nonviolent crimes, but actual criminals like the guy who shot nine people in a South Carolina mall over the weekend, get released on bond for 25 grand. That's the system. Still, straight ahead.(COMMERCIAL BREAK)CARLSON: So the whole point of America is that American laws are applied evenly and fairly to American citizens. They are not even trying anymore to do that.After January 6, the Biden administration placed dozens of its political opponents in solitary for months and months and months, nonviolent protesters who didn't hurt anyone.Meanwhile, actual violent offenders like a guy who just shot nine people in a shopping mall in South Carolina over the weekend are already out of jail. Watch.(BEGIN VIDEO CLIP)UNIDENTIFIED MALE: In Colombia, more than a dozen people injured after gunfire erupted Saturday at a shopping mall. Police believe a dispute among at least three people led to the violence.They charged 22-year-old Jewayne Price with unlawful possession of a gun. He was released on house arrest after a Judge set bond at just $25,000.00 allowing him to go to work with an ankle monitor.(END VIDEO CLIP)CARLSON: The Judge's name in that case is Crystal Rookard by the way. That's her.Buck Sexton is one of the few former C.I.A. officers we trust, our friend, host of \\\"The Clay Travis and Buck Sexton Show,\\\" he joins us now.Buck, thanks so much for coming on. It does seem like the core promise of equal justice has been corroded.BUCK SEXTON, FORMER C.I.A. OFFICER: The Democratic Party has been using prosecutors' offices, not just for social engineering, or you could say, for replacing criminal justice with social justice, but also as a weapon.I mean, the most prominent recent example of this is January 6th, where you have people, let's remind ourselves, they're held because they're either supposed to be a threat to the public, which I don't think any person actually believes, is based in any reality when you're talking about January 6 or a flight risk, which also seems quite strange, considering many of them have already pleaded and they've gotten months, one just actually got off entirely because he was waved into the Capitol.But look at the way the D.O.J. was weaponized against Donald Trump before that. In fact, I would say Republicans have gotten far too used to this whether it's Governor Scott Walker up in Wisconsin or the John Doe Law is being used to go after him, Chris Christie in Bridge-gate. They wanted to lock up Governor McDonnell, former Governor McDonnell of Virginia, his wife for taking gifts if you all remember that at one point. They wanted to go after a Rick Perry when he was the Governor of Texas.These are all prosecutions, by the way that were either in part or in total dramatic overreach, and it always seems to go one way. Where is the equivalent on the other side? That was just off the top of my head. Meanwhile, people who shoot a lot of people get let out on bail because they're not a danger.CARLSON: Twenty five grand for shooting. Nine people are shot in a shopping mall and there is only a gun charge and 25 grand and he's out. I mean, how can that be?SEXTON: We've seen the progressive prosecutors have taken the opinion in city after city at this point, that if they're only honestly softer, more gentle on violent crime across the board, let them out sooner from either a sentence, let them out right away with catch and release bail reform laws, that somehow this will improve the community police relations that we've seen talked about a bit more now in the aftermath of the BLM protests and riots. That hasn't worked at all.They have to admit now across the country that the crime rate has gone up dramatically in pretty much every major city you can think of, not because of COVID, which is one of the lies they told not, because we were cooking the books and trying to create hysteria on TV, but because they have really stupid policies that are reckless and made things worse for everyone.And Tucker, I think they only care about it, which is obvious to everybody now, because crime is a major issue in city after city and they're going into a midterm election and they have people like Gascon and others by the way, Krasner in Philadelphia, Boudin in San Francisco, who just look like lunatics while good people are suffering. They're all Democrats.CARLSON: That's exactly right. Nicely put, the Great Buck Sexton, thank you.SEXTON: Thanks, Tucker.CARLSON: Good to see you.So, the Democratic Party is bracing for total wipeout in the midterms. At this point, they're not even trying to convince you to vote for them, they are trying to take their opponents off the ballot. They're attacking democracy, not letting you vote for people you want to vote for.Here is the latest and most shocking example, a new legal effort underway to keep Marjorie Taylor Greene off the ballot in her own district where she is very popular in the State of Georgia. On what grounds? The left is saying she is guilty of quote, \\\"insurrection.\\\"Marjorie Taylor Greene represents Georgia in this Congress, and she joins us tonight.Congresswoman, thanks so much for coming on. So, they're trying to prevent voters from voting for you. How is that democracy?REP. MARJORIE TAYLOR GREENE (R-GA): Well, it's not, Tucker. That's the thing. These people hate the people in my district so much, they look down on them, because they voted for me and sent me to Washington to fight for the things that most Americans care about, like secure borders, stopping abortion, protecting our Second Amendment, stopping the out of control spending in Washington, and stop funding, never-ending foreign wars and all the insanity that takes place in Washington.Well, I went there and I have been fighting it. And now the progressives, the people that donate, the dark money groups, you know, the 501(c) (3) and the foundations, they've hired up some attorneys from New York who hate the people in my district, and don't believe that they should have the right to elect who they want to send to Washington, which is me. I have overwhelming support in my district, and I'm so thankful for all of them.Well, now they filed a lawsuit because they're trying to rip my name off of the ballot and steal my district's ability to re-elect me and send me back to Congress.CARLSON: So if you can prevent voters from being allowed to vote for the candidate of their choice, which is their constitutional right, then the system is over. Is the Republican Party with all four paws jumping in to help you?GREENE: Not yet. I'm on my own to defend myself. Wonderful people are donating to my campaign, MTGforamerica.com, and I'm so grateful for that. But I have to protect myself. I have to go to Court on Friday and actually be questioned about something I've never been charged with and something I was completely against.And so this is how far it's going, these leftists, these progressives who would rather want -- they'd rather have the judge or bureaucrats making decisions instead of voters, they want to hand that over to them and not let the people in my district to even have the right to vote for me.But no, the Republican Party needs to fight harder, Tucker. You know, there is something that I have learned and I think this is really important. You know, if you can challenge any representative's candidacy or elected office holder, then I bet you we could round up some Republican voters who didn't like Kamala Harris funding rioters, criminal rioters out of jail, or Ilhan Omar or Cori Bush or Maxine Waters inciting riots.You know, I think there is another way to play this game.CARLSON: Well, of course. American citizens have an absolute right to vote for anyone they want to because it is their government, it is self- government, and if you take that away, it's tyranny, obviously.We appreciate your coming on tonight, Congresswoman Marjorie Taylor Greene, of Georgia. Thank you.GREENE: Thank you, Tucker.CARLSON: Pretty shocking medical mystery in the State of New Jersey. Nearly a hundred students who went to a high school nearby have developed the same extremely rare and deadly tumors. Why?Dr. Marc Siegel after the break.(COMMERCIAL BREAK)CARLSON: FOX News Alert: The mask mandate on airlines is dead. Masks are now optional on the biggest U.S. carriers that includes American, Delta, United, Alaska, Southwest. The T.S.A. has also announced it is not going to enforce the mandate anymore. You're not going to get arrested, passengers cheered on many flights when they heard this news in midair.This comes because a Florida Judge has ruled the Biden administration doesn't get to make up the rules because they're not God. This isn't a monarchy, they can't arrest you if you don't comply with their fake rules.Here's one quote from the Judge, quote: \\\"The power to constitutionally release and detain is limited to individuals entering the U.S. from a foreign country.\\\" In other words, you don't get to treat American citizens like an invading army, even as you treat the invaders like they're your own children, which is exactly what they're doing.Anyway, no more mask mandate on planes. Amen.We have been focused on COVID for two years because it's helped a lot of politicians get more powerful, but there are real public health emergencies going on in this country.One of them apparently is unfolding in New Jersey. Dozens of people connected to a single high school in Woodbridge Township are coming down with rare brain tumors. Here's a local news report on it.(BEGIN VIDEO CLIP)UNIDENTIFIED FEMALE: Al Lupiano, an environmental scientist and former resident of Woodbridge Township says he has confirmed 65 cases of people with rare brain tumors.The common denominator, they were all Colonia High School graduates or had worked there.Lupiano was diagnosed 20 years ago and still suffers lingering issues.AL LUPIANO, ENVIRONMENTAL SCIENTIST: Fast forward to August of last year, my sister received the news that she had a primary brain tumor herself, it unfortunately turned out to be stage four glioblastoma. Two hours later, we received information that my wife also had a primary brain tumor.UNIDENTIFIED FEMALE: After his sister sadly passed away less than a month ago, he posted on Facebook calling on all Colonia High School alumni asking if others had brain tumors, and the response was shocking.(END VIDEO CLIP)CARLSON: Shocking is right and scary. What is this exactly? Dr. Marc Siegel joins us tonight to assess -- Doctor.DR. MARC SIEGEL, FOX NEWS CHANNEL MEDICAL CONTRIBUTOR: Tucker, I want to start with a little bit of history. You know, the Middlesex Sampling Plant, which is less than 10 miles away from this high school is part of -- was part of the Manhattan Project that made the first atomic bomb and they had uranium there and they didn't close it until 1967, the same year that Colonia High School opened.And not only that, but reports were that they didn't fully decontaminate that Middlesex Plant until more than 10 years, more than 20 years later, until the 1990s, it wasn't fully decontaminated.And the question is, was there an association between the uranium in that plant and the soil and the radiation in what happened in this high school.Now, let's talk about this high school. Six out of 100,000 people a year get any kind of brain or spinal cord tumor. Very, very rare, but this high school has seen over a hundred brain tumors from 1975 to 2000.You saw Al Lupiano there, he has an acoustic neuroma which is very, very rare. His sister died of a glioblastoma -- terrible, terrible brain tumor.I spoke to our head of Neurosurgery, John Golfinos at NYU who is an expert at this, and also Tom Roland who is an acoustic neuroma expert at NYU, one of the world's best. Both say that a little bit of ionizing radiation, just a small amount in the area is enough to provoke these tumors.Now, we don't know for sure that this is what has gone on, but the Environmental Protection Agency is involved, and the local Department of Health in New Jersey is involved.Tucker, this is what we call a cluster and there are 1,300 students in this school today all wanting to know, do I have risk? Is there radiation here? But you know what I want to add tonight, not just the part about the Manhattan Project, not about just how we dispose of radiation and the issues of our environment, but we need to look beyond the school. We need to look at the entire area around this plant and see and test for radiation in the air and in the soil, Tucker, because people can be hurt and we need to know.CARLSON: Well, that's exactly right. Environmental poisoning is real. It's not just about climate change and COVID. There is a lot going on, and we should pay attention. I appreciate that report.Dr. Marc Siegel, thank you.SIEGEL: Thanks, Tucker.CARLSON: So you've probably eaten a Jimmy John's sandwich, they are all over the country, Jimmy John Liautaud made it. He made millions making sandwiches starting when he was just 19. He never took on debt. Amazing story. Amazing, man. We'll meet him next.(COMMERCIAL BREAK)CARLSON: You've probably had a Jimmy John's sandwich over the years, but if you're like us, you didn't know who Jimmy John was, Jimmy John is Jimmy John Liautaud, he sold most of his company and made billions. He is an amazing person, and politically aware, too.At one point, he came out against Barack Obama and paid the price for that. So we sat down with him for an hour for a new episode of \\\"Tucker Carlson Today\\\" and learned a ton, but mostly we were amused, inspired, engaged. Amazing guy. Here is part of it.(BEGIN VIDEO CLIP)JIMMY JOHN LIAUTAUD, FOUNDER AND FORMER CHAIRMAN OF JIMMY JOHN'S SANDWICH CHAIN: After Obama won his second term, I was completely annihilated and canceled.I'm a hunter, I'm overweight, I'm very, very successful and rich, right? So I get [bleep] beat out of me for all those three things, completely canceled before cancel was cool.But why I want to talk about this is, I had 2,800 restaurants open like 3,000 sold that I had deposits on to open from my operators, and these are mom and pops across America, and they changed the labor law, the definition of what a manager is, minimum wage, insurance, and all of a sudden, I had 3,000 restaurants, each one employing 40 or 50 people, right, and 3,000 restaurants where they just, you know, they just -- virtually, the business just stopped.My mom and pop franchisees were being sued by law firms that lobbied the government, right, for labor from us taking advantage of our people and just became this arduous completely complex -- our mom and pops, you have three -- the average owner had like three and a half stores.I'm incredibly successful, I'm grateful. But what happened was a travesty because it made them -- they were taking all their extra time baking cookies for people that kicked ass and sampling baseball games and building their catering businesses and learning how to run business, and we taught them how to run these businesses.And when we did it with them, and then when the labor laws changed in and middle of the game , we were just sitting there holding the bag, and these mom and pops are now in Court. And then the laws change even further and we became a co-employer, meaning I'm responsible for all the employees in all these sandwich shops all around America so that the big, big law firms could then sue so they could get their money.So I had no idea -- here I was helping Mitt Romney for America, for everybody to have the dream, and I had no idea that I was going to be attacked, and it got so -- anyway, I spend all my time in Court and I did sell the business and I'm happy I did.But this is interesting as well. I've hired a company to go back and do the forensics on where all the money came from and all the attacks, and all the canceling on me, right, it all came from politics, all from the Democratic Party, all supported by them, or their PACs or Soros or whatever it is.And anyway --(END VIDEO CLIP)CARLSON: The guy owned a sandwich shop and he dared to contribute to the wrong candidate and that's what happened to him.But the whole thing is that amazing conversation. What a guy. Jimmy John Liautaud.We're getting up earlier now so you can watch our interviews on FOX Nation, \\\"Tucker Carlson Today\\\" starting at 7:00 AM.Now, we've heard a lot -- we spent a lot of time on the documentary series and we have news to share about that, next.(COMMERCIAL BREAK)CARLSON: So how do you watch the documentaries we make? Our friend, the bestselling author, Shannon Bream is here to tell us.SHANNON BREAM, FOX NEWS CHANNEL CHIEF LEGAL CORRESPONDENT: All right, Tucker. There has been a lot of excitement for Season Two of \\\"Tucker Carlson Originals,\\\" which we got a sneak peek on Friday. I am definitely interested.It is much-watch TV, episodes like \\\"Suicide of Los Angeles,\\\" \\\"Transgressive: The Cult of Confusion,\\\" The Life of a Rock Star: Kid Rock,\\\" and of course everyone is talking about \\\"The End of Men,\\\" some very interesting things in that one.We were flooded with calls and e-mails at FOX this weekend. Everybody wants to know how to watch. I've been confused.But the good news is it's easy. You don't even need to pay for it. Go to tuckercarlson.com. On Tucker's website, you will see something that says free FOX Nation. We want you to click there. Enter your e-mail address and follow the instructions.You can then use your new free account and use it on a phone or tablet. Many say I'd rather watch this on TV, no problem. If you don't have the app on your TV or a TV that doesn't have apps, pick up something like a Roku. It's cheap. It's at a place like Walmart, Target, or Best Buy.Again, it's called Roku, it's about 30 bucks. I am not getting a kickback. I just want you to know.So to recap go to tuckercarlson.com, get the free account, then use it on your phone, iPad or TV. It is that easy.And Tucker, I will not lie, it has been hard for me to sign up, but now I've got it.Content and Programming Copyright 2022 Fox News Network, LLC. ALL RIGHTS RESERVED. Copyright 2022 VIQ Media Transcription, Inc. All materials herein are protected by United States copyright law and may not be reproduced, distributed, transmitted, displayed, published or broadcast without the prior written permission of VIQ Media Transcription, Inc. You may not alter or remove any trademark, copyright or other notice from copies of the content.\"\r\n\r\nSelectorGadget\r\nIf you, like me, do not have a deep knowledge of HTML tags and CSS selectors that you can deploy to find the right element on a page, then the SelectorGadget comes in handy! This is an in-browser tool that was developed alongside the rvest package, which allows you to visit the page you’re scraping and determine what input to html_elements() will get you the section of the page you want.\r\n\r\n\r\n\r\nFigure 1: Keep the text you want, leave out the Amazon ads and whatever Bette Midler tweeted about the baby formula shortage.\r\n\r\n\r\n\r\nIf we use the SelectorGadget on our webpage here, highlighting the elements we want in green and the elements we don’t want in red, it tells us to use the selector .speakable:nth-child(5). Here’s what that complete pipeline looks like:\r\n\r\n\r\ntext <- page |> \r\n  html_elements('.speakable:nth-child(5)') |> \r\n  html_text()\r\n  \r\ntext\r\n\r\n[1] \"TUCKER CARLSON, FOX NEWS CHANNEL HOST, TUCKER CARLSON TONIGHT: Good evening. Welcome to TUCKER CARLSON TONIGHT. Happy Monday.Knowing what we know about our current leadership class, the one thing we can be absolutely certain of is they always go too far. They always get over their skis. They just can't help themselves. That's who they are.So, in February, when the Russian military invaded Ukraine, there was always out there the chance that the Biden administration would find a way to turn what was a regional tragedy into something bigger, like a historical global catastrophe. That was always possible.So even before Russian forces entered into Ukraine, the White House promised us that would not happen, quote: \\\"There is no intention or interest or desire by the President to send troops to Ukraine.\\\" That was the word from Biden's publicist from the White House. She said the very same thing almost identically the next month.The month after that, she said it again, quote: \\\"Joe Biden does not have the intention of sending U.S. troops to Ukraine,\\\" Jen Psaki solemnly pledged to the nation. Why did Jen Psaki keep saying the same thing over and over? Well, because it wasn't true. She had to repeat it because it was a lie. That's how lying works. It's not believable so you have to say it again and again and again.If you want if someone is lying, count the times they assert something. The more often they assert it, the less likely it is to be true, but ultimately the truth does come out and this weekend it began to.Joe Biden's top surrogate in the Congress -- that would be Senator Chris Coons of Delaware, a former Biden intern -- appeared on CBS News and said the opposite of what the White House has been telling us for months. Coons demanded that the Pentagon deploy American troops to Ukraine to fight Russian soldiers. Watch.(BEGIN VIDEO CLIP)MARGARET BRENNAN, CBS ANCHOR: In some public remarks this week, you said the country needs to talk about when it might be willing to send troops to Ukraine.SEN. CHRIS COONS (D-DE): If Vladimir Putin, who has shown us how brutal he can be, is allowed to just continue to massacre civilians, to commit war crimes throughout Ukraine, without NATO, without the West coming more forcefully to his aid, I deeply worry that what is going to happen next is that we will see Ukraine turn into Syria.The American people cannot turn away from this tragedy in Ukraine. I think the history of the 21st Century turns on how fiercely we defend freedom in Ukraine and that Putin will only stop when we stop him.(END VIDEO CLIP)CARLSON: \\\"Without the West coming more forcefully to the aid of Ukraine.\\\" So, the Ukrainian military has been trained by NATO. It uses American arms. In some cases, it's being led by Americans. The Ukrainian government is advised directly moment-to-moment by Americans. There are many Americans in Ukraine right now doing that.So, what Chris Coons is calling for is land war with Russia. Now, that's not a small thing, given that once again, Chris Coons is Joe Biden's closest ally in the Senate. Chris Coons is an unfailing and faithful spokesman for the administration's policies, whatever those policies happen to be.So, when Chris Coons calls for war with Russia, he does not do it accidentally and in this case, the White House has not distanced itself from what Chris Coons said. Oh, why? Well, because war with Russia is the administration's actual policy.Leaders of the Democratic Party want to topple the Russian government by force and effect regime change in Russia. They have wanted this since the day that Hillary Clinton lost the 2016 presidential race. We know this because they've said so many, many times and the only reason the rest of us missed it is because we didn't take them seriously enough, but we should have.A Hot War with Vladimir Putin, using American troops, is the logical, maybe inevitable end stage of Russiagate. So, the whole thing began with Hillary Clinton complaining, then the pee tape and now it's moving toward nuclear war.So, what would that look like? A Hot War with Russia? How many Americans would die during that war? How likely is it to escalate to nuclear conflict? And if we succeed, if we remove Vladimir Putin from office, who will replace him as the head of Russia in charge of 6,000 nuclear weapons?Those are some of the first questions that jump to mind when a war with Russia is discussed. But the news reader on CBS, who was interviewing Chris Coons didn't bother to ask any of those questions, nor did she ask the one thing you would need to know if you were running a functioning democracy, which is how many Americans, how many voters, actually want war with Russia? What percentage of the American population believes that Ukraine's borders are worth dying for?That's a central question in a democracy, and as it happens we know the answer, because CBS itself ran a poll on that topic just a week ago, and they asked this question: Should the United States send troops to Ukraine?Answer? Fully 75 percent of Americans said no, the United States should not send troops to Ukraine. And yet, somehow the CBS News reader forgot to mention any of this to Chris Coons. Why? Well, you know why, because in Washington, what you think is irrelevant.Our foreign policy matters of life and death, decisions that destroy nations, are made entirely by people with no skin in the game, people who face no conceivable risk of injury, people like John Bolton, and Max Boot, and Toria Nuland. Your opinion doesn't factor into the equation at any point.So, if you bothered to ask American citizens what they think -- and if you cared about democracy, you would -- they'd likely tell you that their borders are more important to them than Ukraine's borders are. That makes sense because they're Americans, not Ukrainians.And if you ask deeper, you would find out that at the very top of their concerns is not Ukraine. They feel sympathy for the people of Ukraine, but they're not taking up too much disk space brooding about Ukraine moment to moment, because they have other things to worry about, starting with their own economy, especially the cost of food, energy, and housing. They're worried about these things and they're right to be worried.At this point, the United States is looking at a grim economic picture.(BEGIN VIDEO CLIP)NBC REPORTER: Before you pull out that credit card today, beware. If you don't pay it off in full, your interest rate is probably about to jump.The Federal Reserve, the nation's Central Bank, is expected to raise rates by a quarter point today as it tries to throw cold water on runaway inflation.UNIDENTIFIED FEMALE: Every time you go and shop, every, like a price of something has gone up by so much. It's insane.NBC REPORTER: Every American shopper has seen it firsthand. Clothing up 6.5 percent, food up 8.5 percent, electricity up nine percent, used cars up 41 percent, and gasoline up nearly $1.50 from a year ago.UNIDENTIFIED FEMALE: Milk, flour, sugar, cartons of oil, like frying oil - - that's been insane. That's like tripled in price. So, that's been crazy.NBC REPORTER: The highest inflation in 40 years.(END VIDEO CLIP)CARLSON: Highest inflation in 40 years. Those are the official numbers, which of course, bear no resemblance to the day-to-day reality. Everything is much more expensive and that's especially true of the big things. The big things are the most expensive of all. Why is that? Simple, the declining power of U.S. currency has created an unprecedented asset bubble. That means investors around the world are rushing to convert increasingly worthless U.S. dollars into objects that might hold value over time.So, anything tangible costs a lot more, a lot more than it did a year ago. There's no mystery in this. This is exactly what happens when you pump too much money into an economy. The money becomes worth less.So, where is this going? How is it going to unfold? Nobody believes the interest rate rises we're seeing will get inflation under control quickly. So, what happens? Well, at some point consumers will begin to run out of cash to spend. Assets will become too expensive to buy and the average person will have less money to buy them.At the same time that prices are rising, so are taxes. Property taxes are rising in many places in tandem with the real estate bubble. So even if you didn't buy a new house, you will suffer because of that. State income taxes have risen dramatically in places like New York.So, they're getting it from both ends and that means that some people, maybe a lot of people, will start to go broke and as they do go broke, they'll be forced to curtail what they buy.In an economy driven largely by consumer spending, this is a very scary trend. When people stop buying things, the crash comes. So, you can see very clearly where this is going. Everyone in Washington understands exactly where it's going, but instead of taking real steps to fix it, like stop writing these massive spending bills, they're taking everything they can. All the money is still on the table while there still is money.Janet Yellen, the secretary of the Treasury, declared last week, for example, that quote: \\\"We must redouble our efforts to decarbonize our economy.\\\" So, what does that mean exactly? How do you decarbonize an economy? Well, by spending trillions in new stimulus spending on renewable energy schemes that, by the way, are owned by the Chinese government and Democratic donors.See how that works? You pass the cash around while it still exists. Another name for this is looting. It cannot go on forever, by definition, because if the economy tanks, everything resets, not just the economic questions. There could be genuine social and political volatility.Our current conversation can only happen in a country that still believes itself to be rich, but once the country doesn't think it is rich, everything changes. This tells you exactly why our leaders seem so jumpy.It's why they're more determined than ever to move the conversation away from economics, \\\"No talking about economics.\\\" And toward questions of race and obscure sexual politics.Every new moral panic they create -- and they create them by the dozens -- diverts attention away from themselves. They've been doing this for quite a while, since at least the financial crisis.Since that time -- 2008-2009 -- our leaders have been telling us over and over and over again, many books have been written about it, that the central divide in America, the seeping wound, the original sin, is race.Consider the timing. At exactly the moment the U.S. government bailed out Wall Street, not a popular move, use of the terms \\\"race\\\" and \\\"racism\\\" in \\\"The Washington Post,\\\" \\\"The New York Times,\\\" and \\\"U.S.A. Today\\\" jumped by more than 700 percent.So, the official message was really clear: You've got problems and White men caused those problems. The White guys are taking all the money and the perks for themselves and they're holding everyone else down.Now to this day, you hear that constantly, including from Joe Biden. It's the most divisive possible message. It's also, factually speaking, a lie. According to Federal statistics, White men aren't even close to the richest group in the United States. Indian-Americans, Chinese-Americans, Filipinos, Koreans, Indonesians, among others, all have much higher median household incomes than Whites.So, the story is not only destructive of the social fabric, it's not even true. The actual fault line in American life is not color, it is money.The real problem isn't racism, it is wealth distribution. A small number of people, smaller every year, have become richer than anyone else in history. Meanwhile, the rest of the country has stagnated and if you don't believe that, drive out 20 miles from the city center and see how people are doing.So, if the population understood this -- that effectively it's an economics game, it's got nothing to do with racism or transgenders -- the population would be pretty mad about that. Joe Biden and his donors fear that. They don't want you to think about economics. They prefer to keep you paralyzed by guilt and shame and if that doesn't work, they'd rather you worried about Ukraine. \\\"Ukraine is the real scandal where economic problems are Putin's fault.\\\" Watch Joe Biden.(BEGIN VIDEO CLIP)JOE BIDEN (D), PRESIDENT OF THE UNITED STATES: I'm doing everything within my power by executive orders to bring down the price and address the Putin price hike. In fact, we've already made progress since March inflation data was collected.Your family budget, your ability to fill up your tank, none of it should hinge on whether a dictator declares war and commits genocide and a half a world away.(END VIDEO CLIP)CARLSON: So this is their last desperate talking point and it's highly familiar to anyone who's watched American politics for the last six years, \\\"Putin did it.\\\" But it's ridiculous and we feel it's always a moral obligation to rebut it with facts. This chart clearly shows it.Here are several core measures of inflation, they go back to 2011. You notice that all of those measures began spiking in what year -- 2021, right after Joe Biden took office. It was the spending that did it. He's not the only one who spent too much, but he spent the most.Now, Biden could claim the spike started this February and the media would probably protect him, but things have gotten so obvious, economic decline being the one thing you really can't hide because people feel it every single day, that the media are beginning to stop defending him. Watch this.(BEGIN VIDEO CLIP)ED O'KEEFE, CBS NEWS CORRESPONDENT: The White House says those price jumps are happening because of the war in what they call, quote, \\\"Putin's price hike,\\\" But remember, prices started spiking well before the war in Ukraine began.JONATHAN LEMIRE, WHITE HOUSE BUREAU CHIEF, POLITICO: And every time we talk about gas prices, Democrats do, President Biden does as always \\\"Putin's price hike.\\\" They're trying to blame, of course, the Russian President and the invasion of Ukraine for the jump in prices, but of course, as polling suggests, this President is going to take a lot of the blame here.ABC NEW REPORTER: Biden has called it a \\\"Putin price hike,\\\" but most Americans aren't buying it.DON LEMON, CNN ANCHOR: Despite what President Biden says, inflation was a major concern way before Putin's invasion.(END VIDEO CLIP)CARLSON: So, no one's buying it because everyone understands the most simple principle in all economics, which is supply and demand. If you create a lot more money, the money loses its value, obviously, and yet this administration proposes spending even more money at a scale that this country has never seen.The founder of FedEx, Fred Smith, summed it up this way, quote: \\\"Had we passed the Build Back Better bill that Biden wanted, my guess is that we would be Weimar Germany right now. We'd have 25 percent inflation rather than nine percent or 10 percent.\\\"That's all very obvious, and again, you don't need to be running the Fed to understand it. Joe Biden may be the only person who doesn't understand. In this case, he gets a pass because in Joe Biden's head, he's far away, he's somewhere else.Yesterday, for example, Biden was fumbling through questions about foreign policy when a staffer in an Easter Bunny costume appeared out of nowhere and led him away. It's that bad now? How bad is it? Here is Biden in one of the saddest moments of his or any other presidency.This is from last week. Watch.(BEGIN VIDEO CLIP)BIDEN: There's not a single thing America can't do when we do it together as the United States of America. God bless you all.(END VIDEO CLIP)CARLSON: Shaking imaginary hands, wandering off into the great distance. So the one thing we can say with certainty about the White House in the spring of 2022 is that Joe Biden is not running it. Joe Biden is gone. In his place are unelected ideologues, people who do not care what the price of gas is. They don't care if you can afford dinner at Applebee's with your kids. They don't care even if war with Russia could cause the destruction of entire populations. Those things are not interesting to them. They care about theories, not reality.So, improving the life of Americans, elevating the American population, doesn't even rate on their scale of concern. It's a pure afterthought.Now we've known that for a while. They've been in charge for a while and that's been sustainable as long as everyone's getting a check, as long as everyone feels like \\\"I've got enough money,\\\" but the second the economy turns south, the calculation changes completely. Everything is different in a country that believes it is becoming poor. The short-term effect is a peaceful revolt by voting.So, you can be certain of this: If there are free and fair elections this November, neo liberalism will be swept away entirely, revealed as the joke it is. So, the thing to worry about right now is not public opinion. Public opinion is settled. Nobody likes this.The thing to worry about right now is voting, the mechanics of voting. If the public is allowed to express its preference in the midterms, we're done, but will they be allowed? That should be the thing people are paying attention to.So as the Biden administration tells us, once again that the territorial integrity of Ukraine is worth dying for, our country's territorial integrity is not only an afterthought, but a historical footnote. It doesn't exist.Drug cartels, human traffickers, even terrorists are walking into the United States of America totally unimpeded. FOX's Bill Melugin broke this story, as he has so many, he is live on the border for us tonight. Hey, Bill.BILL MELUGIN, FOX NEWS CHANNEL NATIONAL CORRESPONDENT: Tucker, good evening to you.I was able to obtain a C.B.P. record through a Freedom of Information Act request that reveals at least 23 possible terror linked individuals were stopped here at the U.S. Southern border last year. Take a look at this graphic. We'll get right into the numbers.What you're looking at are hits on the T.S.D.B. that is the Terrorist Screening Database of known and suspected terrorists maintained by the F.B.I. and what you see are the different Border Patrol sectors where these hits happened. Four in San Diego sector, four in El Centro, two in Yuma, two in Tucson, three in El Paso sector, four in Del Rio sector and four in the Rio Grande Valley sector, again totaling up to 23.But keep in mind, those are only the ones they caught, only the ones they know about, Tucker.Back out here live, that is a major concern because C.B.P. officials tell us in the last six months alone here at the border, there have been more than 300,000 known gotaways.I'll send it back to you.CARLSON: Amazing. Bill, as you've chronicled for months now, millions of foreign nationals come over, they don't stay in the Rio Grande Valley. There is not the economy or the services to support them. An awful lot of them wind up in Southern California, and when they get there, it is very easy to break the law and not get punished for it.You were instrumental in the documentary we just finished on Los Angeles, it started streaming today, and you have news to report relevant to that story for us tonight. What is it?MELUGIN: Yes, Tucker. That's right. So look, ever since LA DA George Gascon was elected, it's no secret that criminals have been celebrating his soft on crime policies, but never have we seen such a blatant example of this as what your viewers are about to see and hear right now.FOX News has obtained exclusive jailhouse audio of a convicted gang murderer named Luis Angel Hernandez boasting that he is going to get George Gascon's name tattooed on his face and he calls George Gascon a champ for dropping his gang and gun enhancements. Take a listen.(BEGIN AUDIO CLIP)LUIS ANGEL HERNANDEZ, CONVICTED GANG MURDERED: That [bleep] looking real good. Now, we've got a new DA in LA, so they're going to -- I got caught on the 14th, fool.Right there in Compton on Thursday, so, they're going to drop the gang or like gun enhancement, my gang enhancement. My gang enhancement is 10 years, fool, for being a gang member. And then, the gun in the commission of crime.UNIDENTIFIED MALE: Whatever (INAUDIBLE) Gascon or whatever the [bleep].HERNANDEZ: I'm going to get [bleep] name on my face. That's a champ right there. [Bleep] Gascon.UNIDENTIFIED MALE: (INAUDIBLE) for misdemeanor and stuff.HERNANDEZ: That's the [bleep] right there, bro. He is making historic changes for all of us, fool. You know, so, I am just grateful, fool, like I've got good news off that [bleep].So, at least now, I know like, they're' like, \\\"You're coming home, blood.\\\" Like, they are already told me, my lawyer told me, \\\"You're coming home.\\\"(END AUDIO CLIP)MELUGIN: And Tucker, what you heard right there certainly is not an isolated incident. Your documentary also has another murderer from behind his cell in prison toasting one of his cellmates with prison moonshine smiling, saying, \\\"Hey, we're going home on this George Gascon directive.\\\"Your documentary also has jailhouse audio of a 26-year-old transgender child molester boasting that nothing is going to happen to him and he's not going to face any prison time because George Gascon refused to prosecute him as an adult.There is no denying that George Gascon's policies treat criminals with kiddy gloves sometimes, and prosecutors in his office tell me when it comes to George Gascon, DA stands for Defense Attorney.We'll send it back to you.CARLSON: That is effectively true. Bill Melugin, a big part of that documentary. Thanks so much for all the help you gave us.So as we said, we are premiering Season Two of our series, \\\"Tucker Carlson Originals.\\\" The first one came out today and it's really the story of democracy subverted.So you take the second biggest city in the country, LA, and a tiny group of people back, a truly radical prosecutor called George Gascon, the Black Lives Matter people, the defund the police people, airhead celebrities, George Soros -- this guy takes over and one man changes life for everybody in Los Angeles. It's beyond belief.The documentary called \\\"Suicide of LA.\\\" Part one is available right now. Here's a portion of it.(BEGIN VIDEO CLIP)CARLSON: So who exactly supports this? How could a sane person vote for a maniac like George Gascon who is so clearly intent on destroying what previous generations have built?MELUGIN: George Gascon's primary supporters were Black Lives Matter crowd.PATRISSE CULLORS, FOUNDER, BLACK LIVES MATTER: Why has this been called the second most important race in the country next to the Presidency?MELUGIN: George Gascon is supported by the crowd that wants to defund law enforcement.UNIDENTIFIED MALE: Defund the police.GEORGE GASCON, LOS ANGELES COUNTY DISTRICT ATTORNEY: This is really about moving funding around.MELUGIN: He is supported by a large swath of the celebrity crowd.GASCON: Please join me in welcoming the one and only, John Legend.SOPHIA BUSH, ACTRESS: The DA's races are so, so critical to how our cities function and especially here in LA.MELUGIN: And of course, George Soros who has been bankrolling progressive DAs all across the entire country.CARLSON: George Soros donated more than $2 million to George Gascon's campaign, but he wasn't alone. The CEO of Netflix, Reed Hastings and his wife Patty Quillin donated $2.1 million.ALEX VILLANUEVA, LOS ANGELES COUNTY SHERIFF: Oh, yes, this is all funded by Soros and company, and Reed Hastings, all the billionaires up in the Bay Area.CARLSON: The only significant elected official in Los Angeles who opposes George Gascon is the County Sheriff, Alex Villanueva.VILLANUEVA: The problem is here in LA, in city and county government, they occupy every single seat. There is no other point of view other than that woke ideology.You have to operate in the real world, not their fake fantasy. From 2019 to 2021, we saw 94 percent increase in homicides, which is a mind boggling increase. I can't get the Board of Supervisors to even admit that homicides have gone up 95 percent.MELUGIN: I think the understatement of the year would be to say that there is no love lost between George Gascon and LA County Sheriff, Alex Villanueva. They are polar opposites.VILLANUEVA: My lack of relationship with the DA is unprecedented. I've had one phone call with him since he has taken office. That is it.UNIDENTIFIED MALE: Let's start with the rise in crime in LA County. You are the Sheriff. Do you bear any responsibility for that?VILLANUEVA: Well, as I am being defunded and being discredited and delegitimized by our elected officials, it is kind of hard to put the blame on the people who is doing the most of the work.For six months, with Gascon's time in office, he rejected 5,932 cases. That means all those people just walk free.(END VIDEO CLIP)CARLSON: \\\"Suicide of Los Angeles\\\" sadly not an overstatement. Available now on FOX nation. Part Two out tomorrow. You can get a free account on tuckercarlson.com and use it at FOX Nation.So you may have noticed, it's hard to miss it, unequal justice under the law is now the rule. Your punishment depends on your political views.So January 6 defendants been rotting in jail for over a year without bail for nonviolent crimes, but actual criminals like the guy who shot nine people in a South Carolina mall over the weekend, get released on bond for 25 grand. That's the system. Still, straight ahead.(COMMERCIAL BREAK)CARLSON: So the whole point of America is that American laws are applied evenly and fairly to American citizens. They are not even trying anymore to do that.After January 6, the Biden administration placed dozens of its political opponents in solitary for months and months and months, nonviolent protesters who didn't hurt anyone.Meanwhile, actual violent offenders like a guy who just shot nine people in a shopping mall in South Carolina over the weekend are already out of jail. Watch.(BEGIN VIDEO CLIP)UNIDENTIFIED MALE: In Colombia, more than a dozen people injured after gunfire erupted Saturday at a shopping mall. Police believe a dispute among at least three people led to the violence.They charged 22-year-old Jewayne Price with unlawful possession of a gun. He was released on house arrest after a Judge set bond at just $25,000.00 allowing him to go to work with an ankle monitor.(END VIDEO CLIP)CARLSON: The Judge's name in that case is Crystal Rookard by the way. That's her.Buck Sexton is one of the few former C.I.A. officers we trust, our friend, host of \\\"The Clay Travis and Buck Sexton Show,\\\" he joins us now.Buck, thanks so much for coming on. It does seem like the core promise of equal justice has been corroded.BUCK SEXTON, FORMER C.I.A. OFFICER: The Democratic Party has been using prosecutors' offices, not just for social engineering, or you could say, for replacing criminal justice with social justice, but also as a weapon.I mean, the most prominent recent example of this is January 6th, where you have people, let's remind ourselves, they're held because they're either supposed to be a threat to the public, which I don't think any person actually believes, is based in any reality when you're talking about January 6 or a flight risk, which also seems quite strange, considering many of them have already pleaded and they've gotten months, one just actually got off entirely because he was waved into the Capitol.But look at the way the D.O.J. was weaponized against Donald Trump before that. In fact, I would say Republicans have gotten far too used to this whether it's Governor Scott Walker up in Wisconsin or the John Doe Law is being used to go after him, Chris Christie in Bridge-gate. They wanted to lock up Governor McDonnell, former Governor McDonnell of Virginia, his wife for taking gifts if you all remember that at one point. They wanted to go after a Rick Perry when he was the Governor of Texas.These are all prosecutions, by the way that were either in part or in total dramatic overreach, and it always seems to go one way. Where is the equivalent on the other side? That was just off the top of my head. Meanwhile, people who shoot a lot of people get let out on bail because they're not a danger.CARLSON: Twenty five grand for shooting. Nine people are shot in a shopping mall and there is only a gun charge and 25 grand and he's out. I mean, how can that be?SEXTON: We've seen the progressive prosecutors have taken the opinion in city after city at this point, that if they're only honestly softer, more gentle on violent crime across the board, let them out sooner from either a sentence, let them out right away with catch and release bail reform laws, that somehow this will improve the community police relations that we've seen talked about a bit more now in the aftermath of the BLM protests and riots. That hasn't worked at all.They have to admit now across the country that the crime rate has gone up dramatically in pretty much every major city you can think of, not because of COVID, which is one of the lies they told not, because we were cooking the books and trying to create hysteria on TV, but because they have really stupid policies that are reckless and made things worse for everyone.And Tucker, I think they only care about it, which is obvious to everybody now, because crime is a major issue in city after city and they're going into a midterm election and they have people like Gascon and others by the way, Krasner in Philadelphia, Boudin in San Francisco, who just look like lunatics while good people are suffering. They're all Democrats.CARLSON: That's exactly right. Nicely put, the Great Buck Sexton, thank you.SEXTON: Thanks, Tucker.CARLSON: Good to see you.So, the Democratic Party is bracing for total wipeout in the midterms. At this point, they're not even trying to convince you to vote for them, they are trying to take their opponents off the ballot. They're attacking democracy, not letting you vote for people you want to vote for.Here is the latest and most shocking example, a new legal effort underway to keep Marjorie Taylor Greene off the ballot in her own district where she is very popular in the State of Georgia. On what grounds? The left is saying she is guilty of quote, \\\"insurrection.\\\"Marjorie Taylor Greene represents Georgia in this Congress, and she joins us tonight.Congresswoman, thanks so much for coming on. So, they're trying to prevent voters from voting for you. How is that democracy?REP. MARJORIE TAYLOR GREENE (R-GA): Well, it's not, Tucker. That's the thing. These people hate the people in my district so much, they look down on them, because they voted for me and sent me to Washington to fight for the things that most Americans care about, like secure borders, stopping abortion, protecting our Second Amendment, stopping the out of control spending in Washington, and stop funding, never-ending foreign wars and all the insanity that takes place in Washington.Well, I went there and I have been fighting it. And now the progressives, the people that donate, the dark money groups, you know, the 501(c) (3) and the foundations, they've hired up some attorneys from New York who hate the people in my district, and don't believe that they should have the right to elect who they want to send to Washington, which is me. I have overwhelming support in my district, and I'm so thankful for all of them.Well, now they filed a lawsuit because they're trying to rip my name off of the ballot and steal my district's ability to re-elect me and send me back to Congress.CARLSON: So if you can prevent voters from being allowed to vote for the candidate of their choice, which is their constitutional right, then the system is over. Is the Republican Party with all four paws jumping in to help you?GREENE: Not yet. I'm on my own to defend myself. Wonderful people are donating to my campaign, MTGforamerica.com, and I'm so grateful for that. But I have to protect myself. I have to go to Court on Friday and actually be questioned about something I've never been charged with and something I was completely against.And so this is how far it's going, these leftists, these progressives who would rather want -- they'd rather have the judge or bureaucrats making decisions instead of voters, they want to hand that over to them and not let the people in my district to even have the right to vote for me.But no, the Republican Party needs to fight harder, Tucker. You know, there is something that I have learned and I think this is really important. You know, if you can challenge any representative's candidacy or elected office holder, then I bet you we could round up some Republican voters who didn't like Kamala Harris funding rioters, criminal rioters out of jail, or Ilhan Omar or Cori Bush or Maxine Waters inciting riots.You know, I think there is another way to play this game.CARLSON: Well, of course. American citizens have an absolute right to vote for anyone they want to because it is their government, it is self- government, and if you take that away, it's tyranny, obviously.We appreciate your coming on tonight, Congresswoman Marjorie Taylor Greene, of Georgia. Thank you.GREENE: Thank you, Tucker.CARLSON: Pretty shocking medical mystery in the State of New Jersey. Nearly a hundred students who went to a high school nearby have developed the same extremely rare and deadly tumors. Why?Dr. Marc Siegel after the break.(COMMERCIAL BREAK)CARLSON: FOX News Alert: The mask mandate on airlines is dead. Masks are now optional on the biggest U.S. carriers that includes American, Delta, United, Alaska, Southwest. The T.S.A. has also announced it is not going to enforce the mandate anymore. You're not going to get arrested, passengers cheered on many flights when they heard this news in midair.This comes because a Florida Judge has ruled the Biden administration doesn't get to make up the rules because they're not God. This isn't a monarchy, they can't arrest you if you don't comply with their fake rules.Here's one quote from the Judge, quote: \\\"The power to constitutionally release and detain is limited to individuals entering the U.S. from a foreign country.\\\" In other words, you don't get to treat American citizens like an invading army, even as you treat the invaders like they're your own children, which is exactly what they're doing.Anyway, no more mask mandate on planes. Amen.We have been focused on COVID for two years because it's helped a lot of politicians get more powerful, but there are real public health emergencies going on in this country.One of them apparently is unfolding in New Jersey. Dozens of people connected to a single high school in Woodbridge Township are coming down with rare brain tumors. Here's a local news report on it.(BEGIN VIDEO CLIP)UNIDENTIFIED FEMALE: Al Lupiano, an environmental scientist and former resident of Woodbridge Township says he has confirmed 65 cases of people with rare brain tumors.The common denominator, they were all Colonia High School graduates or had worked there.Lupiano was diagnosed 20 years ago and still suffers lingering issues.AL LUPIANO, ENVIRONMENTAL SCIENTIST: Fast forward to August of last year, my sister received the news that she had a primary brain tumor herself, it unfortunately turned out to be stage four glioblastoma. Two hours later, we received information that my wife also had a primary brain tumor.UNIDENTIFIED FEMALE: After his sister sadly passed away less than a month ago, he posted on Facebook calling on all Colonia High School alumni asking if others had brain tumors, and the response was shocking.(END VIDEO CLIP)CARLSON: Shocking is right and scary. What is this exactly? Dr. Marc Siegel joins us tonight to assess -- Doctor.DR. MARC SIEGEL, FOX NEWS CHANNEL MEDICAL CONTRIBUTOR: Tucker, I want to start with a little bit of history. You know, the Middlesex Sampling Plant, which is less than 10 miles away from this high school is part of -- was part of the Manhattan Project that made the first atomic bomb and they had uranium there and they didn't close it until 1967, the same year that Colonia High School opened.And not only that, but reports were that they didn't fully decontaminate that Middlesex Plant until more than 10 years, more than 20 years later, until the 1990s, it wasn't fully decontaminated.And the question is, was there an association between the uranium in that plant and the soil and the radiation in what happened in this high school.Now, let's talk about this high school. Six out of 100,000 people a year get any kind of brain or spinal cord tumor. Very, very rare, but this high school has seen over a hundred brain tumors from 1975 to 2000.You saw Al Lupiano there, he has an acoustic neuroma which is very, very rare. His sister died of a glioblastoma -- terrible, terrible brain tumor.I spoke to our head of Neurosurgery, John Golfinos at NYU who is an expert at this, and also Tom Roland who is an acoustic neuroma expert at NYU, one of the world's best. Both say that a little bit of ionizing radiation, just a small amount in the area is enough to provoke these tumors.Now, we don't know for sure that this is what has gone on, but the Environmental Protection Agency is involved, and the local Department of Health in New Jersey is involved.Tucker, this is what we call a cluster and there are 1,300 students in this school today all wanting to know, do I have risk? Is there radiation here? But you know what I want to add tonight, not just the part about the Manhattan Project, not about just how we dispose of radiation and the issues of our environment, but we need to look beyond the school. We need to look at the entire area around this plant and see and test for radiation in the air and in the soil, Tucker, because people can be hurt and we need to know.CARLSON: Well, that's exactly right. Environmental poisoning is real. It's not just about climate change and COVID. There is a lot going on, and we should pay attention. I appreciate that report.Dr. Marc Siegel, thank you.SIEGEL: Thanks, Tucker.CARLSON: So you've probably eaten a Jimmy John's sandwich, they are all over the country, Jimmy John Liautaud made it. He made millions making sandwiches starting when he was just 19. He never took on debt. Amazing story. Amazing, man. We'll meet him next.(COMMERCIAL BREAK)CARLSON: You've probably had a Jimmy John's sandwich over the years, but if you're like us, you didn't know who Jimmy John was, Jimmy John is Jimmy John Liautaud, he sold most of his company and made billions. He is an amazing person, and politically aware, too.At one point, he came out against Barack Obama and paid the price for that. So we sat down with him for an hour for a new episode of \\\"Tucker Carlson Today\\\" and learned a ton, but mostly we were amused, inspired, engaged. Amazing guy. Here is part of it.(BEGIN VIDEO CLIP)JIMMY JOHN LIAUTAUD, FOUNDER AND FORMER CHAIRMAN OF JIMMY JOHN'S SANDWICH CHAIN: After Obama won his second term, I was completely annihilated and canceled.I'm a hunter, I'm overweight, I'm very, very successful and rich, right? So I get [bleep] beat out of me for all those three things, completely canceled before cancel was cool.But why I want to talk about this is, I had 2,800 restaurants open like 3,000 sold that I had deposits on to open from my operators, and these are mom and pops across America, and they changed the labor law, the definition of what a manager is, minimum wage, insurance, and all of a sudden, I had 3,000 restaurants, each one employing 40 or 50 people, right, and 3,000 restaurants where they just, you know, they just -- virtually, the business just stopped.My mom and pop franchisees were being sued by law firms that lobbied the government, right, for labor from us taking advantage of our people and just became this arduous completely complex -- our mom and pops, you have three -- the average owner had like three and a half stores.I'm incredibly successful, I'm grateful. But what happened was a travesty because it made them -- they were taking all their extra time baking cookies for people that kicked ass and sampling baseball games and building their catering businesses and learning how to run business, and we taught them how to run these businesses.And when we did it with them, and then when the labor laws changed in and middle of the game , we were just sitting there holding the bag, and these mom and pops are now in Court. And then the laws change even further and we became a co-employer, meaning I'm responsible for all the employees in all these sandwich shops all around America so that the big, big law firms could then sue so they could get their money.So I had no idea -- here I was helping Mitt Romney for America, for everybody to have the dream, and I had no idea that I was going to be attacked, and it got so -- anyway, I spend all my time in Court and I did sell the business and I'm happy I did.But this is interesting as well. I've hired a company to go back and do the forensics on where all the money came from and all the attacks, and all the canceling on me, right, it all came from politics, all from the Democratic Party, all supported by them, or their PACs or Soros or whatever it is.And anyway --(END VIDEO CLIP)CARLSON: The guy owned a sandwich shop and he dared to contribute to the wrong candidate and that's what happened to him.But the whole thing is that amazing conversation. What a guy. Jimmy John Liautaud.We're getting up earlier now so you can watch our interviews on FOX Nation, \\\"Tucker Carlson Today\\\" starting at 7:00 AM.Now, we've heard a lot -- we spent a lot of time on the documentary series and we have news to share about that, next.(COMMERCIAL BREAK)CARLSON: So how do you watch the documentaries we make? Our friend, the bestselling author, Shannon Bream is here to tell us.SHANNON BREAM, FOX NEWS CHANNEL CHIEF LEGAL CORRESPONDENT: All right, Tucker. There has been a lot of excitement for Season Two of \\\"Tucker Carlson Originals,\\\" which we got a sneak peek on Friday. I am definitely interested.It is much-watch TV, episodes like \\\"Suicide of Los Angeles,\\\" \\\"Transgressive: The Cult of Confusion,\\\" The Life of a Rock Star: Kid Rock,\\\" and of course everyone is talking about \\\"The End of Men,\\\" some very interesting things in that one.We were flooded with calls and e-mails at FOX this weekend. Everybody wants to know how to watch. I've been confused.But the good news is it's easy. You don't even need to pay for it. Go to tuckercarlson.com. On Tucker's website, you will see something that says free FOX Nation. We want you to click there. Enter your e-mail address and follow the instructions.You can then use your new free account and use it on a phone or tablet. Many say I'd rather watch this on TV, no problem. If you don't have the app on your TV or a TV that doesn't have apps, pick up something like a Roku. It's cheap. It's at a place like Walmart, Target, or Best Buy.Again, it's called Roku, it's about 30 bucks. I am not getting a kickback. I just want you to know.So to recap go to tuckercarlson.com, get the free account, then use it on your phone, iPad or TV. It is that easy.And Tucker, I will not lie, it has been hard for me to sign up, but now I've got it.Content and Programming Copyright 2022 Fox News Network, LLC. ALL RIGHTS RESERVED. Copyright 2022 VIQ Media Transcription, Inc. All materials herein are protected by United States copyright law and may not be reproduced, distributed, transmitted, displayed, published or broadcast without the prior written permission of VIQ Media Transcription, Inc. You may not alter or remove any trademark, copyright or other notice from copies of the content.\"\r\n\r\nBeing Polite\r\nIf you plan to use lots of webscraping for your research, it would be wise to brush up on etiquette. Some sites (like Facebook) explicitly ban scraping in their Terms of Service, and even sites that do permit scraping would prefer you didn’t overload them with automated requests. You know how people talk about bots destroying the Internet? Well, you’ve just created a bot, and it’s incumbent on you to use it wisely. The polite package is a good place to get started.\r\nPractice Problems\r\nScrape the transcript from the Rachel Maddow Show on May 11, 2022.\r\nScrape the text of Federalist Papers No. 10.\r\nScrape the text of the US Congressional Record (Senate - May 16, 2022).\r\nScrape the text of The Patient Protection and Affordable Care Act (March 23, 2010).\r\n\r\n\r\n\r\n",
      "last_modified": "2025-06-13T14:00:53-04:00"
    },
    {
      "path": "word-embeddings.html",
      "title": "Text Embeddings",
      "description": "How to quantify what text *means*.\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nRetrieving Embeddings\r\nPractice Problems\r\nFurther Reading\r\n\r\n\r\n\r\n\r\nOften, we’d like to not only count the frequency of words, but also get a sense of what the words mean. In a bag of words representation, we treat words words like “president” and “executive” as separate indices in a word count vector, implicitly assuming that they have completely unique meanings. But the statistical models we use to understand text data will perform better if words with similar meaning have similar representations. That is the purpose of the embeddings approach, which represents each word (or document) as a vector, encoding the fact that “president” and “executive” have some overlapping meaning by placing their vectors close together.\r\nIn this exercise, we’ll work with a set of pretrained text embeddings from OpenAI. These off-the-shelf embeddings tend to do a pretty good job at capturing meaning, even for political science specific applications (Rodriguez and Spirling 2021).1\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(tidytext)\r\nlibrary(fuzzylink)\r\n\r\n\r\nThe fuzzylink R package contains a convenience function called get_embeddings() which we will use for this exercise. You will need an account with OpenAI and an API key. Once you have your API key, you should save it to your R environment with the following line of code (pasting in your key):\r\nfuzzylink::openai_api_key('<YOUR API KEY GOES HERE>', install = TRUE)\r\nFor more information on setup, see the package documentation.\r\nRetrieving Embeddings\r\nTo retrieve text embeddings, create a list of words you want to embed, and input the list into the get_embeddings() funtion. The result is a matrix where each row is a 256-dimensional vector representing its meaning\r\n\r\n\r\nwords <- c('president', 'executive', 'legislative',\r\n           'judicial', 'banana')\r\n\r\nembeddings <- get_embeddings(words)\r\n\r\nembeddings['president',]\r\n\r\n  [1] -0.0099220990  0.0766712200 -0.0199635620  0.0252652970\r\n  [5]  0.0609152280  0.0248276300 -0.0137964430  0.1803186200\r\n  [9]  0.0088428540  0.0738860740  0.0068534603  0.0810081000\r\n [13] -0.1431567500 -0.0838728250 -0.1040054860  0.0196253660\r\n [17] -0.0331631900  0.0466313800 -0.0827587700 -0.0937402200\r\n [21] -0.0416976850 -0.0347944900 -0.0314125230 -0.0205902220\r\n [25]  0.0786208300  0.0137168680  0.0044910560 -0.0268966000\r\n [29] -0.0183223130  0.0173176700 -0.0522016850  0.1741117100\r\n [33] -0.0166313300 -0.0074801194  0.0234947370  0.0376393240\r\n [37]  0.0292042960 -0.0199337230  0.0753980100 -0.0785014600\r\n [41] -0.0606765000 -0.0111406040 -0.0729709500  0.0175464500\r\n [45]  0.0152089130  0.0991513650 -0.0432494130 -0.0176658130\r\n [49]  0.0628648300  0.0574934700 -0.0049162884  0.0615518300\r\n [53]  0.0687136500  0.0512069870 -0.0481433200  0.0196949950\r\n [57]  0.0754378000 -0.0744033160 -0.0464722300 -0.1178516700\r\n [61] -0.0036754042 -0.0280305540 -0.0993901000  0.0649338000\r\n [65]  0.0283289630 -0.0582892260  0.0547481070  0.0954908900\r\n [69] -0.0713794400  0.1036871800  0.0419364120 -0.0612733180\r\n [73] -0.0300398410  0.0394695660  0.0252851900  0.0343767180\r\n [77] -0.0451194420 -0.0220225840 -0.0052271313  0.0238926150\r\n [81]  0.0718966800  0.0091512100  0.1890719500  0.0022442844\r\n [85] -0.0673608600 -0.0406632000 -0.0243103880 -0.2250401800\r\n [89] -0.0202520250 -0.0209881010  0.0949338500 -0.0085444450\r\n [93] -0.1005041500  0.0334218100  0.1233423950 -0.0276326740\r\n [97]  0.0009455836 -0.0925465800 -0.0023002361 -0.1351991700\r\n[101] -0.1847748600  0.0175762900 -0.0495756830  0.0844298600\r\n[105]  0.0367440950 -0.0153581170 -0.0169496310 -0.0167208520\r\n[109] -0.0108421940 -0.0057443734 -0.0378382600 -0.0249469930\r\n[113]  0.0616711970  0.0419762020 -0.0389921100 -0.0018986274\r\n[117] -0.0524802000  0.0634218600 -0.0489390800 -0.0292639770\r\n[121] -0.0885677900 -0.0781035900 -0.0700266500 -0.0677587400\r\n[125]  0.0272347960 -0.0200829260  0.0352719460  0.0755571650\r\n[129] -0.0342772500 -0.0891248300 -0.1087004540  0.0732892500\r\n[133] -0.0523210470  0.0311539000 -0.0269363880  0.0644563400\r\n[137] -0.0368833540  0.0295225980 -0.0098773380  0.0288263110\r\n[141] -0.0845890100  0.0555040760 -0.0737667100 -0.0824404660\r\n[145]  0.1198410600  0.0111008160  0.0958091840 -0.0849868900\r\n[149]  0.1369498400 -0.0233156900 -0.0167606400 -0.0441645350\r\n[153]  0.0096883460  0.0936606450 -0.0250464640 -0.0005632470\r\n[157] -0.0266976600  0.0017257988 -0.0398276560 -0.0407029900\r\n[161] -0.0054956990  0.0649338000  0.0006247939  0.0366645200\r\n[165]  0.0014920451 -0.0197646250  0.0461937150 -0.0389722180\r\n[169] -0.0204509650  0.0354311000 -0.0101210390 -0.0370027160\r\n[173] -0.0724934900 -0.0792574360 -0.0487799270  0.0452785940\r\n[177]  0.1032097340 -0.0380372030  0.0333223380  0.0388926400\r\n[181]  0.0386738070  0.0104841030  0.0401857460 -0.0229973890\r\n[185] -0.0582494400  0.0511274100  0.0436870800 -0.0426525960\r\n[189] -0.0559019560 -0.1176129360  0.0191578590 -0.0106830430\r\n[193] -0.0413395950 -0.0680372600  0.0723741350 -0.0612733180\r\n[197]  0.0842707100 -0.0682759800 -0.0617507730 -0.0781831600\r\n[201]  0.0608754400  0.0144131560  0.0340783100  0.0523210470\r\n[205] -0.1024139750 -0.0218634340  0.0672812800  0.0266180840\r\n[209] -0.1051195500  0.0763529200  0.1281169400 -0.0834749500\r\n[213]  0.1232628150  0.0028125050 -0.0533157440 -0.0012222336\r\n[217] -0.0557030140  0.0116180570  0.0169197920 -0.0606367100\r\n[221]  0.0989126400 -0.0796553100 -0.0540717130  0.0386141280\r\n[225]  0.0492573830 -0.0727322250 -0.0706632500  0.0788197700\r\n[229] -0.0206300100  0.0524404120 -0.0196054730  0.0709019800\r\n[233]  0.0312334760  0.0537534100 -0.0996288200  0.0432892000\r\n[237]  0.0310942200  0.0936606450  0.0048068720  0.0605173500\r\n[241]  0.0012707250  0.0154376930 -0.0077835020  0.0484616230\r\n[245]  0.0603979830  0.0221817360 -0.1143503340 -0.0328249930\r\n[249] -0.0284483270 -0.0685147100 -0.0258024330  0.0026359463\r\n[253] -0.0003332234 -0.0169794730  0.0649338000 -0.0030984802\r\n\r\nIt’s difficult to visualize and interpret a 256-dimensional vector space, but we can explore which words have similar meaning by looking at their cosine similarity. The get_similarity_matrix() function returns cosine similarity for each pair of vectors in an embedding matrix (or a subset of those vectors if you prefer)\r\n\r\n\r\nget_similarity_matrix(embeddings)\r\n\r\n            president executive legislative  judicial    banana\r\npresident   0.9999999 0.6483657   0.4321773 0.4690661 0.3034118\r\nexecutive   0.6483657 1.0000001   0.5697680 0.5728509 0.2424244\r\nlegislative 0.4321773 0.5697680   1.0000000 0.6276265 0.1904764\r\njudicial    0.4690661 0.5728509   0.6276265 1.0000000 0.1964824\r\nbanana      0.3034118 0.2424244   0.1904764 0.1964824 1.0000000\r\n\r\nget_similarity_matrix(embeddings,\r\n                      'president',\r\n                      c('executive', 'banana'))\r\n\r\n          executive    banana\r\npresident 0.6483657 0.3034118\r\n\r\nThis is how large language models like ChatGPT encode meaning, and it seems to do a pretty good job! Pairs of words with similar meaning have higher cosine similarity scores. In the next module we’ll explore how to use these embedding representations to fit models for discovery, prediction, measurement, and inference.\r\nPractice Problems\r\nExplore some of the stereotypes reflected in the OpenAI embeddings. How close is the word “professor” to female names compared to male names? Hispanic names?\r\nWhat about words that are ambiguous without context, like “bill” or “share”? What are their nearest neighbors?\r\nFurther Reading\r\nGrimmer, Stewart, and Roberts (2021), Chapter 8.\r\nHvitfeldt & Silge, Chapter 5.\r\n\r\n\r\n\r\nGrimmer, Justin, Brandon M. Stewart, and Margaret E. Roberts. 2021. Text as Data: A New Framework for Machine Learning and the Social Sciences. S.l.: Princeton University Press.\r\n\r\n\r\nRodriguez, Pedro L., and Arthur Spirling. 2021. “Word Embeddings: What Works, What Doesn’t, and How to Tell the Difference for Applied Research.” The Journal of Politics, May, 000–000. https://doi.org/10.1086/715162.\r\n\r\n\r\nSee code/03_word-embeddings/federalist-embeddings.R if you are interested in how to train word embeddings on your own corpus.↩︎\r\n",
      "last_modified": "2025-06-13T14:00:58-04:00"
    }
  ],
  "collections": []
}
