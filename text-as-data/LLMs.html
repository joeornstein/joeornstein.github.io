<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  { color: #00769e; background-color: #f1f3f5; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span { color: #00769e; } /* Normal */
code span.al { color: #ad0000; } /* Alert */
code span.an { color: #5e5e5e; } /* Annotation */
code span.at { color: #657422; } /* Attribute */
code span.bn { color: #ad0000; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #00769e; } /* ControlFlow */
code span.ch { color: #20794d; } /* Char */
code span.cn { color: #8f5902; } /* Constant */
code span.co { color: #5e5e5e; } /* Comment */
code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
code span.dt { color: #ad0000; } /* DataType */
code span.dv { color: #ad0000; } /* DecVal */
code span.er { color: #ad0000; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #ad0000; } /* Float */
code span.fu { color: #4758ab; } /* Function */
code span.im { } /* Import */
code span.in { color: #5e5e5e; } /* Information */
code span.kw { color: #00769e; } /* Keyword */
code span.op { color: #5e5e5e; } /* Operator */
code span.ot { color: #00769e; } /* Other */
code span.pp { color: #ad0000; } /* Preprocessor */
code span.sc { color: #5e5e5e; } /* SpecialChar */
code span.ss { color: #20794d; } /* SpecialString */
code span.st { color: #20794d; } /* String */
code span.va { color: #111111; } /* Variable */
code span.vs { color: #20794d; } /* VerbatimString */
code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
</style>

<style>
  div.csl-bib-body { }
  div.csl-entry {
    clear: both;
    }
  .hanging div.csl-entry {
    margin-left:2em;
    text-indent:-2em;
  }
  div.csl-left-margin {
    min-width:2em;
    float:left;
  }
  div.csl-right-inline {
    margin-left:2em;
    padding-left:1em;
  }
  div.csl-indent {
    margin-left: 2em;
  }
</style>

  <!--radix_placeholder_meta_tags-->
  <title>Text As Data: Large Language Models</title>

  <meta property="description" itemprop="description" content="A dumb auto-complete model -- trained on the entire Internet -- can accomplish a remarkable number of tasks if you ask it nicely."/>

  <link rel="icon" type="image/vnd.microsoft.icon" href="img/favicon_io/favicon.ico"/>


  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Text As Data: Large Language Models"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="A dumb auto-complete model -- trained on the entire Internet -- can accomplish a remarkable number of tasks if you ask it nicely."/>
  <meta property="og:locale" content="en_US"/>
  <meta property="og:site_name" content="Text As Data"/>

  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Text As Data: Large Language Models"/>
  <meta property="twitter:description" content="A dumb auto-complete model -- trained on the entire Internet -- can accomplish a remarkable number of tasks if you ask it nicely."/>

  <!--/radix_placeholder_meta_tags-->
  
  <meta name="citation_reference" content="citation_title=Why open-source generative AI models are an ethical way forward for science;citation_volume=616;citation_doi=10.1038/d41586-023-01295-4;citation_author=Arthur Spirling"/>
  <meta name="citation_reference" content="citation_title=How to Train Your Stochastic Parrot: Large Language Models for Political Texts;citation_author=Joseph T Ornstein;citation_author=Elise N Blasingame;citation_author=Jake S Truscott"/>
  <meta name="citation_reference" content="citation_title=Attention Is All You Need;citation_author=Ashish Vaswani;citation_author=Noam Shazeer;citation_author=Niki Parmar;citation_author=Jakob Uszkoreit;citation_author=Llion Jones;citation_author=Aidan N. Gomez;citation_author=Lukasz Kaiser;citation_author=Illia Polosukhin"/>
  <meta name="citation_reference" content="citation_title=Language models are few-shot learners;citation_author=Tom B. Brown;citation_author=Benjamin Mann;citation_author=Nick Ryder;citation_author=Melanie Subbiah;citation_author=Jared Kaplan;citation_author=Prafulla Dhariwal;citation_author=Arvind Neelakantan;citation_author=Pranav Shyam;citation_author=Girish Sastry;citation_author=Amanda Askell;citation_author=Sandhini Agarwal;citation_author=Ariel Herbert-Voss;citation_author=Gretchen Krueger;citation_author=Tom Henighan;citation_author=Rewon Child;citation_author=Aditya Ramesh;citation_author=Daniel M. Ziegler;citation_author=Jeffrey Wu;citation_author=Clemens Winter;citation_author=Christopher Hesse;citation_author=Mark Chen;citation_author=Eric Sigler;citation_author=Mateusz Litwin;citation_author=Scott Gray;citation_author=Benjamin Chess;citation_author=Jack Clark;citation_author=Christopher Berner;citation_author=Sam McCandlish;citation_author=Alec Radford;citation_author=Ilya Sutskever;citation_author=Dario Amodei"/>
  <!--radix_placeholder_rmarkdown_metadata-->

  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","bibliography"]}},"value":[{"type":"character","attributes":{},"value":["Large Language Models"]},{"type":"character","attributes":{},"value":["A dumb auto-complete model -- trained on the entire Internet -- can accomplish a remarkable number of tasks if you ask it nicely.\n"]},{"type":"character","attributes":{},"value":["references.bib"]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  <!--radix_placeholder_navigation_in_header-->
  <meta name="distill:offset" content=""/>

  <script type="application/javascript">

    window.headroom_prevent_pin = false;

    window.document.addEventListener("DOMContentLoaded", function (event) {

      // initialize headroom for banner
      var header = $('header').get(0);
      var headerHeight = header.offsetHeight;
      var headroom = new Headroom(header, {
        tolerance: 5,
        onPin : function() {
          if (window.headroom_prevent_pin) {
            window.headroom_prevent_pin = false;
            headroom.unpin();
          }
        }
      });
      headroom.init();
      if(window.location.hash)
        headroom.unpin();
      $(header).addClass('headroom--transition');

      // offset scroll location for banner on hash change
      // (see: https://github.com/WickyNilliams/headroom.js/issues/38)
      window.addEventListener("hashchange", function(event) {
        window.scrollTo(0, window.pageYOffset - (headerHeight + 25));
      });

      // responsive menu
      $('.distill-site-header').each(function(i, val) {
        var topnav = $(this);
        var toggle = topnav.find('.nav-toggle');
        toggle.on('click', function() {
          topnav.toggleClass('responsive');
        });
      });

      // nav dropdowns
      $('.nav-dropbtn').click(function(e) {
        $(this).next('.nav-dropdown-content').toggleClass('nav-dropdown-active');
        $(this).parent().siblings('.nav-dropdown')
           .children('.nav-dropdown-content').removeClass('nav-dropdown-active');
      });
      $("body").click(function(e){
        $('.nav-dropdown-content').removeClass('nav-dropdown-active');
      });
      $(".nav-dropdown").click(function(e){
        e.stopPropagation();
      });
    });
  </script>

  <style type="text/css">

  /* Theme (user-documented overrideables for nav appearance) */

  .distill-site-nav {
    color: rgba(255, 255, 255, 0.8);
    background-color: #0F2E3D;
    font-size: 15px;
    font-weight: 300;
  }

  .distill-site-nav a {
    color: inherit;
    text-decoration: none;
  }

  .distill-site-nav a:hover {
    color: white;
  }

  @media print {
    .distill-site-nav {
      display: none;
    }
  }

  .distill-site-header {

  }

  .distill-site-footer {

  }


  /* Site Header */

  .distill-site-header {
    width: 100%;
    box-sizing: border-box;
    z-index: 3;
  }

  .distill-site-header .nav-left {
    display: inline-block;
    margin-left: 8px;
  }

  @media screen and (max-width: 768px) {
    .distill-site-header .nav-left {
      margin-left: 0;
    }
  }


  .distill-site-header .nav-right {
    float: right;
    margin-right: 8px;
  }

  .distill-site-header a,
  .distill-site-header .title {
    display: inline-block;
    text-align: center;
    padding: 14px 10px 14px 10px;
  }

  .distill-site-header .title {
    font-size: 18px;
    min-width: 150px;
  }

  .distill-site-header .logo {
    padding: 0;
  }

  .distill-site-header .logo img {
    display: none;
    max-height: 20px;
    width: auto;
    margin-bottom: -4px;
  }

  .distill-site-header .nav-image img {
    max-height: 18px;
    width: auto;
    display: inline-block;
    margin-bottom: -3px;
  }



  @media screen and (min-width: 1000px) {
    .distill-site-header .logo img {
      display: inline-block;
    }
    .distill-site-header .nav-left {
      margin-left: 20px;
    }
    .distill-site-header .nav-right {
      margin-right: 20px;
    }
    .distill-site-header .title {
      padding-left: 12px;
    }
  }


  .distill-site-header .nav-toggle {
    display: none;
  }

  .nav-dropdown {
    display: inline-block;
    position: relative;
  }

  .nav-dropdown .nav-dropbtn {
    border: none;
    outline: none;
    color: rgba(255, 255, 255, 0.8);
    padding: 16px 10px;
    background-color: transparent;
    font-family: inherit;
    font-size: inherit;
    font-weight: inherit;
    margin: 0;
    margin-top: 1px;
    z-index: 2;
  }

  .nav-dropdown-content {
    display: none;
    position: absolute;
    background-color: white;
    min-width: 200px;
    border: 1px solid rgba(0,0,0,0.15);
    border-radius: 4px;
    box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.1);
    z-index: 1;
    margin-top: 2px;
    white-space: nowrap;
    padding-top: 4px;
    padding-bottom: 4px;
  }

  .nav-dropdown-content hr {
    margin-top: 4px;
    margin-bottom: 4px;
    border: none;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .nav-dropdown-active {
    display: block;
  }

  .nav-dropdown-content a, .nav-dropdown-content .nav-dropdown-header {
    color: black;
    padding: 6px 24px;
    text-decoration: none;
    display: block;
    text-align: left;
  }

  .nav-dropdown-content .nav-dropdown-header {
    display: block;
    padding: 5px 24px;
    padding-bottom: 0;
    text-transform: uppercase;
    font-size: 14px;
    color: #999999;
    white-space: nowrap;
  }

  .nav-dropdown:hover .nav-dropbtn {
    color: white;
  }

  .nav-dropdown-content a:hover {
    background-color: #ddd;
    color: black;
  }

  .nav-right .nav-dropdown-content {
    margin-left: -45%;
    right: 0;
  }

  @media screen and (max-width: 768px) {
    .distill-site-header a, .distill-site-header .nav-dropdown  {display: none;}
    .distill-site-header a.nav-toggle {
      float: right;
      display: block;
    }
    .distill-site-header .title {
      margin-left: 0;
    }
    .distill-site-header .nav-right {
      margin-right: 0;
    }
    .distill-site-header {
      overflow: hidden;
    }
    .nav-right .nav-dropdown-content {
      margin-left: 0;
    }
  }


  @media screen and (max-width: 768px) {
    .distill-site-header.responsive {position: relative; min-height: 500px; }
    .distill-site-header.responsive a.nav-toggle {
      position: absolute;
      right: 0;
      top: 0;
    }
    .distill-site-header.responsive a,
    .distill-site-header.responsive .nav-dropdown {
      display: block;
      text-align: left;
    }
    .distill-site-header.responsive .nav-left,
    .distill-site-header.responsive .nav-right {
      width: 100%;
    }
    .distill-site-header.responsive .nav-dropdown {float: none;}
    .distill-site-header.responsive .nav-dropdown-content {position: relative;}
    .distill-site-header.responsive .nav-dropdown .nav-dropbtn {
      display: block;
      width: 100%;
      text-align: left;
    }
  }

  /* Site Footer */

  .distill-site-footer {
    width: 100%;
    overflow: hidden;
    box-sizing: border-box;
    z-index: 3;
    margin-top: 30px;
    padding-top: 30px;
    padding-bottom: 30px;
    text-align: center;
  }

  /* Headroom */

  d-title {
    padding-top: 6rem;
  }

  @media print {
    d-title {
      padding-top: 4rem;
    }
  }

  .headroom {
    z-index: 1000;
    position: fixed;
    top: 0;
    left: 0;
    right: 0;
  }

  .headroom--transition {
    transition: all .4s ease-in-out;
  }

  .headroom--unpinned {
    top: -100px;
  }

  .headroom--pinned {
    top: 0;
  }

  /* adjust viewport for navbar height */
  /* helps vertically center bootstrap (non-distill) content */
  .min-vh-100 {
    min-height: calc(100vh - 100px) !important;
  }

  </style>

  <script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
  <link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet"/>
  <link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet"/>
  <script src="site_libs/headroom-0.9.4/headroom.min.js"></script>
  <script src="site_libs/autocomplete-0.37.1/autocomplete.min.js"></script>
  <script src="site_libs/fuse-6.4.1/fuse.min.js"></script>

  <script type="application/javascript">

  function getMeta(metaName) {
    var metas = document.getElementsByTagName('meta');
    for (let i = 0; i < metas.length; i++) {
      if (metas[i].getAttribute('name') === metaName) {
        return metas[i].getAttribute('content');
      }
    }
    return '';
  }

  function offsetURL(url) {
    var offset = getMeta('distill:offset');
    return offset ? offset + '/' + url : url;
  }

  function createFuseIndex() {

    // create fuse index
    var options = {
      keys: [
        { name: 'title', weight: 20 },
        { name: 'categories', weight: 15 },
        { name: 'description', weight: 10 },
        { name: 'contents', weight: 5 },
      ],
      ignoreLocation: true,
      threshold: 0
    };
    var fuse = new window.Fuse([], options);

    // fetch the main search.json
    return fetch(offsetURL('search.json'))
      .then(function(response) {
        if (response.status == 200) {
          return response.json().then(function(json) {
            // index main articles
            json.articles.forEach(function(article) {
              fuse.add(article);
            });
            // download collections and index their articles
            return Promise.all(json.collections.map(function(collection) {
              return fetch(offsetURL(collection)).then(function(response) {
                if (response.status === 200) {
                  return response.json().then(function(articles) {
                    articles.forEach(function(article) {
                      fuse.add(article);
                    });
                  })
                } else {
                  return Promise.reject(
                    new Error('Unexpected status from search index request: ' +
                              response.status)
                  );
                }
              });
            })).then(function() {
              return fuse;
            });
          });

        } else {
          return Promise.reject(
            new Error('Unexpected status from search index request: ' +
                        response.status)
          );
        }
      });
  }

  window.document.addEventListener("DOMContentLoaded", function (event) {

    // get search element (bail if we don't have one)
    var searchEl = window.document.getElementById('distill-search');
    if (!searchEl)
      return;

    createFuseIndex()
      .then(function(fuse) {

        // make search box visible
        searchEl.classList.remove('hidden');

        // initialize autocomplete
        var options = {
          autoselect: true,
          hint: false,
          minLength: 2,
        };
        window.autocomplete(searchEl, options, [{
          source: function(query, callback) {
            const searchOptions = {
              isCaseSensitive: false,
              shouldSort: true,
              minMatchCharLength: 2,
              limit: 10,
            };
            var results = fuse.search(query, searchOptions);
            callback(results
              .map(function(result) { return result.item; })
            );
          },
          templates: {
            suggestion: function(suggestion) {
              var img = suggestion.preview && Object.keys(suggestion.preview).length > 0
                ? `<img src="${offsetURL(suggestion.preview)}"</img>`
                : '';
              var html = `
                <div class="search-item">
                  <h3>${suggestion.title}</h3>
                  <div class="search-item-description">
                    ${suggestion.description || ''}
                  </div>
                  <div class="search-item-preview">
                    ${img}
                  </div>
                </div>
              `;
              return html;
            }
          }
        }]).on('autocomplete:selected', function(event, suggestion) {
          window.location.href = offsetURL(suggestion.path);
        });
        // remove inline display style on autocompleter (we want to
        // manage responsive display via css)
        $('.algolia-autocomplete').css("display", "");
      })
      .catch(function(error) {
        console.log(error);
      });

  });

  </script>

  <style type="text/css">

  .nav-search {
    font-size: x-small;
  }

  /* Algolioa Autocomplete */

  .algolia-autocomplete {
    display: inline-block;
    margin-left: 10px;
    vertical-align: sub;
    background-color: white;
    color: black;
    padding: 6px;
    padding-top: 8px;
    padding-bottom: 0;
    border-radius: 6px;
    border: 1px #0F2E3D solid;
    width: 180px;
  }


  @media screen and (max-width: 768px) {
    .distill-site-nav .algolia-autocomplete {
      display: none;
      visibility: hidden;
    }
    .distill-site-nav.responsive .algolia-autocomplete {
      display: inline-block;
      visibility: visible;
    }
    .distill-site-nav.responsive .algolia-autocomplete .aa-dropdown-menu {
      margin-left: 0;
      width: 400px;
      max-height: 400px;
    }
  }

  .algolia-autocomplete .aa-input, .algolia-autocomplete .aa-hint {
    width: 90%;
    outline: none;
    border: none;
  }

  .algolia-autocomplete .aa-hint {
    color: #999;
  }
  .algolia-autocomplete .aa-dropdown-menu {
    width: 550px;
    max-height: 70vh;
    overflow-x: visible;
    overflow-y: scroll;
    padding: 5px;
    margin-top: 3px;
    margin-left: -150px;
    background-color: #fff;
    border-radius: 5px;
    border: 1px solid #999;
    border-top: none;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion {
    cursor: pointer;
    padding: 5px 4px;
    border-bottom: 1px solid #eee;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion:last-of-type {
    border-bottom: none;
    margin-bottom: 2px;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item {
    overflow: hidden;
    font-size: 0.8em;
    line-height: 1.4em;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item h3 {
    font-size: 1rem;
    margin-block-start: 0;
    margin-block-end: 5px;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-description {
    display: inline-block;
    overflow: hidden;
    height: 2.8em;
    width: 80%;
    margin-right: 4%;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview {
    display: inline-block;
    width: 15%;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img {
    height: 3em;
    width: auto;
    display: none;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion .search-item-preview img[src] {
    display: initial;
  }

  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion.aa-cursor {
    background-color: #eee;
  }
  .algolia-autocomplete .aa-dropdown-menu .aa-suggestion em {
    font-weight: bold;
    font-style: normal;
  }

  </style>


  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->

  <style type="text/css">

  body {
    background-color: white;
  }

  .pandoc-table {
    width: 100%;
  }

  .pandoc-table>caption {
    margin-bottom: 10px;
  }

  .pandoc-table th:not([align]) {
    text-align: left;
  }

  .pagedtable-footer {
    font-size: 15px;
  }

  d-byline .byline {
    grid-template-columns: 2fr 2fr;
  }

  d-byline .byline h3 {
    margin-block-start: 1.5em;
  }

  d-byline .byline .authors-affiliations h3 {
    margin-block-start: 0.5em;
  }

  .authors-affiliations .orcid-id {
    width: 16px;
    height:16px;
    margin-left: 4px;
    margin-right: 4px;
    vertical-align: middle;
    padding-bottom: 2px;
  }

  d-title .dt-tags {
    margin-top: 1em;
    grid-column: text;
  }

  .dt-tags .dt-tag {
    text-decoration: none;
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0em 0.4em;
    margin-right: 0.5em;
    margin-bottom: 0.4em;
    font-size: 70%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  d-article table.gt_table td,
  d-article table.gt_table th {
    border-bottom: none;
    font-size: 100%;
  }

  .html-widget {
    margin-bottom: 2.0em;
  }

  .l-screen-inset {
    padding-right: 16px;
  }

  .l-screen .caption {
    margin-left: 10px;
  }

  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }

  .shaded .shaded-content {
    background: white;
  }

  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }

  .hidden {
    display: none !important;
  }

  d-article {
    padding-top: 2.5rem;
    padding-bottom: 30px;
  }

  d-appendix {
    padding-top: 30px;
  }

  d-article>p>img {
    width: 100%;
  }

  d-article h2 {
    margin: 1rem 0 1.5rem 0;
  }

  d-article h3 {
    margin-top: 1.5rem;
  }

  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }

  /* Tweak code blocks */

  d-article div.sourceCode code,
  d-article pre code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: auto;
  }

  d-article div.sourceCode {
    background-color: white;
  }

  d-article div.sourceCode pre {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }

  d-article pre {
    font-size: 12px;
    color: black;
    background: none;
    margin-top: 0;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  d-article pre a {
    border-bottom: none;
  }

  d-article pre a:hover {
    border-bottom: none;
    text-decoration: underline;
  }

  d-article details {
    grid-column: text;
    margin-bottom: 0.8em;
  }

  @media(min-width: 768px) {

  d-article pre,
  d-article div.sourceCode,
  d-article div.sourceCode pre {
    overflow: visible !important;
  }

  d-article div.sourceCode pre {
    padding-left: 18px;
    font-size: 14px;
  }

  d-article pre {
    font-size: 14px;
  }

  }

  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  /* CSS for d-contents */

  .d-contents {
    grid-column: text;
    color: rgba(0,0,0,0.8);
    font-size: 0.9em;
    padding-bottom: 1em;
    margin-bottom: 1em;
    padding-bottom: 0.5em;
    margin-bottom: 1em;
    padding-left: 0.25em;
    justify-self: start;
  }

  @media(min-width: 1000px) {
    .d-contents.d-contents-float {
      height: 0;
      grid-column-start: 1;
      grid-column-end: 4;
      justify-self: center;
      padding-right: 3em;
      padding-left: 2em;
    }
  }

  .d-contents nav h3 {
    font-size: 18px;
    margin-top: 0;
    margin-bottom: 1em;
  }

  .d-contents li {
    list-style-type: none
  }

  .d-contents nav > ul {
    padding-left: 0;
  }

  .d-contents ul {
    padding-left: 1em
  }

  .d-contents nav ul li {
    margin-top: 0.6em;
    margin-bottom: 0.2em;
  }

  .d-contents nav a {
    font-size: 13px;
    border-bottom: none;
    text-decoration: none
    color: rgba(0, 0, 0, 0.8);
  }

  .d-contents nav a:hover {
    text-decoration: underline solid rgba(0, 0, 0, 0.6)
  }

  .d-contents nav > ul > li > a {
    font-weight: 600;
  }

  .d-contents nav > ul > li > ul {
    font-weight: inherit;
  }

  .d-contents nav > ul > li > ul > li {
    margin-top: 0.2em;
  }


  .d-contents nav ul {
    margin-top: 0;
    margin-bottom: 0.25em;
  }

  .d-article-with-toc h2:nth-child(2) {
    margin-top: 0;
  }


  /* Figure */

  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }

  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }

  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }

  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }

  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }

  /* Citations */

  d-article .citation {
    color: inherit;
    cursor: inherit;
  }

  div.hanging-indent{
    margin-left: 1em; text-indent: -1em;
  }

  /* Citation hover box */

  .tippy-box[data-theme~=light-border] {
    background-color: rgba(250, 250, 250, 0.95);
  }

  .tippy-content > p {
    margin-bottom: 0;
    padding: 2px;
  }


  /* Tweak 1000px media break to show more text */

  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }

    .grid {
      grid-column-gap: 16px;
    }

    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }

  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }

    .grid {
      grid-column-gap: 32px;
    }
  }


  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */

  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }

  /* Include appendix styles here so they can be overridden */

  d-appendix {
    contain: layout style;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-top: 60px;
    margin-bottom: 0;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    color: rgba(0,0,0,0.5);
    padding-top: 60px;
    padding-bottom: 48px;
  }

  d-appendix h3 {
    grid-column: page-start / text-start;
    font-size: 15px;
    font-weight: 500;
    margin-top: 1em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.65);
  }

  d-appendix h3 + * {
    margin-top: 1em;
  }

  d-appendix ol {
    padding: 0 0 0 15px;
  }

  @media (min-width: 768px) {
    d-appendix ol {
      padding: 0 0 0 30px;
      margin-left: -30px;
    }
  }

  d-appendix li {
    margin-bottom: 1em;
  }

  d-appendix a {
    color: rgba(0, 0, 0, 0.6);
  }

  d-appendix > * {
    grid-column: text;
  }

  d-appendix > d-footnote-list,
  d-appendix > d-citation-list,
  d-appendix > distill-appendix {
    grid-column: screen;
  }

  /* Include footnote styles here so they can be overridden */

  d-footnote-list {
    contain: layout style;
  }

  d-footnote-list > * {
    grid-column: text;
  }

  d-footnote-list a.footnote-backlink {
    color: rgba(0,0,0,0.3);
    padding-left: 0.5em;
  }



  /* Anchor.js */

  .anchorjs-link {
    /*transition: all .25s linear; */
    text-decoration: none;
    border-bottom: none;
  }
  *:hover > .anchorjs-link {
    margin-left: -1.125em !important;
    text-decoration: none;
    border-bottom: none;
  }

  /* Social footer */

  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }

  .disqus-comments {
    margin-right: 30px;
  }

  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }

  #disqus_thread {
    margin-top: 30px;
  }

  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }

  .article-sharing a:hover {
    border-bottom: none;
  }

  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }

  .subscribe p {
    margin-bottom: 0.5em;
  }


  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }


  .sidebar-section.custom {
    font-size: 12px;
    line-height: 1.6em;
  }

  .custom p {
    margin-bottom: 0.5em;
  }

  /* Styles for listing layout (hide title) */
  .layout-listing d-title, .layout-listing .d-title {
    display: none;
  }

  /* Styles for posts lists (not auto-injected) */


  .posts-with-sidebar {
    padding-left: 45px;
    padding-right: 45px;
  }

  .posts-list .description h2,
  .posts-list .description p {
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  .posts-list .description h2 {
    font-weight: 700;
    border-bottom: none;
    padding-bottom: 0;
  }

  .posts-list h2.post-tag {
    border-bottom: 1px solid rgba(0, 0, 0, 0.2);
    padding-bottom: 12px;
  }
  .posts-list {
    margin-top: 60px;
    margin-bottom: 24px;
  }

  .posts-list .post-preview {
    text-decoration: none;
    overflow: hidden;
    display: block;
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
    padding: 24px 0;
  }

  .post-preview-last {
    border-bottom: none !important;
  }

  .posts-list .posts-list-caption {
    grid-column: screen;
    font-weight: 400;
  }

  .posts-list .post-preview h2 {
    margin: 0 0 6px 0;
    line-height: 1.2em;
    font-style: normal;
    font-size: 24px;
  }

  .posts-list .post-preview p {
    margin: 0 0 12px 0;
    line-height: 1.4em;
    font-size: 16px;
  }

  .posts-list .post-preview .thumbnail {
    box-sizing: border-box;
    margin-bottom: 24px;
    position: relative;
    max-width: 500px;
  }
  .posts-list .post-preview img {
    width: 100%;
    display: block;
  }

  .posts-list .metadata {
    font-size: 12px;
    line-height: 1.4em;
    margin-bottom: 18px;
  }

  .posts-list .metadata > * {
    display: inline-block;
  }

  .posts-list .metadata .publishedDate {
    margin-right: 2em;
  }

  .posts-list .metadata .dt-authors {
    display: block;
    margin-top: 0.3em;
    margin-right: 2em;
  }

  .posts-list .dt-tags {
    display: block;
    line-height: 1em;
  }

  .posts-list .dt-tags .dt-tag {
    display: inline-block;
    color: rgba(0,0,0,0.6);
    padding: 0.3em 0.4em;
    margin-right: 0.2em;
    margin-bottom: 0.4em;
    font-size: 60%;
    border: 1px solid rgba(0,0,0,0.2);
    border-radius: 3px;
    text-transform: uppercase;
    font-weight: 500;
  }

  .posts-list img {
    opacity: 1;
  }

  .posts-list img[data-src] {
    opacity: 0;
  }

  .posts-more {
    clear: both;
  }


  .posts-sidebar {
    font-size: 16px;
  }

  .posts-sidebar h3 {
    font-size: 16px;
    margin-top: 0;
    margin-bottom: 0.5em;
    font-weight: 400;
    text-transform: uppercase;
  }

  .sidebar-section {
    margin-bottom: 30px;
  }

  .categories ul {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }

  .categories li {
    color: rgba(0, 0, 0, 0.8);
    margin-bottom: 0;
  }

  .categories li>a {
    border-bottom: none;
  }

  .categories li>a:hover {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
  }

  .categories .active {
    font-weight: 600;
  }

  .categories .category-count {
    color: rgba(0, 0, 0, 0.4);
  }


  @media(min-width: 768px) {
    .posts-list .post-preview h2 {
      font-size: 26px;
    }
    .posts-list .post-preview .thumbnail {
      float: right;
      width: 30%;
      margin-bottom: 0;
    }
    .posts-list .post-preview .description {
      float: left;
      width: 45%;
    }
    .posts-list .post-preview .metadata {
      float: left;
      width: 20%;
      margin-top: 8px;
    }
    .posts-list .post-preview p {
      margin: 0 0 12px 0;
      line-height: 1.5em;
      font-size: 16px;
    }
    .posts-with-sidebar .posts-list {
      float: left;
      width: 75%;
    }
    .posts-with-sidebar .posts-sidebar {
      float: right;
      width: 20%;
      margin-top: 60px;
      padding-top: 24px;
      padding-bottom: 24px;
    }
  }


  /* Improve display for browsers without grid (IE/Edge <= 15) */

  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }

  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }

  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }

  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }

  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }

  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }

  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }


  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }

  .downlevel .footnotes ol {
    padding-left: 13px;
  }

  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }

  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }

  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }

  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;

    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;

    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }

  .downlevel .posts-list .post-preview {
    color: inherit;
  }



  </style>

  <script type="application/javascript">

  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }

  // show body when load is complete
  function on_load_complete() {

    // add anchors
    if (window.anchors) {
      window.anchors.options.placement = 'left';
      window.anchors.add('d-article > h2, d-article > h3, d-article > h4, d-article > h5');
    }


    // set body to visible
    document.body.style.visibility = 'visible';

    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }

    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }

  function init_distill() {

    init_common();

    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);

    // create d-title
    $('.d-title').changeElementType('d-title');

    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);

    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();

    // move posts container into article
    $('.posts-container').appendTo($('d-article'));

    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');

    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;

    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();

    // move refs into #references-listing
    $('#references-listing').replaceWith($('#refs'));

    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-contents a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });

    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');

    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {

      // capture layout
      var layout = $(this).attr('data-layout');

      // apply layout to markdown level block elements
      var elements = $(this).children().not('details, div.sourceCode, pre, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });


      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });

    // remove code block used to force  highlighting css
    $('.distill-force-highlighting-css').parent().remove();

    // remove empty line numbers inserted by pandoc when using a
    // custom syntax highlighting theme
    $('code.sourceCode a:empty').remove();

    // load distill framework
    load_distill_framework();

    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {

      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;

      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');

      // article with toc class
      $('.d-contents').parent().addClass('d-article-with-toc');

      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');

      // add orcid ids
      $('.authors-affiliations').find('.author').each(function(i, el) {
        var orcid_id = front_matter.authors[i].orcidID;
        if (orcid_id) {
          var a = $('<a></a>');
          a.attr('href', 'https://orcid.org/' + orcid_id);
          var img = $('<img></img>');
          img.addClass('orcid-id');
          img.attr('alt', 'ORCID ID');
          img.attr('src','data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA2ZpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wTU09Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9tbS8iIHhtbG5zOnN0UmVmPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvc1R5cGUvUmVzb3VyY2VSZWYjIiB4bWxuczp4bXA9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC8iIHhtcE1NOk9yaWdpbmFsRG9jdW1lbnRJRD0ieG1wLmRpZDo1N0NEMjA4MDI1MjA2ODExOTk0QzkzNTEzRjZEQTg1NyIgeG1wTU06RG9jdW1lbnRJRD0ieG1wLmRpZDozM0NDOEJGNEZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wTU06SW5zdGFuY2VJRD0ieG1wLmlpZDozM0NDOEJGM0ZGNTcxMUUxODdBOEVCODg2RjdCQ0QwOSIgeG1wOkNyZWF0b3JUb29sPSJBZG9iZSBQaG90b3Nob3AgQ1M1IE1hY2ludG9zaCI+IDx4bXBNTTpEZXJpdmVkRnJvbSBzdFJlZjppbnN0YW5jZUlEPSJ4bXAuaWlkOkZDN0YxMTc0MDcyMDY4MTE5NUZFRDc5MUM2MUUwNEREIiBzdFJlZjpkb2N1bWVudElEPSJ4bXAuZGlkOjU3Q0QyMDgwMjUyMDY4MTE5OTRDOTM1MTNGNkRBODU3Ii8+IDwvcmRmOkRlc2NyaXB0aW9uPiA8L3JkZjpSREY+IDwveDp4bXBtZXRhPiA8P3hwYWNrZXQgZW5kPSJyIj8+84NovQAAAR1JREFUeNpiZEADy85ZJgCpeCB2QJM6AMQLo4yOL0AWZETSqACk1gOxAQN+cAGIA4EGPQBxmJA0nwdpjjQ8xqArmczw5tMHXAaALDgP1QMxAGqzAAPxQACqh4ER6uf5MBlkm0X4EGayMfMw/Pr7Bd2gRBZogMFBrv01hisv5jLsv9nLAPIOMnjy8RDDyYctyAbFM2EJbRQw+aAWw/LzVgx7b+cwCHKqMhjJFCBLOzAR6+lXX84xnHjYyqAo5IUizkRCwIENQQckGSDGY4TVgAPEaraQr2a4/24bSuoExcJCfAEJihXkWDj3ZAKy9EJGaEo8T0QSxkjSwORsCAuDQCD+QILmD1A9kECEZgxDaEZhICIzGcIyEyOl2RkgwAAhkmC+eAm0TAAAAABJRU5ErkJggg==');
          a.append(img);
          $(this).append(a);
        }
      });

      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }

      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');

      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");

      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }

       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }

      // remove d-appendix and d-footnote-list local styles
      $('d-appendix > style:first-child').remove();
      $('d-footnote-list > style:first-child').remove();

      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();

      // hoverable references
      $('span.citation[data-cites]').each(function() {
        const citeChild = $(this).children()[0]
        // Do not process if @xyz has been used without escaping and without bibliography activated
        // https://github.com/rstudio/distill/issues/466
        if (citeChild === undefined) return true

        if (citeChild.nodeName == "D-FOOTNOTE") {
          var fn = citeChild
          $(this).html(fn.shadowRoot.querySelector("sup"))
          $(this).id = fn.id
          fn.remove()
        }
        var refs = $(this).attr('data-cites').split(" ");
        var refHtml = refs.map(function(ref) {
          // Could use CSS.escape too here, we insure backward compatibility in navigator
          return "<p>" + $('div[id="ref-' + ref + '"]').html() + "</p>";
        }).join("\n");
        window.tippy(this, {
          allowHTML: true,
          content: refHtml,
          maxWidth: 500,
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start'
        });
      });

      // fix footnotes in tables (#411)
      // replacing broken distill.pub feature
      $('table d-footnote').each(function() {
        // we replace internal showAtNode methode which is triggered when hovering a footnote
        this.hoverBox.showAtNode = function(node) {
          // ported from https://github.com/distillpub/template/pull/105/files
          calcOffset = function(elem) {
              let x = elem.offsetLeft;
              let y = elem.offsetTop;
              // Traverse upwards until an `absolute` element is found or `elem`
              // becomes null.
              while (elem = elem.offsetParent && elem.style.position != 'absolute') {
                  x += elem.offsetLeft;
                  y += elem.offsetTop;
              }

              return { left: x, top: y };
          }
          // https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/offsetTop
          const bbox = node.getBoundingClientRect();
          const offset = calcOffset(node);
          this.show([offset.left + bbox.width, offset.top + bbox.height]);
        }
      })

      // clear polling timer
      clearInterval(tid);

      // show body now that everything is ready
      on_load_complete();
    }

    var tid = setInterval(distill_post_process, 50);
    distill_post_process();

  }

  function init_downlevel() {

    init_common();

     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));

    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;

    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();

    // remove toc
    $('.d-contents').remove();

    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });


    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);

    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);

    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();

    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();

    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));

    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });

    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));

    $('body').addClass('downlevel');

    on_load_complete();
  }


  function init_common() {

    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};

        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });

        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);

    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});

    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      // ignore leaflet img layers (#106)
      figures = figures.filter(':not(img[class*="leaflet"])')
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });

      }
    });

    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });

    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace(/^index[.]html/, "./"));
      });
    }

    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');

    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");

    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();

    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }

  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });

  </script>

  <style type="text/css">
  /* base variables */

  /* Edit the CSS properties in this file to create a custom
     Distill theme. Only edit values in the right column
     for each row; values shown are the CSS defaults.
     To return any property to the default,
     you may set its value to: unset
     All rows must end with a semi-colon.                      */

  /* Optional: embed custom fonts here with `@import`          */
  /* This must remain at the top of this file.                 */



  html {
    /*-- Main font sizes --*/
    --title-size:      50px;
    --body-size:       1.06rem;
    --code-size:       14px;
    --aside-size:      12px;
    --fig-cap-size:    13px;
    /*-- Main font colors --*/
    --title-color:     #000000;
    --header-color:    rgba(0, 0, 0, 0.8);
    --body-color:      rgba(0, 0, 0, 0.8);
    --aside-color:     rgba(0, 0, 0, 0.6);
    --fig-cap-color:   rgba(0, 0, 0, 0.6);
    /*-- Specify custom fonts ~~~ must be imported above   --*/
    --heading-font:    sans-serif;
    --mono-font:       monospace;
    --body-font:       sans-serif;
    --navbar-font:     sans-serif;  /* websites + blogs only */
  }

  /*-- ARTICLE METADATA --*/
  d-byline {
    --heading-size:    0.6rem;
    --heading-color:   rgba(0, 0, 0, 0.5);
    --body-size:       0.8rem;
    --body-color:      rgba(0, 0, 0, 0.8);
  }

  /*-- ARTICLE TABLE OF CONTENTS --*/
  .d-contents {
    --heading-size:    18px;
    --contents-size:   13px;
  }

  /*-- ARTICLE APPENDIX --*/
  d-appendix {
    --heading-size:    15px;
    --heading-color:   rgba(0, 0, 0, 0.65);
    --text-size:       0.8em;
    --text-color:      rgba(0, 0, 0, 0.5);
  }

  /*-- WEBSITE HEADER + FOOTER --*/
  /* These properties only apply to Distill sites and blogs  */

  .distill-site-header {
    --title-size:       18px;
    --text-color:       rgba(255, 255, 255, 0.8);
    --text-size:        15px;
    --hover-color:      white;
    --bkgd-color:       #0F2E3D;
  }

  .distill-site-footer {
    --text-color:       rgba(255, 255, 255, 0.8);
    --text-size:        15px;
    --hover-color:      white;
    --bkgd-color:       #0F2E3D;
  }

  /*-- Additional custom styles --*/
  /* Add any additional CSS rules below                      */
  </style>
  <style type="text/css">
  /* base variables */

  /* Edit the CSS properties in this file to create a custom
     Distill theme. Only edit values in the right column
     for each row; values shown are the CSS defaults.
     To return any property to the default,
     you may set its value to: unset
     All rows must end with a semi-colon.                      */

  /* Optional: embed custom fonts here with `@import`          */
  /* This must remain at the top of this file.                 */



  html {
    /*-- Main font sizes --*/
    --title-size:      50px;
    --body-size:       1.06rem;
    --code-size:       14px;
    --aside-size:      12px;
    --fig-cap-size:    13px;
    /*-- Main font colors --*/
    --title-color:     #000000;
    --header-color:    rgba(0, 0, 0, 0.8);
    --body-color:      rgba(0, 0, 0, 0.8);
    --aside-color:     rgba(0, 0, 0, 0.6);
    --fig-cap-color:   rgba(0, 0, 0, 0.6);
    /*-- Specify custom fonts ~~~ must be imported above   --*/
    --heading-font:    sans-serif;
    --mono-font:       monospace;
    --body-font:       sans-serif;
    --navbar-font:     sans-serif;  /* websites + blogs only */
  }

  /*-- ARTICLE METADATA --*/
  d-byline {
    --heading-size:    0.6rem;
    --heading-color:   rgba(0, 0, 0, 0.5);
    --body-size:       0.8rem;
    --body-color:      rgba(0, 0, 0, 0.8);
  }

  /*-- ARTICLE TABLE OF CONTENTS --*/
  .d-contents {
    --heading-size:    18px;
    --contents-size:   13px;
  }

  /*-- ARTICLE APPENDIX --*/
  d-appendix {
    --heading-size:    15px;
    --heading-color:   rgba(0, 0, 0, 0.65);
    --text-size:       0.8em;
    --text-color:      rgba(0, 0, 0, 0.5);
  }

  /*-- WEBSITE HEADER + FOOTER --*/
  /* These properties only apply to Distill sites and blogs  */

  .distill-site-header {
    --title-size:       18px;
    --text-color:       white;
    --text-size:        15px;
    --hover-color:      rgba(255, 255, 255, 0.8);
    --bkgd-color:       #BA0C2F;
  }

  .distill-site-footer {
    --text-color:       rgba(255, 255, 255, 0.8);
    --text-size:        15px;
    --hover-color:      white;
    --bkgd-color:       #BA0C2F;
  }

  /*-- Additional custom styles --*/
  /* Add any additional CSS rules below                      */
  </style>
  <style type="text/css">
  /* base style */

  /* FONT FAMILIES */

  :root {
    --heading-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    --mono-default: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    --body-default: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
  }

  body,
  .posts-list .post-preview p,
  .posts-list .description p {
    font-family: var(--body-font), var(--body-default);
  }

  h1, h2, h3, h4, h5, h6,
  .posts-list .post-preview h2,
  .posts-list .description h2 {
    font-family: var(--heading-font), var(--heading-default);
  }

  d-article div.sourceCode code,
  d-article pre code {
    font-family: var(--mono-font), var(--mono-default);
  }


  /*-- TITLE --*/
  d-title h1,
  .posts-list > h1 {
    color: var(--title-color, black);
  }

  d-title h1 {
    font-size: var(--title-size, 50px);
  }

  /*-- HEADERS --*/
  d-article h1,
  d-article h2,
  d-article h3,
  d-article h4,
  d-article h5,
  d-article h6 {
    color: var(--header-color, rgba(0, 0, 0, 0.8));
  }

  /*-- BODY --*/
  d-article > p,  /* only text inside of <p> tags */
  d-article > ul, /* lists */
  d-article > ol {
    color: var(--body-color, rgba(0, 0, 0, 0.8));
    font-size: var(--body-size, 1.06rem);
  }


  /*-- CODE --*/
  d-article div.sourceCode code,
  d-article pre code {
    font-size: var(--code-size, 14px);
  }

  /*-- ASIDE --*/
  d-article aside {
    font-size: var(--aside-size, 12px);
    color: var(--aside-color, rgba(0, 0, 0, 0.6));
  }

  /*-- FIGURE CAPTIONS --*/
  figure .caption,
  figure figcaption,
  .figure .caption {
    font-size: var(--fig-cap-size, 13px);
    color: var(--fig-cap-color, rgba(0, 0, 0, 0.6));
  }

  /*-- METADATA --*/
  d-byline h3 {
    font-size: var(--heading-size, 0.6rem);
    color: var(--heading-color, rgba(0, 0, 0, 0.5));
  }

  d-byline {
    font-size: var(--body-size, 0.8rem);
    color: var(--body-color, rgba(0, 0, 0, 0.8));
  }

  d-byline a,
  d-article d-byline a {
    color: var(--body-color, rgba(0, 0, 0, 0.8));
  }

  /*-- TABLE OF CONTENTS --*/
  .d-contents nav h3 {
    font-size: var(--heading-size, 18px);
  }

  .d-contents nav a {
    font-size: var(--contents-size, 13px);
  }

  /*-- APPENDIX --*/
  d-appendix h3 {
    font-size: var(--heading-size, 15px);
    color: var(--heading-color, rgba(0, 0, 0, 0.65));
  }

  d-appendix {
    font-size: var(--text-size, 0.8em);
    color: var(--text-color, rgba(0, 0, 0, 0.5));
  }

  d-appendix d-footnote-list a.footnote-backlink {
    color: var(--text-color, rgba(0, 0, 0, 0.5));
  }

  /*-- WEBSITE HEADER + FOOTER --*/
  .distill-site-header .title {
    font-size: var(--title-size, 18px);
    font-family: var(--navbar-font), var(--heading-default);
  }

  .distill-site-header a,
  .nav-dropdown .nav-dropbtn {
    font-family: var(--navbar-font), var(--heading-default);
  }

  .nav-dropdown .nav-dropbtn {
    color: var(--text-color, rgba(255, 255, 255, 0.8));
    font-size: var(--text-size, 15px);
  }

  .distill-site-header a:hover,
  .nav-dropdown:hover .nav-dropbtn {
    color: var(--hover-color, white);
  }

  .distill-site-header {
    font-size: var(--text-size, 15px);
    color: var(--text-color, rgba(255, 255, 255, 0.8));
    background-color: var(--bkgd-color, #0F2E3D);
  }

  .distill-site-footer {
    font-size: var(--text-size, 15px);
    color: var(--text-color, rgba(255, 255, 255, 0.8));
    background-color: var(--bkgd-color, #0F2E3D);
  }

  .distill-site-footer a:hover {
    color: var(--hover-color, white);
  }</style>
  <!--/radix_placeholder_distill-->
  <script src="site_libs/header-attrs-2.20/header-attrs.js"></script>
  <script src="site_libs/popper-2.6.0/popper.min.js"></script>
  <link href="site_libs/tippy-6.2.7/tippy.css" rel="stylesheet" />
  <link href="site_libs/tippy-6.2.7/tippy-light-border.css" rel="stylesheet" />
  <script src="site_libs/tippy-6.2.7/tippy.umd.min.js"></script>
  <script src="site_libs/anchor-4.2.2/anchor.min.js"></script>
  <script src="site_libs/bowser-1.9.3/bowser.min.js"></script>
  <script src="site_libs/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="site_libs/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Large Language Models","description":"A dumb auto-complete model -- trained on the entire Internet -- can accomplish a remarkable number of tasks if you ask it nicely.","authors":[]}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<header class="header header--fixed" role="banner">
<nav class="distill-site-nav distill-site-header">
<div class="nav-left">
<a href="index.html" class="title">Text As Data</a>
<div class="nav-dropdown">
<button class="nav-dropbtn">
Harvest the Text
 
<span class="down-arrow">&#x25BE;</span>
</button>
<div class="nav-dropdown-content">
<a href="webscraping.html">Webscraping</a>
<a href="APIs.html">APIs</a>
<a href="OCR.html">Optical Character Recognition</a>
</div>
</div>
<div class="nav-dropdown">
<button class="nav-dropbtn">
Tidy the Text
 
<span class="down-arrow">&#x25BE;</span>
</button>
<div class="nav-dropdown-content">
<a href="bag-of-words.html">Counting Words</a>
<a href="word-embeddings.html">Word Embeddings</a>
<span class="nav-dropdown-header"></span>
</div>
</div>
<div class="nav-dropdown">
<button class="nav-dropbtn">
Model the Text
 
<span class="down-arrow">&#x25BE;</span>
</button>
<div class="nav-dropdown-content">
<a href="federalist-papers.html">Federalist Paper Authorship</a>
<a href="clustering.html">Clustering</a>
<a href="LDA.html">Topic Models</a>
<a href="sentiment-analysis.html">Sentiment Analysis</a>
<a href="supervised-learning.html">Supervised Learning</a>
<a href="LLMs.html">Large Language Models</a>
</div>
</div>
</div>
<div class="nav-right">
<a href="index.html">Home</a>
<a href="syllabus/POLS-8500-syllabus.pdf">Syllabus</a>
<a href="https://app.perusall.com/courses/text-as-data-281296639/">
<i class="fas fa-book-open" aria-hidden="true"></i>
</a>
<a href="https://github.com/joeornstein/maymester-text-as-data-2022">
<i class="fab fa-github" aria-hidden="true"></i>
</a>
<a href="javascript:void(0);" class="nav-toggle">&#9776;</a>
</div>
</nav>
</header>
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Large Language Models</h1>
<!--radix_placeholder_categories-->
<!--/radix_placeholder_categories-->
<p><p>A dumb auto-complete model – trained on the entire Internet – can accomplish a remarkable number of tasks if you ask it nicely.</p></p>
</div>


<div class="d-article">
<div class="d-contents d-contents-float">
<nav class="l-text toc figcaption" id="TOC">
<h3>Contents</h3>
<ul>
<li><a href="#setting-up-the-text2data-package" id="toc-setting-up-the-text2data-package">Setting Up The <code>text2data</code> Package</a></li>
<li><a href="#completing-prompts" id="toc-completing-prompts">Completing Prompts</a></li>
<li><a href="#formatting-prompts" id="toc-formatting-prompts">Formatting Prompts</a></li>
<li><a href="#classifying-documents" id="toc-classifying-documents">Classifying Documents</a></li>
<li><a href="#classifiation-performance" id="toc-classifiation-performance">Classifiation Performance</a></li>
<li><a href="#cleaning-up-ocr" id="toc-cleaning-up-ocr">Cleaning Up OCR</a></li>
<li><a href="#text-to-data" id="toc-text-to-data">Text To Data</a></li>
<li><a href="#practice-problems" id="toc-practice-problems">Practice Problems</a></li>
</ul>
</nav>
</div>
<p>Large language models (LLMs) have transformed the way computer scientists approach natural language processing over the past five years. These models, trained to predict the next word in a sequence, make use of a massive quantity of text data from the Internet and digitized books. In this tutorial, I will hand-wave over exactly <em>how</em> LLMs perform this task, focusing instead on how to adapt such models for use in social science applications. If you are interested in what’s going on under the hood, I highly recommend the following two blog posts for not-too-technical introductions:</p>
<ul>
<li><p><a href="https://dugas.ch/artificial_curiosity/GPT_architecture.html">The GPT-3 Architecture, on a Napkin</a></p></li>
<li><p><a href="https://www.understandingai.org/p/large-language-models-explained-with">Large language models, explained with a minimum of math and jargon</a>.</p></li>
</ul>
<p>In a nutshell, LLMs represent words using <a href="word-embeddings.html">embeddings</a>, and are trained to predict the most likely next word in a sequence using a model architecture called the <strong>transformer</strong> <span class="citation" data-cites="vaswaniAttentionAllYou2017">(<a href="#ref-vaswaniAttentionAllYou2017" role="doc-biblioref">Vaswani et al. 2017</a>)</span>. A powerful feature of this type of model is that the embeddings representing the input sequence are iteratively updated based on which words appear nearby (a process called <strong>self-attention</strong>). This allows an LLM to flexibly represent words based on their context, which is useful in cases where the same word can mean different things in different contexts. For example, an LLM will represent the word “bill” differently depending on whether it appears in the phrase “sign the bill”, “foot the bill”, or “Hillary and Bill”.</p>
<p>What’s remarkable is that if we have a model that is sufficiently good at predicting the next word in a sequence, we can <em>adapt</em> it to perform all sorts of text-as-data tasks, by creating a prompt that converts our desired task into a next-word prediction problem <span class="citation" data-cites="ornsteinHowTrainYour2022">(<a href="#ref-ornsteinHowTrainYour2022" role="doc-biblioref">Ornstein, Blasingame, and Truscott 2022</a>)</span>. To show you how, we will use the <code>text2data</code> R package to create LLM prompts and submit them to OpenAI’s GPT-3.<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> Let’s start by getting the R package set up.</p>
<h2 id="setting-up-the-text2data-package">Setting Up The <code>text2data</code> Package</h2>
<p>The package is currently available as a GitHub repository. To install, first make sure you have the <code>devtools</code> package available, then you can install the package with the following line of code:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'>devtools</span><span class='fu'>::</span><span class='fu'><a href='https://remotes.r-lib.org/reference/install_github.html'>install_github</a></span><span class='op'>(</span><span class='st'>'joeornstein/text2data'</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>If you have not yet installed Python and the <code>reticulate</code> package on your computer, follow the instructions for doing so <a href="APIs.html#How%20to%20Drive%20Python%20from%20RStudio">here</a>. Once that step is complete, you can set up OpenAI’s Python module using the <code>setup_openai()</code> function, which will allow you to submit prompts to the GPT-3 API.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>text2data</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/pkg/text2data/man/setup_openai.html'>setup_openai</a></span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<p>Next, you will need an account with OpenAI. You can sign up for one <a href="https://platform.openai.com/signup">here</a>, after which you will need to generate an API key <a href="https://platform.openai.com/account/api-keys">here</a>. I recommend adding this <a href="APIs.html">API key</a> as a variable in your operating system environment called <code>OPENAI_API_KEY</code>; that way you won’t risk leaking it by hard-coding it into your <code>R</code> scripts. The <code>text2data</code> package will automatically look for your API key under that variable name, and will prompt you to enter the API key manually if it can’t find one there. If you’re unfamiliar with setting Environment Variables in your operating system, <a href="https://dev.to/biplov/handling-passwords-and-secret-keys-using-environment-variables-2ei0">here</a> are some helpful instructions. Note that you may need to restart your computer after completing this step.</p>
<p>When the setup is complete, we can begin.</p>
<h2 id="completing-prompts">Completing Prompts</h2>
<p>The workhorse function of the <code>text2data</code> package is <code>complete_prompt()</code>. This function submits a sequence of words (the prompt) to the OpenAI API, and returns a dataframe with the five highest-probability next word predictions and their associated probabilities.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a></p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>text2data</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/pkg/text2data/man/complete_prompt.html'>complete_prompt</a></span><span class='op'>(</span>prompt <span class='op'>=</span> <span class='st'>'My favorite food is'</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code>  response       prob
1    pizza 0.08614531
2        a 0.03913327
3    sushi 0.03705063
4  chicken 0.01834140
5    pasta 0.01819866</code></pre>
</div>
<p>If you prefer the model to auto-regressively generate sequences of text instead of outputting the next-word probabilities, set the <code>max_tokens</code> argument greater than 1. The function will return a character object with the most likely completion at each point in the sequence.</p>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/pkg/text2data/man/complete_prompt.html'>complete_prompt</a></span><span class='op'>(</span>prompt <span class='op'>=</span> <span class='st'>'My favorite food is'</span>, </span>
<span>                max_tokens <span class='op'>=</span> <span class='fl'>6</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code>[1] &quot; pizza. I love pizza.&quot;</code></pre>
</div>
<p>If we want GPT-3 to perform a classification task, we can structure the prompt so that the best next-word prediction is the classification we want (a process called <strong>adaptation</strong>). Consider, for example, the following prompt.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>prompt</span> <span class='op'>&lt;-</span> <span class='st'>'Decide whether the following statement is happy, sad, or neither.\n\nText: I feel happy.\nClassification:'</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='va'>prompt</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Decide whether the following statement is happy, sad, or neither.

Text: I feel happy.
Classification:</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/pkg/text2data/man/complete_prompt.html'>complete_prompt</a></span><span class='op'>(</span><span class='va'>prompt</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code>  response       prob
1    happy 0.25048140
2    Happy 0.14383937
3      Sad 0.09507202
4      sad 0.05949457
5  Neither 0.04669781</code></pre>
</div>
<p>The result is a probability vector with the most likely completions. The correct classification – happy – is assigned the highest probability, though note that some post-processing is necessary to combine the “happy” and “Happy” responses.</p>
<p>A <strong>few-shot prompt</strong> includes several completed examples in the text of the prompt to demonstrate the desired output. Prompts structured this way tend perform significantly better than zero-shot prompts with no examples <span class="citation" data-cites="brownLanguageModelsAre2020">(<a href="#ref-brownLanguageModelsAre2020" role="doc-biblioref">Brown et al. 2020</a>)</span>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>prompt</span> <span class='op'>&lt;-</span> <span class='st'>'Decide whether the following statement is happy, sad, or neither.\n\nText: What should we do today?.\nClassification: Neither\n\nText: My puppy is so cute today.\nClassification: Happy\n\nText: The news is bumming me out.\nClassification: Sad\n\nText: I feel happy.\nClassification:'</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='va'>prompt</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Decide whether the following statement is happy, sad, or neither.

Text: What should we do today?.
Classification: Neither

Text: My puppy is so cute today.
Classification: Happy

Text: The news is bumming me out.
Classification: Sad

Text: I feel happy.
Classification:</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/pkg/text2data/man/complete_prompt.html'>complete_prompt</a></span><span class='op'>(</span><span class='va'>prompt</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code>  response        prob
1    Happy 0.868470778
2  Neither 0.071847533
3      Sad 0.014258582
4     None 0.004738859
5     Both 0.004486662</code></pre>
</div>
<h2 id="formatting-prompts">Formatting Prompts</h2>
<p>Manually typing prompts with multiple few-shot examples can be tedious and error-prone, particularly when performing the sort of context-specific prompting we recommend in our paper <span class="citation" data-cites="ornsteinHowTrainYour2022">(<a href="#ref-ornsteinHowTrainYour2022" role="doc-biblioref">Ornstein, Blasingame, and Truscott 2022</a>)</span>. The <code>format_prompt()</code> function is a useful tool to aid in that process.</p>
<p>The function is designed with classification problems in mind. If you input the text you would like to classify along with a set of instructions, the default prompt template looks like this:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>text2data</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/pkg/text2data/man/format_prompt.html'>format_prompt</a></span><span class='op'>(</span>text <span class='op'>=</span> <span class='st'>'I am feeling happy today.'</span>,</span>
<span>              instructions <span class='op'>=</span> <span class='st'>'Decide whether this statment is happy, sad, or neither.'</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Decide whether this statment is happy, sad, or neither.

Text: I am feeling happy today.
Classification:</code></pre>
</div>
<p>You can customize the template using <code>glue</code> syntax, with placeholders for the text you want to classify {text} and the desired label {label}.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/pkg/text2data/man/format_prompt.html'>format_prompt</a></span><span class='op'>(</span>text <span class='op'>=</span> <span class='st'>'I am feeling happy today.'</span>,</span>
<span>              instructions <span class='op'>=</span> <span class='st'>'Decide whether this statment is happy or sad.'</span>,</span>
<span>              template <span class='op'>=</span> <span class='st'>'Statement: {text}\nSentiment: {label}'</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Decide whether this statment is happy or sad.

Statement: I am feeling happy today.
Sentiment:</code></pre>
</div>
<p>This is particularly useful when including few-shot examples in the prompt. If you input these examples as a tidy dataframe with the columns <code>text</code> and <code>label</code>, the <code>format_prompt()</code> function will paste them into the prompt them according to the template. To illustrate, let’s classify the sentiment of a set of tweets about the Supreme Court of the United States, a dataset which is included with the <code>text2data</code> package.</p>
<h2 id="classifying-documents">Classifying Documents</h2>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span><span class='op'>(</span><span class='va'>scotus_tweets</span><span class='op'>)</span> <span class='co'># the full dataset</span></span>
<span><span class='fu'><a href='https://rdrr.io/r/utils/data.html'>data</a></span><span class='op'>(</span><span class='va'>scotus_tweets_examples</span><span class='op'>)</span> <span class='co'># a sample of labeled examples</span></span></code></pre>
</div>
</div>
<p>We can format our few-shot prompt template using <code>format_prompt()</code>, leaving the <code>{TWEET}</code> placeholder for the text we want to classify:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://tidyverse.tidyverse.org'>tidyverse</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://github.com/tidyverse/glue'>glue</a></span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>prompt</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/text2data/man/format_prompt.html'>format_prompt</a></span><span class='op'>(</span>text <span class='op'>=</span> <span class='st'>'{TWEET}'</span>,</span>
<span>              instructions <span class='op'>=</span> <span class='st'>'Classify the sentiment of these tweets as Positive, Neutral, or Negative.'</span>,</span>
<span>              examples <span class='op'>=</span> <span class='va'>scotus_tweets_examples</span> <span class='op'>|&gt;</span> </span>
<span>                <span class='fu'><a href='https://dplyr.tidyverse.org/reference/filter.html'>filter</a></span><span class='op'>(</span><span class='va'>case</span> <span class='op'>==</span> <span class='st'>'masterpiece'</span><span class='op'>)</span>,</span>
<span>              template <span class='op'>=</span> <span class='st'>'Tweet: {text}\nSentiment: {label}'</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>prompt</span></span></code></pre>
</div>
<pre><code>Classify the sentiment of these tweets as Positive, Neutral, or Negative.

Tweet: Thank you Supreme Court I take pride in your decision!!!!✝️ #SCOTUS
Sentiment: Positive

Tweet: Supreme Court rules in favor of Colorado baker! This day is getting better by the minute!
Sentiment: Positive

Tweet: Can’t escape the awful irony of someone allowed to use religion to discriminate against people in love. 
Not my Jesus. 
#opentoall #SCOTUS #Hypocrisy #MasterpieceCakeshop
Sentiment: Negative

Tweet: I can’t believe this cake case went all the way to #SCOTUS . Can someone let me know what cake was ultimately served at the wedding? Are they married and living happily ever after?
Sentiment: Neutral

Tweet: Supreme Court rules in favor of baker who would not make wedding cake for gay couple
Sentiment: Neutral

Tweet: #SCOTUS set a dangerous precedent today. Although the Court limited the scope to which a business owner could deny services to patrons, the legal argument has been legitimized that one&#39;s subjective religious convictions trump (no pun intended) #humanrights. #LGBTQRights
Sentiment: Negative

Tweet: {TWEET}
Sentiment:</code></pre>
</div>
<p>Using the <code>glue()</code> function, we can insert tweets into that template.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>TWEET</span> <span class='op'>&lt;-</span> <span class='va'>scotus_tweets</span><span class='op'>$</span><span class='va'>text</span><span class='op'>[</span><span class='fl'>42</span><span class='op'>]</span></span>
<span><span class='va'>TWEET</span></span></code></pre>
</div>
<pre><code>[1] &quot;This Supreme Court ruling highlights why there needs to be term limits for scotus, healthcare needs to uncoupled from employment, Christianity brings nothing but evil but, most importantly it shows you why voting at every level matters&quot;</code></pre>
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://glue.tidyverse.org/reference/glue.html'>glue</a></span><span class='op'>(</span><span class='va'>prompt</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Classify the sentiment of these tweets as Positive, Neutral, or Negative.

Tweet: Thank you Supreme Court I take pride in your decision!!!!✝️ #SCOTUS
Sentiment: Positive

Tweet: Supreme Court rules in favor of Colorado baker! This day is getting better by the minute!
Sentiment: Positive

Tweet: Can’t escape the awful irony of someone allowed to use religion to discriminate against people in love. 
Not my Jesus. 
#opentoall #SCOTUS #Hypocrisy #MasterpieceCakeshop
Sentiment: Negative

Tweet: I can’t believe this cake case went all the way to #SCOTUS . Can someone let me know what cake was ultimately served at the wedding? Are they married and living happily ever after?
Sentiment: Neutral

Tweet: Supreme Court rules in favor of baker who would not make wedding cake for gay couple
Sentiment: Neutral

Tweet: #SCOTUS set a dangerous precedent today. Although the Court limited the scope to which a business owner could deny services to patrons, the legal argument has been legitimized that one&#39;s subjective religious convictions trump (no pun intended) #humanrights. #LGBTQRights
Sentiment: Negative

Tweet: This Supreme Court ruling highlights why there needs to be term limits for scotus, healthcare needs to uncoupled from employment, Christianity brings nothing but evil but, most importantly it shows you why voting at every level matters
Sentiment:</code></pre>
</div>
<p>We can then pipe that prompt into <code>complete_prompt()</code> to output the desired classification:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>prompt</span> <span class='op'>|&gt;</span> </span>
<span>  <span class='fu'><a href='https://glue.tidyverse.org/reference/glue.html'>glue</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>|&gt;</span> </span>
<span>  <span class='fu'><a href='https://rdrr.io/pkg/text2data/man/complete_prompt.html'>complete_prompt</a></span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code>   response         prob
1  Negative 0.7229223011
2   Neutral 0.1358330800
3  Positive 0.1276033570
4     Mixed 0.0048710128
5           0.0007889828</code></pre>
</div>
<h2 id="classifiation-performance">Classifiation Performance</h2>
<p>As we saw in the <a href="sentiment-analysis.html">sentiment analysis</a> tutorial, conventional methods for classifying sentiment perform pretty poorly on text from social media. Does this approach perform any better? To find out, let’s complete the prompt for each of the tweets in the <code>scotus_tweets</code> dataframe related to the Masterpiece Cakeshop ruling, create a measure of sentiment, and compare it against the human coders.</p>
<p>First, create our prompt template with <code>format_prompt()</code>, this time with a bit more detail in the instructions. For few-shot examples, we’ll use the ‘masterpiece’ tweets in <code>scotus_tweets_examples</code>. These are six tweets that were unanimously coded by three human annotators as Positive, Negative, or Neutral (two per category).</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>prompt</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/text2data/man/format_prompt.html'>format_prompt</a></span><span class='op'>(</span>text <span class='op'>=</span> <span class='st'>'{TWEET}'</span>,</span>
<span>              instructions <span class='op'>=</span> <span class='st'>'Read these tweets posted the day after the US Supreme Court ruled in </span></span>
<span><span class='st'>              favor of a baker who refused to bake a wedding cake for a same-sex couple. </span></span>
<span><span class='st'>              For each tweet, decide whether its sentiment is Positive, Neutral, or Negative.'</span>,</span>
<span>              examples <span class='op'>=</span> <span class='va'>scotus_tweets_examples</span> <span class='op'>|&gt;</span> </span>
<span>                <span class='fu'><a href='https://dplyr.tidyverse.org/reference/filter.html'>filter</a></span><span class='op'>(</span><span class='va'>case</span> <span class='op'>==</span> <span class='st'>'masterpiece'</span><span class='op'>)</span>,</span>
<span>              template <span class='op'>=</span> <span class='st'>'Tweet: {text}\nSentiment: {label}'</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='va'>prompt</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code>Read these tweets posted the day after the US Supreme Court ruled in favor of a baker who refused to bake a wedding cake for a same-sex couple. For each tweet, decide whether its sentiment is Positive, Neutral, or Negative.

Tweet: Thank you Supreme Court I take pride in your decision!!!!✝️ #SCOTUS
Sentiment: Positive

Tweet: Supreme Court rules in favor of Colorado baker! This day is getting better by the minute!
Sentiment: Positive

Tweet: Can’t escape the awful irony of someone allowed to use religion to discriminate against people in love. 
Not my Jesus. 
#opentoall #SCOTUS #Hypocrisy #MasterpieceCakeshop
Sentiment: Negative

Tweet: I can’t believe this cake case went all the way to #SCOTUS . Can someone let me know what cake was ultimately served at the wedding? Are they married and living happily ever after?
Sentiment: Neutral

Tweet: Supreme Court rules in favor of baker who would not make wedding cake for gay couple
Sentiment: Neutral

Tweet: #SCOTUS set a dangerous precedent today. Although the Court limited the scope to which a business owner could deny services to patrons, the legal argument has been legitimized that one&#39;s subjective religious convictions trump (no pun intended) #humanrights. #LGBTQRights
Sentiment: Negative

Tweet: {TWEET}
Sentiment:</code></pre>
</div>
<p>Next, we’ll create a function that takes the dataframe of next-word predictions from GPT-3 and converts it into a measure of sentiment. For this tutorial, our measure will be <span class="math inline">\(P(\text{positive}) - P(\text{negative})\)</span>.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>gpt3_sentiment_score</span> <span class='op'>&lt;-</span> <span class='kw'>function</span><span class='op'>(</span><span class='va'>df</span><span class='op'>)</span><span class='op'>{</span></span>
<span>  </span>
<span>  <span class='va'>p_positive</span> <span class='op'>&lt;-</span> <span class='va'>df</span> <span class='op'>|&gt;</span> </span>
<span>    <span class='co'># put responses in all caps</span></span>
<span>    <span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate</a></span><span class='op'>(</span>response <span class='op'>=</span> <span class='fu'><a href='https://stringr.tidyverse.org/reference/case.html'>str_to_upper</a></span><span class='op'>(</span><span class='va'>response</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>|&gt;</span> </span>
<span>    <span class='co'># keep and sum probabilities assigned to "POS"</span></span>
<span>    <span class='fu'><a href='https://dplyr.tidyverse.org/reference/filter.html'>filter</a></span><span class='op'>(</span><span class='fu'><a href='https://stringr.tidyverse.org/reference/str_detect.html'>str_detect</a></span><span class='op'>(</span><span class='va'>response</span>, <span class='st'>'POS'</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>|&gt;</span> </span>
<span>    <span class='fu'><a href='https://dplyr.tidyverse.org/reference/pull.html'>pull</a></span><span class='op'>(</span><span class='va'>prob</span><span class='op'>)</span> <span class='op'>|&gt;</span> </span>
<span>    <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='va'>p_negative</span> <span class='op'>&lt;-</span> <span class='va'>df</span> <span class='op'>|&gt;</span> </span>
<span>    <span class='co'># put responses in all caps</span></span>
<span>    <span class='fu'><a href='https://dplyr.tidyverse.org/reference/mutate.html'>mutate</a></span><span class='op'>(</span>response <span class='op'>=</span> <span class='fu'><a href='https://stringr.tidyverse.org/reference/case.html'>str_to_upper</a></span><span class='op'>(</span><span class='va'>response</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>|&gt;</span> </span>
<span>    <span class='co'># keep and sum probabilities assigned to "NEG"</span></span>
<span>    <span class='fu'><a href='https://dplyr.tidyverse.org/reference/filter.html'>filter</a></span><span class='op'>(</span><span class='fu'><a href='https://stringr.tidyverse.org/reference/str_detect.html'>str_detect</a></span><span class='op'>(</span><span class='va'>response</span>, <span class='st'>'NEG'</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>|&gt;</span> </span>
<span>    <span class='fu'><a href='https://dplyr.tidyverse.org/reference/pull.html'>pull</a></span><span class='op'>(</span><span class='va'>prob</span><span class='op'>)</span> <span class='op'>|&gt;</span> </span>
<span>    <span class='fu'><a href='https://rdrr.io/r/base/sum.html'>sum</a></span><span class='op'>(</span><span class='op'>)</span></span>
<span>  </span>
<span>  <span class='kw'><a href='https://rdrr.io/r/base/function.html'>return</a></span><span class='op'>(</span><span class='va'>p_positive</span> <span class='op'>-</span> <span class='va'>p_negative</span><span class='op'>)</span></span>
<span><span class='op'>}</span></span></code></pre>
</div>
</div>
<p>We can add this function to the end of the pipeline we developed before.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>prompt</span> <span class='op'>|&gt;</span> </span>
<span>  <span class='fu'><a href='https://glue.tidyverse.org/reference/glue.html'>glue</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>|&gt;</span> </span>
<span>  <span class='fu'><a href='https://rdrr.io/pkg/text2data/man/complete_prompt.html'>complete_prompt</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>|&gt;</span> </span>
<span>  <span class='fu'>gpt3_sentiment_score</span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code>[1] -0.7517173</code></pre>
</div>
<p>With these elements in place, let’s loop through the <code>scotus_tweets</code> dataset and estimate sentiment scores for each tweet referencing Masterpiece Cakeshop. <strong>Be mindful before you run this code.</strong> At <a href="https://openai.com/pricing">current prices</a>, OpenAI will charge approximately 0.07 cents per prompt, for a total of $0.65 if you classify all 945 tweets.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>scotus_tweets</span><span class='op'>$</span><span class='va'>gpt3_sentiment</span> <span class='op'>&lt;-</span> <span class='cn'>NA</span></span>
<span></span>
<span><span class='kw'>for</span><span class='op'>(</span><span class='va'>i</span> <span class='kw'>in</span> <span class='fl'>1</span><span class='op'>:</span><span class='fu'><a href='https://rdrr.io/r/base/nrow.html'>nrow</a></span><span class='op'>(</span><span class='va'>scotus_tweets</span><span class='op'>)</span><span class='op'>)</span><span class='op'>{</span></span>
<span>  </span>
<span>  <span class='co'># skip the non-masterpiece tweets</span></span>
<span>  <span class='kw'>if</span><span class='op'>(</span><span class='va'>scotus_tweets</span><span class='op'>$</span><span class='va'>case</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span> <span class='op'>!=</span> <span class='st'>'masterpiece'</span><span class='op'>)</span><span class='op'>{</span></span>
<span>    <span class='kw'>next</span></span>
<span>  <span class='op'>}</span></span>
<span>  </span>
<span>  <span class='co'># get the tweet text</span></span>
<span>  <span class='va'>TWEET</span> <span class='op'>&lt;-</span> <span class='va'>scotus_tweets</span><span class='op'>$</span><span class='va'>text</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span></span>
<span>  </span>
<span>  <span class='co'># format the prompt, send it to GPT-3, and construct the sentiment measure </span></span>
<span>  <span class='va'>scotus_tweets</span><span class='op'>$</span><span class='va'>gpt3_sentiment</span><span class='op'>[</span><span class='va'>i</span><span class='op'>]</span> <span class='op'>&lt;-</span> <span class='va'>prompt</span> <span class='op'>|&gt;</span> </span>
<span>    <span class='fu'><a href='https://glue.tidyverse.org/reference/glue.html'>glue</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>|&gt;</span> </span>
<span>    <span class='fu'><a href='https://rdrr.io/pkg/text2data/man/complete_prompt.html'>complete_prompt</a></span><span class='op'>(</span><span class='op'>)</span> <span class='op'>|&gt;</span> </span>
<span>    <span class='fu'>gpt3_sentiment_score</span><span class='op'>(</span><span class='op'>)</span></span>
<span>  </span>
<span><span class='op'>}</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<p>Plotting those sentiment scores against the average of the hand-coded scores, we can see that this measure is much better than the one from the <a href="sentiment-analysis.html">dictionary method</a> we tried before. The correlation between the two scores is 0.75.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://ggplot2.tidyverse.org/reference/ggplot.html'>ggplot</a></span><span class='op'>(</span>data <span class='op'>=</span> <span class='va'>scotus_tweets</span>,</span>
<span>       mapping <span class='op'>=</span> <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/aes.html'>aes</a></span><span class='op'>(</span>x <span class='op'>=</span> <span class='op'>(</span><span class='va'>expert1</span> <span class='op'>+</span> <span class='va'>expert2</span> <span class='op'>+</span> <span class='va'>expert3</span><span class='op'>)</span> <span class='op'>/</span> <span class='fl'>3</span>,</span>
<span>                     y <span class='op'>=</span> <span class='va'>gpt3_sentiment</span><span class='op'>)</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/geom_jitter.html'>geom_jitter</a></span><span class='op'>(</span>width <span class='op'>=</span> <span class='fl'>0.1</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/labs.html'>labs</a></span><span class='op'>(</span>x <span class='op'>=</span> <span class='st'>'Hand-Coded Sentiment Score'</span>,</span>
<span>       y <span class='op'>=</span> <span class='st'>'GPT-3 Sentiment Score'</span><span class='op'>)</span> <span class='op'>+</span></span>
<span>  <span class='fu'><a href='https://ggplot2.tidyverse.org/reference/ggtheme.html'>theme_minimal</a></span><span class='op'>(</span><span class='op'>)</span></span></code></pre>
</div>
<p><img src="LLMs_files/figure-html5/unnamed-chunk-34-1.png" width="624" /></p>
</div>
<p>All in all, few-shot prompting an LLM is a powerful method for classifying documents without the need for extensive fine-tuning or large sets of training data, as with <a href="supervised-learning.html">supervised learning</a> methods.</p>
<h2 id="cleaning-up-ocr">Cleaning Up OCR</h2>
<p>In the <a href="OCR.html">OCR tutorial</a>, we worked with a newspaper clipping about the sinking of the Titanic.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://docs.ropensci.org/tesseract/'>tesseract</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'><a href='https://docs.ropensci.org/magick/'>magick</a></span><span class='op'>)</span></span>
<span><span class='kw'><a href='https://rdrr.io/r/base/library.html'>library</a></span><span class='op'>(</span><span class='va'>text2data</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>image</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://docs.ropensci.org/magick/reference/editing.html'>image_read</a></span><span class='op'>(</span><span class='st'>'img/titanic.png'</span><span class='op'>)</span></span>
<span><span class='va'>image</span></span></code></pre>
</div>
<p><img src="LLMs_files/figure-html5/unnamed-chunk-35-1.png" width="505" /></p>
</div>
<p>Let’s focus for now on the first column.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>first_column</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://docs.ropensci.org/magick/reference/transform.html'>image_crop</a></span><span class='op'>(</span><span class='va'>image</span>,</span>
<span>                           geometry <span class='op'>=</span> <span class='st'>'336 x 660 + 0 + 0'</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>first_column</span></span></code></pre>
</div>
<p><img src="LLMs_files/figure-html5/unnamed-chunk-36-1.png" width="168" /></p>
</div>
<p>Though a human can easily read and interpret this text, converting the image to plain text is a non-trivial problem in the field of computer vision. Note that the text is slightly tilted in places, and some lines are squished or cut off. A smudge obscures some letters in the lower left corner.</p>
<p>How well does OCR capture the text from that image?</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>text</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://docs.ropensci.org/tesseract/reference/ocr.html'>ocr</a></span><span class='op'>(</span><span class='va'>first_column</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='va'>text</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Titanic Sank at 2:20 A. M. Monday.
In the White Star offices the hope
was held out all day that the Parisian
ond the Virginian had taken off some
-{ the Titanic&#39;s passengers, and efforts
were made to get into communication
with these liners, Until such commu-
nication was established the White
Star officials reused tu recusiiee ce
possibility that there were none of the
Titanic’s passengers aboard them.

But by nightfall came the message
from Capt. Haddock of the Olympic to
Cape Race,’ Newfoundland, telling of
the foundering of the Titanic and of
the rescue of 655 of her passengers by
the Cunarder Carpathia, which, the
Wireless message waid, reached the pos!-
tion of the Titanic at daybreak. All
they found there, however, was lif¢-
boats and wreckage. The biggest ship
in the world had sunk at 2:20 o&#39;clock
yesterday morning.

Mr, Franklin admitted late last ulght
thet the Parisian and the Virginian,
though they were among the first to
answer the Titanic’s calls for help,
could not have reached the scene before
10 o&#39;clock yesterday morning, seven
and a half hours after the big Titanic
buried her nese beneath the waves and
Pitched downward out of sight. The
Carpathia, so the wireless dispatch

m Capt. Haddock to Cape Race an-.
jounced, reached the scene of the Ti-,
‘sanic&#39;s foundering at daybreak, several</code></pre>
</div>
<p>As is common with OCR, the result is generally quite good, but not perfect. Notice, for example, the phrases “reused tu recusiiee ce”, “lif¢-boats”, and “Ti-,’sanic’s”. Look closely at the letters in the image above to see how the OCR algorithm may have made those mistakes. When you consider the image letter-by-letter, ignoring the semantic context in which those letters are placed, it is easy to mistake some letters for others. But when humans read a passage like this, they’re not reading it letter-by-letter. Instead, fluent readers learn to recognize whole words at a time, using their knowledge of the language to “predict” what the constituent letters of a word must be, even when they are difficult to make out on the page. In the same way, we can make use of the fact that GPT-3 is very good at predicting words in sequences to impute what the phrase “reused tu recusiiee ce” is likely to have been, given the context.</p>
<p>To do so, we can prompt GPT-3 like so:</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>prompt</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://glue.tidyverse.org/reference/glue.html'>glue</a></span><span class='op'>(</span><span class='st'>'Create a copy of the following passage, correcting any OCR errors.\n---\nOriginal Passage:\n\n{text}\n---\nCorrected Passage:\n\n'</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='va'>prompt</span><span class='op'>)</span></span></code></pre>
</div>
<pre><code>Create a copy of the following passage, correcting any OCR errors.
---
Original Passage:

Titanic Sank at 2:20 A. M. Monday.
In the White Star offices the hope
was held out all day that the Parisian
ond the Virginian had taken off some
-{ the Titanic&#39;s passengers, and efforts
were made to get into communication
with these liners, Until such commu-
nication was established the White
Star officials reused tu recusiiee ce
possibility that there were none of the
Titanic’s passengers aboard them.

But by nightfall came the message
from Capt. Haddock of the Olympic to
Cape Race,’ Newfoundland, telling of
the foundering of the Titanic and of
the rescue of 655 of her passengers by
the Cunarder Carpathia, which, the
Wireless message waid, reached the pos!-
tion of the Titanic at daybreak. All
they found there, however, was lif¢-
boats and wreckage. The biggest ship
in the world had sunk at 2:20 o&#39;clock
yesterday morning.

Mr, Franklin admitted late last ulght
thet the Parisian and the Virginian,
though they were among the first to
answer the Titanic’s calls for help,
could not have reached the scene before
10 o&#39;clock yesterday morning, seven
and a half hours after the big Titanic
buried her nese beneath the waves and
Pitched downward out of sight. The
Carpathia, so the wireless dispatch

m Capt. Haddock to Cape Race an-.
jounced, reached the scene of the Ti-,
‘sanic&#39;s foundering at daybreak, several

---
Corrected Passage:</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>cleaned_text</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/text2data/man/complete_prompt.html'>complete_prompt</a></span><span class='op'>(</span></span>
<span>  prompt <span class='op'>=</span> <span class='va'>prompt</span>,</span>
<span>  max_tokens <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/nchar.html'>nchar</a></span><span class='op'>(</span><span class='va'>text</span><span class='op'>)</span>,</span>
<span>  model <span class='op'>=</span> <span class='st'>'gpt-3.5-turbo'</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='va'>cleaned_text</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code>Titanic sank at 2:20 A.M. Monday.
In the White Star offices the hope
was held out all day that the Parisian
and the Virginian had taken off some
of the Titanic&#39;s passengers, and efforts
were made to get into communication
with these liners. Until such commu-
nication was established the White
Star officials refused to concede the
possibility that there were none of the
Titanic&#39;s passengers aboard them.

But by nightfall came the message
from Capt. Haddock of the Olympic to
Cape Race, Newfoundland, telling of
the foundering of the Titanic and of
the rescue of 655 of her passengers by
the Cunarder Carpathia, which, the
wireless message said, reached the post-
tion of the Titanic at daybreak. All
they found there, however, was life-
boats and wreckage. The biggest ship
in the world had sunk at 2:20 o&#39;clock
yesterday morning.

Mr. Franklin admitted late last night
that the Parisian and the Virginian,
though they were among the first to
answer the Titanic&#39;s calls for help,
could not have reached the scene before
10 o&#39;clock yesterday morning, seven
and a half hours after the big Titanic
buried her nose beneath the waves and
pitched downward out of sight. The
Carpathia, so the wireless dispatch
from Capt. Haddock to Cape Race an-
nounced, reached the scene of the Ti-
tanic&#39;s foundering at daybreak, several</code></pre>
</div>
<p>The resulting text is a nearly perfect transcription, despite the garbled inputs! The <code>text2data::clean_ocr()</code> function performs these steps in a single function call.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>cleaned_text</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/text2data/man/clean_ocr.html'>clean_ocr</a></span><span class='op'>(</span><span class='va'>text</span><span class='op'>)</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/r/base/cat.html'>cat</a></span><span class='op'>(</span><span class='va'>cleaned_text</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code>Titanic sank at 2:20 A.M. Monday.
In the White Star offices the hope
was held out all day that the Parisian
and the Virginian had taken off some
of the Titanic&#39;s passengers, and efforts
were made to get into communication
with these liners. Until such commu-
nication was established the White
Star officials refused to concede the
possibility that there were none of the
Titanic&#39;s passengers aboard them.

But by nightfall came the message
from Capt. Haddock of the Olympic to
Cape Race, Newfoundland, telling of
the foundering of the Titanic and of
the rescue of 655 of her passengers by
the Cunarder Carpathia, which, the
wireless message said, reached the post-
tion of the Titanic at daybreak. All
they found there, however, was life-
boats and wreckage. The biggest ship
in the world had sunk at 2:20 o&#39;clock
yesterday morning.

Mr. Franklin admitted late last night
that the Parisian and the Virginian,
though they were among the first to
answer the Titanic&#39;s calls for help,
could not have reached the scene before
10 o&#39;clock yesterday morning, seven
and a half hours after the big Titanic
buried her nose beneath the waves and
pitched downward out of sight. The
Carpathia, so the wireless dispatch
from Capt. Haddock to Cape Race an-
nounced, reached the scene of the Ti-
tanic&#39;s foundering at daybreak, several</code></pre>
</div>
<h2 id="text-to-data">Text To Data</h2>
<p>One of the most labor-intensive tasks in a research workflow involves converting unstructured text to structured datasets. Traditionally, this is a task that has only been suitable for human research assistants, but with LLMs, a truly automated workflow is feasible. Consider the following prompt:</p>
<div class="layout-chunk" data-layout="l-body">
<pre><code>Create a data table from the following passage.
---
The little dog laughed to see such fun, and the dish ran away with the spoon.
---
Data Table:
Character | What They Did 
---|---</code></pre>
</div>
<p>When we submit this prompt to ChatGPT, it yields a data table delimited by vertical bars, which can then be read into a dataframe.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>prompt</span> <span class='op'>&lt;-</span> <span class='st'>'Create a data table from the following passage.\n---\nThe little dog laughed to see such fun, and the dish ran away with the spoon.\n---\nData Table:\nCharacter | What They Did \n---|---\n'</span></span>
<span></span>
<span><span class='va'>response</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/pkg/text2data/man/complete_prompt.html'>complete_prompt</a></span><span class='op'>(</span><span class='va'>prompt</span>, </span>
<span>                            max_tokens <span class='op'>=</span> <span class='fl'>100</span>,</span>
<span>                            model <span class='op'>=</span> <span class='st'>'gpt-3.5-turbo'</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>response</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code>[1] &quot;Little dog | Laughed \nDish | Ran away with the spoon&quot;</code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>df</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://readr.tidyverse.org/reference/read_delim.html'>read_delim</a></span><span class='op'>(</span><span class='va'>response</span>,</span>
<span>                 delim <span class='op'>=</span> <span class='st'>'|'</span>,</span>
<span>                 col_names <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span></span>
<span></span>
<span><span class='va'>df</span></span></code></pre>
</div>
<pre><code># A tibble: 2 × 2
  X1            X2                        
  &lt;chr&gt;         &lt;chr&gt;                     
1 &quot;Little dog &quot; &quot; Laughed &quot;               
2 &quot;Dish &quot;       &quot; Ran away with the spoon&quot;</code></pre>
</div>
<p>Formatting this sort of prompt by hand can be tedious and error-prone, so the <code>parse_text()</code> function puts all those steps together in a more convenient interface.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='fu'><a href='https://rdrr.io/pkg/text2data/man/parse_text.html'>parse_text</a></span><span class='op'>(</span>instructions <span class='op'>=</span> <span class='st'>'Create a data table from the following passage.'</span>,</span>
<span>           text <span class='op'>=</span> <span class='st'>'The little dog laughed to see such fun, and the dish ran away with the spoon.'</span>,</span>
<span>           col_names <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>'Character'</span>, <span class='st'>'What They Did'</span><span class='op'>)</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code># A tibble: 2 × 2
  Character  `What They Did`        
  &lt;chr&gt;      &lt;chr&gt;                  
1 Little dog Laughed                
2 Dish       Ran away with the spoon</code></pre>
</div>
<p>As with classification, more detailed instructions typically yield better completions.</p>
<div class="layout-chunk" data-layout="l-body">
<div class="sourceCode">
<pre class="sourceCode r"><code class="sourceCode r"><span><span class='va'>instructions</span> <span class='op'>&lt;-</span> <span class='st'>'Create a data table based on the following passage. The table should include </span></span>
<span><span class='st'>information on (1) the names of the characters, (2) their hair color, and (3) their shoe sizes. </span></span>
<span><span class='st'>Use NA for missing information.'</span></span>
<span></span>
<span><span class='va'>text</span> <span class='op'>&lt;-</span> <span class='st'>"Jack and Jill went up the hill to fetch a pail of water. Jack fell down and broke his </span></span>
<span><span class='st'>crown, revealing his stunning golden locks. Investigators on the scene were only able to recover </span></span>
<span><span class='st'>Jack's shoes (size 10) and Jill's shoes (size 8)."</span></span>
<span></span>
<span><span class='fu'><a href='https://rdrr.io/pkg/text2data/man/parse_text.html'>parse_text</a></span><span class='op'>(</span>text <span class='op'>=</span> <span class='va'>text</span>,</span>
<span>           instructions <span class='op'>=</span> <span class='va'>instructions</span>,</span>
<span>           col_names <span class='op'>=</span> <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span><span class='op'>(</span><span class='st'>'Name of Character'</span>, <span class='st'>'Hair Color'</span>, <span class='st'>'Shoe Size'</span><span class='op'>)</span><span class='op'>)</span></span></code></pre>
</div>
</div>
<div class="layout-chunk" data-layout="l-body">

</div>
<div class="layout-chunk" data-layout="l-body">
<pre><code># A tibble: 2 × 3
  `Name of Character` `Hair Color` `Shoe Size`
  &lt;chr&gt;               &lt;chr&gt;        &lt;chr&gt;      
1 Jack                Golden       10         
2 Jill                NA           8          </code></pre>
</div>
<h2 id="practice-problems">Practice Problems</h2>
<ol type="1">
<li><p>Take a sample of the Senate press releases from the <a href="clustering.html">clustering tutorial</a>. Format a few-shot GPT-3 prompt that returns a list of topics. Are the topic labels sensible? Are they similar to what we came up with using unsupervised methods?</p></li>
<li><p>Ask GPT-3 to summarize the remarks on pages 4-5 of the <a href="img/SOJ.pdf">PDF</a> that you imported in the <a href="OCR.html">OCR practice problems</a>.</p></li>
</ol>
<div class="sourceCode" id="cb24"><pre class="sourceCode r distill-force-highlighting-css"><code class="sourceCode r"></code></pre></div>
<div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-brownLanguageModelsAre2020" class="csl-entry" role="listitem">
Brown, Tom B., Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, et al. 2020. <span>“Language Models Are Few-Shot Learners.”</span> <em>arXiv:2005.14165 [Cs]</em>, July. <a href="http://arxiv.org/abs/2005.14165">http://arxiv.org/abs/2005.14165</a>.
</div>
<div id="ref-ornsteinHowTrainYour2022" class="csl-entry" role="listitem">
Ornstein, Joseph T, Elise N Blasingame, and Jake S Truscott. 2022. <span>“How to <span>Train Your Stochastic Parrot</span>: <span>Large Language Models</span> for <span>Political Texts</span>.”</span>
</div>
<div id="ref-spirlingWhyOpensourceGenerative2023" class="csl-entry" role="listitem">
Spirling, Arthur. 2023. <span>“Why Open-Source Generative AI Models Are an Ethical Way Forward for Science.”</span> <em>Nature</em> 616 (7957): 413–13. <a href="https://doi.org/10.1038/d41586-023-01295-4">https://doi.org/10.1038/d41586-023-01295-4</a>.
</div>
<div id="ref-vaswaniAttentionAllYou2017" class="csl-entry" role="listitem">
Vaswani, Ashish, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. <span>“Attention <span>Is All You Need</span>.”</span> <em>arXiv:1706.03762 [Cs]</em>, December. <a href="https://arxiv.org/abs/1706.03762">https://arxiv.org/abs/1706.03762</a>.
</div>
</div>
<section id="footnotes" class="footnotes footnotes-end-of-document" role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>Like many others, I have qualms about using proprietary, closed-source models for scientific research <span class="citation" data-cites="spirlingWhyOpensourceGenerative2023">(<a href="#ref-spirlingWhyOpensourceGenerative2023" role="doc-biblioref">Spirling 2023</a>)</span>. But as of summer 2023 the ease-of-use and capabilities of OpenAI’s models are sufficiently beyond those of similar open-source models that it makes sense to start here. I will update both this page and the R package when I have identified a suitable set of open-source alternatives.<a href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>Note that the default model used by <code>complete_prompt()</code> is “davinci-002”, the 175-billion parameter base GPT-3 model. You can prompt different model variants using the <code>model</code> argument.<a href="#fnref2" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom">
<h3 id="references">References</h3>
<div id="references-listing"></div>
</div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
