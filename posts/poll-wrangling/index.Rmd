---
title: "Poll Wrangling"
author: "Joseph T. Ornstein"
date: '2020-11-02'
slug: poll-wrangling
categories:
 - Data Science
 - Elections
tags:  []
images: []
draft: false
---

```{r preamble, include = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
library(tidyverse)
library(lubridate)
```

In my [Intro to Political Methodology](https://joeornstein.github.io/courses/intro-political-methodology/) class, we wrote some `R` code to wrangle and visualize the presidential polling data aggregated by [fivethirtyeight](https://data.fivethirtyeight.com/). Here's a modified version of what we produced. 

## Import and Tidy

First, here's a script to load and tidy the polling data from 2016 and 2020. We'll keep only the high-quality polls of likely voters (rated B- or higher by fivethirtyeight) conducted since July.

```{r get data}
# 2016 polls
polls_2016 <- read_csv('http://projects.fivethirtyeight.com/general-model/president_general_polls_2016.csv') %>% 
  # reformat dates
  mutate(end_date = as.Date(enddate, format = '%m/%d/%Y')) %>% 
  # keep recent high-quality polls of likely voters
  filter(end_date > '2016-07-01',
         type == 'now-cast', # remove duplicates for different model versions
         grade %in% c('A', 'A-', 'A+', 'B', 'B-', 'B+'),
         population == 'lv')

# 2020 polls from: https://github.com/fivethirtyeight/data/tree/master/polls
polls_2020 <- read_csv('https://projects.fivethirtyeight.com/polls-page/president_polls.csv') %>% 
  #keep the variables we want
  select(question_id, poll_id, state,
         pollster_id, pollster, fte_grade,
         sample_size, population, 
         end_date, candidate_id, candidate_name, pct) %>% 
  # reformat dates
  mutate(end_date = as.Date(end_date, format = '%m/%d/%y')) %>% 
  # keep recent high-quality polls of likely voters (Joe and Donny only)
  filter(candidate_id %in% c(13256, 13254),
         end_date > '2020-07-01',
         fte_grade %in% c('A','A-','A/B','A+',
                          'B', 'B-', 'B/C', 'B+'),
         population == 'lv',
         # drop the Morning Consult daily tracker; a bit duplicative
         pollster != "Morning Consult") %>% 
  # pivot the percentage into their own columns
  pivot_wider(id_cols = question_id:end_date,
              names_from = candidate_name, 
              values_from = pct) %>% 
  rename('biden' = `Joseph R. Biden Jr.`,
         'trump' = `Donald Trump`) %>% 
  # for polls with multiple questions, take the average value across questions
  group_by(poll_id, state,
           pollster_id, pollster, fte_grade,
           sample_size, population, 
           end_date) %>% 
  summarize(biden = mean(biden),
            trump = mean(trump))
```

Next, bring in a dataset of state-level election results from the [MIT Election Data + Science Lab](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/42MVDX).

```{r election results}
results <- read_csv('data/1976-2016-president.csv')
```

## Visualize

Now let's create some visualizations to compare the 2016 presidential election polls with those from this year. Start by merging the two datasets together.

```{r create superset}
polls <- polls_2016 %>%
  mutate(cycle = 2016,
         democrat = rawpoll_clinton,
         republican = rawpoll_trump,
         # add four years so they plot on the same x-axis scale
         end_date = end_date + years(4)) %>% 
  select(cycle, end_date, state, democrat, republican) %>% 
  bind_rows(polls_2020 %>% 
              ungroup %>% 
              mutate(cycle = 2020,
                     democrat = biden,
                     republican = trump) %>% 
              select(cycle, end_date, state, democrat, republican))
```

Create a function to plot the 2016 and 2020 polls side-by-side for a given state.

```{r plot swing states 2016}

plot_polls <- function(state_to_plot, start_date = '09-01'){
  
  # get the 2016 results
  republican_2016 <- results %>% 
    filter(year == 2016, 
           state %in% state_to_plot,
           candidate == 'Trump, Donald J.') %>% 
    mutate(pct = candidatevotes / totalvotes * 100) %>% 
    pull(pct)
  
  democrat_2016 <- results %>% 
    filter(year == 2016, 
           state %in% state_to_plot,
           candidate == 'Clinton, Hillary') %>% 
    mutate(pct = candidatevotes / totalvotes * 100) %>% 
    pull(pct)
  
  polls %>% 
    filter(state == state_to_plot,
           end_date > paste0('2020-', start_date)) %>% 
    ggplot() +
    geom_point(mapping = aes(x=end_date, y=democrat), 
               color = 'blue', alpha = 0.2) +
    geom_smooth(mapping = aes(x=end_date, y=democrat), 
                color = 'blue', se = FALSE, method = 'loess') +
    geom_point(mapping = aes(x=end_date, y=republican),
               color = 'red', alpha = 0.2) +
    geom_smooth(mapping = aes(x=end_date, y=republican),
                color = 'red', se = FALSE, method = 'loess') +
    facet_grid(~cycle) +
    theme_bw() +
    labs(x = 'Poll End Date', y = 'Raw Polling Percentage',
         title = paste0(state_to_plot, ' Polls')) +
    geom_hline(yintercept = republican_2016, color = 'red',
               linetype = 'dashed', size = 1) +
    geom_hline(yintercept = democrat_2016, color = 'blue',
               linetype = 'dashed', size = 1)
  
}
```

### The Blue Wall

Let's start by looking at the good old [Blue Wall](https://fivethirtyeight.com/features/there-is-no-blue-wall/) states: Wisconsin, Michigan, and Pennsylvania. The horizontal dashed lines mark the 2016 election result.

```{r wisconsin}
plot_polls('Wisconsin')
```

In Wisconsin, the size of Biden's polling lead is roughly the same as Clinton's was in 2016. The major difference is the intercept shift, reflecting a much smaller share of undecided voters. Whereas Clinton never polled higher than 50% among badgers, Biden has pretty consistenly averaged higher than 50%. That matters, because even if undecideds break strongly to Trump as they did in 2016, that alone wouldn't produce a polling error big enough for him to win there.

```{r michigan}
plot_polls('Michigan')
```

In 2016, the Michigan polls tightened significantly in the final weeks. Contrary to [some protestations](https://nymag.com/intelligencer/2016/11/donald-trump-is-not-going-to-win-michigan.html), the polls really suggested a squeaker, and Trump won by a razor-thin margin. It is difficult to look at the 2020 chart -- where he has never led a single poll -- and conclude that he can pull off a similar result this year.

```{r pennsylvania}
plot_polls('Pennsylvania')
```

Pennsylvania is the state Trump [needs to win](https://fivethirtyeight.com/features/is-joe-biden-toast-if-he-loses-pennsylvania/) this year. He can plot a plausible course to 270 without Michigan and Wisconsin, but not Pennsylvania. And while the margin is closer than in the other two states, the general pattern is the same. The 2016 polls were very close in the final week, and Clinton never polled greater than 50%. In 2020, Trump needs an even bigger polling error in his favor, without the benefit of a pool of undecided voters.

### The South and Southwest

Next, a few states where Clinton was not likely to win, but Biden might be:

```{r Georgia}
plot_polls('Georgia')
```

In Georgia, Trump won basically by the margin predicted by the polls in 2016. Today, everything is within the margin of error. I have nothing prognosticatory to say here. It's a complete toss-up.

```{r Arizona}
plot_polls('Arizona')
plot_polls('North Carolina')
plot_polls('Florida')
```

Arizona, Florida, and North Carolina all kind of look like the Midwestern states, except with much tighter margins. Biden has consistently led in the polling average, but by a margin that would not require a surprising polling error to surmount.

### A Few Other States

These I present without comment, except that why are there so few quality polls in these states this year? It would be nice to have more data.

```{r other states}
plot_polls('Nevada')
plot_polls('Minnesota')
plot_polls('Virginia')
plot_polls('Alaska')
```

## Putting It All Together

So what would Trump need to cobble together a win tomorrow? The following is nothing nearly as sophisticated as Nate Silver's recency- and quality-weighted moving average. I'm just going to take the mean of the last three weeks of high-quality polls, and compare the polling miss in 2016 with Biden's margin today.

```{r polling errors}

# function to get the polling margin in 2016
polling_margin_2016 <- function(data, state_name, num_weeks = 2){
  data %>% 
    filter(end_date > ymd('2016-11-08') - weeks(num_weeks),
           state == state_name) %>% 
    mutate(clinton_margin = rawpoll_clinton - rawpoll_trump) %>% 
    pull(clinton_margin) %>% 
    mean
}

# function to get the polling margin in 2020
polling_margin_2020 <- function(data, state_name, num_weeks = 2){
  data %>% 
    filter(end_date > ymd('2020-11-03') - weeks(num_weeks),
           state == state_name) %>%
    mutate(biden_margin = biden - trump) %>% 
    pull(biden_margin) %>%
    mean
}

# get the results from 2020
results_2016 <- results %>% 
  filter(year == 2016,
         candidate %in% c('Trump, Donald J.','Clinton, Hillary')) %>%
  group_by(state, candidate, totalvotes) %>%
  summarize(candidatevotes = sum(candidatevotes)) %>% 
  mutate(pct = candidatevotes / totalvotes * 100) %>% 
  select(state, candidate, pct) %>% 
  pivot_wider(names_from = candidate, values_from = pct) %>%
  mutate(clinton_actual_margin_2016 = `Clinton, Hillary` - `Trump, Donald J.`) %>% 
  select(state, clinton_actual_margin_2016)

# compute the polling error for key swing states, merge with 2020 polling margin
swing_states <- tibble(state = c('Pennsylvania', 'Wisconsin', 'Michigan',
                                 'Florida', 'North Carolina', 'Arizona',
                                 'Ohio', 'Virginia', 'Nevada', 'Georgia',
                                 'Iowa', 'Minnesota')) %>% 
  mutate(clinton_polling_margin_2016 = 
           map(state, ~polling_margin_2016(data = polls_2016,
                                           state_name = .x,
                                           num_weeks = 3)) %>% 
           unlist,
         biden_polling_margin_2020 = 
           map(state, ~polling_margin_2020(data = polls_2020,
                                           state_name = .x,
                                           num_weeks = 3)) %>% 
           unlist) %>% 
  left_join(results_2016, by = 'state') %>% 
  # join with state abbreviations for visualization
  left_join(tibble(state.abb, state.name) %>% 
              rename('state' = state.name),
            by = 'state') %>% 
  mutate(polling_error_2016 = clinton_actual_margin_2016 - clinton_polling_margin_2016)

ggplot(data = swing_states) +
  geom_text(mapping = aes(x = -polling_error_2016, 
                          y = biden_polling_margin_2020,
                          label = state.abb)) +
  theme_bw() + 
  geom_abline(intercept = 0, slope = 1, linetype = 'dashed') +
  labs(x = 'Polling Error in 2016', 
       y = 'Polling Error Trump Needs in 2020')
```

The figure paints a difficult, if not impossible, challenge for Trump to overcome. Assume, for a moment, that he wins all the states below the dotted line. All that would require is a modest polling error in his favor, less than the error he benefited from in 2016. But even in that universe, Trump still needs a bigger-than-2016 polling error in both Florida *and* Pennsylvania to get to 270.

Saying "the polls were wrong in 2016 and could be wrong in 2020" is a weaker argument than you need to believe that Trump will win in 2020. Instead, the 2020 polls must be (a) wrong in the same direction as they were in 2016 and (b) significantly wronger-than-2016 in both Pennsylvania and Florida.

## Further Reading

[Matt Yglesias](https://www.vox.com/21524703/biden-trump-poll-lead-2016)