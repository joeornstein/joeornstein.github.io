{
  "articles": [
    {
      "path": "index.html",
      "title": "Political Analysis in R",
      "description": "The website for the course.\n",
      "author": [
        {
          "name": "Joe Ornstein",
          "url": "https://joeornstein.github.io/"
        }
      ],
      "contents": "\r\n\r\nContents\r\nOverview\r\nGetting\r\nStarted\r\nThe Programming Language\r\n(R)\r\nThe\r\nInterface (RStudio)\r\nOPTIONAL: Version Control\r\n(git)\r\nOPTIONAL: Memory Aid (Anki)\r\nOPTIONAL: Reference\r\nManagement (Zotero)\r\n\r\n\r\nOverview\r\nIn this course, you’ll learn how to work with data using the\r\nR programming language.1 By the end of the\r\nsemester, you’ll be able to:\r\nWrite R scripts to import, tidy, and summarize\r\ndatasets\r\nCreate beautiful and informative data visualizations\r\nDraw thoughtful conclusions from data\r\nOrganize your work so that it is transparent and reproducible\r\nAll the course materials you need will be available on this website.\r\nCheck the Schedule tab for an overview of each week’s\r\ntopics and assignments. On the navbar, you can also find links to read the syllabus, schedule an office hours\r\nappointment, and visit the\r\nclass code repository.\r\nGetting Started\r\nThere is a lot of software to install for this class, but in the\r\ninstructions below I’ve tried to make it as straightforward as possible.\r\n(And everything is free!) Before the end of our first week, please\r\ncomplete the following steps.\r\n\r\nThe Programming Language (R)\r\nYou won’t get super far in an R class without\r\nR. The most current version is available here. To download, click link\r\nfor your operating system (i.e. Mac, Windows, Linux), then follow the\r\ninstructions on the page.\r\nThe Interface (RStudio)\r\nR is the programming language itself, but it comes with\r\na pretty unfriendly interface.\r\n\r\nYou don’t want to do all your typing in that lonely black box.\r\nInstead, you want RStudio, a piece of software that\r\nmakes R much prettier. Download the RStudio\r\nDesktop version here.\r\nOPTIONAL: Version Control\r\n(git)\r\nProfessional coders use a version control system\r\ncalled git to keep track of their code. If you’re on a Mac,\r\nskip this section. Your machine already has it installed.2 If\r\nyou use a PC, follow the installation instructions here.\r\nOnce git is installed, it will want you to introduce\r\nyourself. To do so, follow these three steps:\r\n1. In RStudio, click `Tools > Shell`. This will open your\r\ncomputer’s shell, a\r\nprogram that runs other programs.\r\n2. Type and enter\r\ngit config --global user.name 'Jane Doe' (substituting your\r\nname for Jane Doe).\r\n3. Type and enter\r\ngit config --global user.email 'jane@example.com'\r\n(substituting your email for that fake email address).\r\nUsing git to track changes in your code involves a bit\r\nof struggle on the front end, but it is well worth it (Bryan 2017).3\r\nI’ll walk you through the basics in class.\r\nOPTIONAL: Memory Aid (Anki)\r\nA lot of learning to write code is memorizing the names of functions\r\nand what they do. This is the boring and frustrating part, but there are\r\nways to make it somewhat less boring and frustrating. Do yourself a\r\nfavor and take 20 minutes and play through Case (2018). If you’re convinced, download Anki. It’s not the prettiest spaced\r\nrepetition software out there, but it is free, streamlined, highly\r\ncustomizable, and has a large, dedicated fanbase.\r\nOPTIONAL: Reference\r\nManagement (Zotero)\r\nYou won’t need Zotero to complete any of the assignments in this\r\nclass, but I like to evangelize it whenever I can. This software makes\r\nit blindingly simple to keep track of and format your citations. It also\r\nplays really nicely with RStudio. Download it here and follow the setup\r\ninstructions. The Chrome\r\nextension is particularly useful; anything you find on the Internet\r\ncan be saved to your library with one click.\r\n\r\n\r\n\r\nBryan, Jennifer. 2017. “Excuse Me, Do You Have a Moment to Talk\r\nabout Version Control?” https://doi.org/10.7287/peerj.preprints.3159v2.\r\n\r\n\r\nCase, Nicky. 2018. “How To Remember Anything Forever-Ish.”\r\nhttps://ncase.me/remember/.\r\n\r\n\r\nR is a powerful (and\r\nin-demand!) tool for data analysis and communication. For example, this\r\nvery website was built with R.↩︎\r\nI think? If you’re on a Mac and you\r\ncan’t get git to work, let me know!↩︎\r\nIt’s something you can put on your\r\nresume and people will be super impressed.↩︎\r\n",
      "last_modified": "2022-08-19T09:40:46-04:00"
    },
    {
      "path": "week-01.html",
      "title": "Week 1",
      "description": "Getting all the software up and running",
      "author": [],
      "contents": "\r\n\r\nContents\r\nIntroductions\r\nReading\r\nAssignments\r\nTeam Project\r\n\r\nThis week, we’ll make sure that everything we need is installed and\r\nworking on our computers. To begin, please complete the instructions in\r\nthe Getting Started section on\r\nthe home page.\r\nIntroductions\r\nOn the first day, we’ll begin by collecting and analyzing some data\r\nabout the class. Please complete the following survey.1\r\n\r\n\r\n\r\n\r\nThe responses will be available here.\r\nReading Assignments\r\nBefore next week, please read and annotate the following:\r\nThe Syllabus\r\nHealy Preface\r\n(and complete the package installation instructions at the bottom)\r\nHealy\r\nChapter 2\r\nTeam Project\r\nOur first project will ensure that all the software is functioning on\r\nyour machine. If you can complete all of the following steps, then\r\nyou’re in good shape!\r\nDownload the folder from the class GitHub repository and open\r\npolitical-analysis-in-R.Rproj.\r\nOpen R/week-01-introduction/project-01.R.\r\nUpdate the author and date in the metadata at the top. (You’re\r\nthe author. The date is today.)\r\nUpdate the script so that it filters the data for your name and\r\nsex (or some other name and sex of your choice) instead of the male\r\n“Joseph”s.\r\nMake sure you have the tinytex package installed.\r\nThis is the library you need to convert RMarkdown documents into PDFs.\r\nTo install, enter these two lines into your RStudio console.\r\n\r\n\r\ninstall.packages('tinytex')\r\ntinytex::install_tinytex()\r\n\r\n\r\n\r\nClick ‘Compile Report’ (Ctrl + Shift + K) and output to\r\nPDF.\r\nSubmit the resulting PDF document to eLC.\r\n\r\nIf the embedded survey isn’t working\r\nfor some reason, click here.↩︎\r\n",
      "last_modified": "2022-08-19T09:40:47-04:00"
    },
    {
      "path": "week-02.html",
      "title": "Week 2",
      "description": "The week we make our first data visualizations!",
      "author": [],
      "contents": "\r\n\r\nContents\r\nReading\r\nAssignments\r\nTeam Project\r\n\r\nIn its raw form, data is completely unintelligible – it’s just a\r\nbunch of numbers, and our brains aren’t really good at juggling a bunch\r\nof numbers. But our brains are extremely good at seeing\r\npatterns in visual images. Well-crafted data visualizations take\r\nadvantage of that fact to communicate lots of information in an\r\naesthetically pleasing way.\r\n\r\nThis week, we start building our own visualizations using the\r\nggplot2 package (a part of the tidyverse). It\r\nwill take some time to learn all of the function syntax, so be patient\r\nwith yourself. Once you get the hang of it, you’ll have an endlessly\r\nflexible tool for exploring and communicating patterns in your data.\r\nLet’s get started.\r\nReading Assignments\r\nBefore next week, please read and annotate the following:\r\nHealy Chapter 3\r\nHealy Chapter\r\n4\r\nTeam Project\r\nLocate the file R/week-02-ggplot/project-02.qmd in our\r\ncode repository. Open it, complete the instructions therein, and submit\r\nthe resulting PDF to eLC.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-08-19T09:40:50-04:00"
    },
    {
      "path": "week-03.html",
      "title": "Week 3",
      "description": "After this week, your charts will be *extremely* fancy",
      "author": [],
      "contents": "\r\n\r\nContents\r\nReading\r\nAssignments\r\nTeam Project\r\n\r\nThis week, we expand our data visualization repertoire, exploring\r\ndifferent kinds of data (e.g. distributions, change over time) and\r\nmaking our charts prettier and prettier.\r\nReading Assignments\r\nBefore next week, please read and annotate Wrangling\r\nPenguins, by Allison Horst. You’ll learn what to do when your data\r\ndoesn’t come to you exactly the way you want it.\r\nTeam Project\r\nCreate a bar chart from a categorical variable in the CES dataset.\r\nFacet by two other categorical variables. Make it pretty. Save the chart\r\nwith ggsave() and submit the image plus the R script that\r\nproduced it to eLC.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-08-19T09:40:51-04:00"
    },
    {
      "path": "week-04.html",
      "title": "Week 4",
      "description": "Wrangle that data into shape",
      "author": [],
      "contents": "\r\n\r\nContents\r\nReading\r\nAssignments\r\nTeam Project\r\n\r\nUp to now, we’ve been working with pretty tidy datasets. Every column\r\nis a variable, every row is an observation, and every value is where it\r\nshould be. But things are not always this way. More often than you’re\r\ngoing to like, data comes to you an unruly mess, and you’ll need to tidy\r\nit up before you can even start to explore it.\r\n Over the next few weeks, we’ll\r\nlearn some of the most important functions in the tidyverse\r\nfor data wrangling.\r\nReading Assignments\r\nBefore next week, read up on:\r\nHow to join information from two dataframes\r\ntogether. left_join() is the most useful. Here’s a good\r\nexplanation, and here’s an interactive primer.1\r\nHealy Chapter 5\r\nTeam Project\r\nTBD\r\n\r\nWarning: doesn’t play nice with\r\nHypothesis highlights, but you can still leave page notes.↩︎\r\n",
      "last_modified": "2022-08-19T09:40:52-04:00"
    },
    {
      "path": "week-05.html",
      "title": "Week 5",
      "description": "Getting information from multiple sources to play nicely",
      "author": [],
      "contents": "\r\n\r\nContents\r\nReading\r\nAssignments\r\nTeam Project\r\n\r\nThis week, we talk about merging data from multiple\r\nsources. Also there’s a quiz.\r\n\r\nReading Assignments\r\nNo new reading assignments this week! Take the time to catch up on\r\nanything you missed.\r\nTeam Project\r\nRead over the CES codebook and pick some survey questions you find\r\ninteresting. Modify R/week-04-clean-ces-2020 to clean up\r\nand include those variables, and create a new data visualization. Your\r\nvisualization should be pretty, easy to understand, and tell an\r\ninteresting story! Submit your image and the R script that produced it\r\nto eLC.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-08-19T09:40:54-04:00"
    },
    {
      "path": "week-06.html",
      "title": "Week 6",
      "description": "Putting it all together",
      "author": [],
      "contents": "\r\n\r\nContents\r\nReading\r\nAssignments\r\nTeam Project\r\n\r\nThis week, we review the entire data analysis pipeline from start to\r\nfinish: how to find the data, import it, clean it up, summarize it, and\r\nbuild a visualization.\r\n\r\nIf you’re looking for additional practice with the skills we’ve\r\nlearned over the past five weeks, I highly recommend the RStudio primers, a set of\r\ninteractive online tutorials. To review the functions we’ve covered so\r\nfar, check out “The Basics”, “Work With Data”, “Visualize Data”, and\r\n“Tidy Your Data”. The other primers are more advanced R\r\nfunctions – you may try them if you’re looking for an extra\r\nchallenge.\r\nReading Assignments\r\nNext week, we start making maps! Before then, please read:\r\nHealy Chapter 7\r\nTeam Project\r\nReproduce Figure 1.8 (or Figure 1.9, your choice) from Chapter 1 of the Healy\r\nbook. You can ignore the shaded confidence interval, but add six\r\ncountries not included in the original plot.1\r\nWrite a report in RMarkdown including your chart, and submit the report\r\nto eLC as a knitted PDF.\r\nTo get PDF knitting working, first enter these two commands into your\r\nRStudio console:\r\ninstall.packages('tinytex')\r\ntinytex::install_tinytex()\r\nI want to know what this trend looks\r\nlike in, for example, non-democratic countries!\r\n\r\n↩︎\r\n",
      "last_modified": "2022-08-19T09:40:55-04:00"
    },
    {
      "path": "week-07.html",
      "title": "Week 7",
      "description": "Drawing Maps",
      "author": [],
      "contents": "\r\n\r\nContents\r\nReading\r\nAssignments\r\nTeam Project\r\n\r\nThis week, we’ll learn to draw maps to represent geographic data with\r\nggplot. We’ll discuss both the code you need and the\r\naesthetic choices you should be aware of when working with spatial\r\ndata.\r\n\r\nReading Assignments\r\nNext week, we play with interactive maps using the\r\nleaflet package. Before then, please read:\r\nIntroduction to\r\nLeaflet\r\nThe Map\r\nWidget\r\nUsing\r\nBasemaps\r\nAdding\r\nMarkers\r\nColors\r\nLegends\r\nChoropleths\r\nTeam Project\r\nDraw a map with R illustrating some interesting data.\r\nAnything you choose. If you need ideas, consider:\r\nA state-level map of answers to a question in the Cooperative\r\nElection Study 2020.\r\nA world map of answers to a question in the World Values\r\nSurvey.\r\nA county-level map of COVID-19 infections from the NYT\r\nrepository.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-08-19T09:40:56-04:00"
    },
    {
      "path": "week-08.html",
      "title": "Week 8",
      "description": "Fancy Maps",
      "author": [],
      "contents": "\r\n\r\nContents\r\nSample Code\r\nReading\r\nAssignments\r\nTeam Project\r\n\r\nThis week, we’ll make our maps zoom-able and interactive with the\r\nleaflet package.\r\nSample Code\r\nHere’s a demonstration, plotting the county-level 2020 presidential\r\nelection results for each county in Georgia.1\r\nFirst, load all the packages we need:\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(ggthemes) # for the theme_map() layer\r\nlibrary(sf) # functions for working with spatial data\r\nlibrary(tigris) # for map data from the US Census\r\nlibrary(leaflet) # for interactive maps\r\n\r\n\r\n\r\nNext, we’ll get our map data from the tigris package.\r\nThe format of this data is called a Simple Feature, or sf\r\nobject. It is a more compact way of representing GIS data, and is\r\nquickly becoming the standard way to do things.\r\n\r\n\r\ncounty_map <- counties('Georgia')\r\n\r\nhead(county_map)\r\n\r\n\r\nSimple feature collection with 6 features and 17 fields\r\nGeometry type: MULTIPOLYGON\r\nDimension:     XY\r\nBounding box:  xmin: -85.46221 ymin: 31.01044 xmax: -81.73169 ymax: 34.58748\r\nGeodetic CRS:  NAD83\r\n    STATEFP COUNTYFP COUNTYNS GEOID     NAME        NAMELSAD LSAD\r\n16       13      189 00348794 13189 McDuffie McDuffie County   06\r\n53       13      025 00351605 13025 Brantley Brantley County   06\r\n54       13      171 00326713 13171    Lamar    Lamar County   06\r\n83       13      115 00353665 13115    Floyd    Floyd County   06\r\n102      13      273 00352238 13273  Terrell  Terrell County   06\r\n103      13      063 01672399 13063  Clayton  Clayton County   06\r\n    CLASSFP MTFCC CSAFP CBSAFP METDIVFP FUNCSTAT      ALAND   AWATER\r\n16       H1 G4020  <NA>  12260     <NA>        A  666590014 23114032\r\n53       H1 G4020  <NA>  15260     <NA>        A 1147972258 10291563\r\n54       H1 G4020   122  12060     <NA>        A  475264404  6044329\r\n83       H1 G4020   122  40660     <NA>        A 1320404595 22414013\r\n102      H1 G4020  <NA>  10500     <NA>        A  869695791  4951325\r\n103      H1 G4020   122  12060     <NA>        A  366879097  6962586\r\n       INTPTLAT     INTPTLON                       geometry\r\n16  +33.4806126 -082.4795333 MULTIPOLYGON (((-82.44998 3...\r\n53  +31.1973339 -081.9829779 MULTIPOLYGON (((-81.91012 3...\r\n54  +33.0744405 -084.1466893 MULTIPOLYGON (((-84.24837 3...\r\n83  +34.2636918 -085.2136851 MULTIPOLYGON (((-85.24134 3...\r\n102 +31.7771909 -084.4394464 MULTIPOLYGON (((-84.56317 3...\r\n103 +33.5426863 -084.3555727 MULTIPOLYGON (((-84.45856 3...\r\n\r\nNotice that this may take a little while, because it’s downloading\r\nthe shape data from the Census. Next we’ll merge that map data with the\r\ncounty-level election results.\r\n\r\n\r\n# load data from project folder\r\nload('../data/county-results-2020-for-map.RData')\r\n\r\n# we're going to merge by fips code, so \r\n# make sure that the fips code in each dataset\r\n# is named the same thing and is in the same format\r\ncounty_map <- mutate(county_map, \r\n                     fips = as.numeric(GEOID))\r\n\r\ncounties_2020 <- mutate(counties_2020,\r\n                        fips = as.numeric(county_fips))\r\n\r\n# join the map data and the election results data together\r\nd <- left_join(county_map, counties_2020, by = 'fips')\r\n\r\n\r\n\r\nWe can plot sf objects with ggplot using\r\nthe geom_sf() layer.\r\n\r\n\r\n# define the hex color codes for Democratic Blue and Republican Red\r\nparty_colors <- c(\"#CB454A\", 'gray', \"#2E74C0\") \r\n\r\nggplot(data = d,\r\n       mapping = aes(fill = percent_biden)) +\r\n  geom_sf() +\r\n  scale_fill_gradient2(low = party_colors[1],\r\n                       mid = party_colors[2],\r\n                       high = party_colors[3],\r\n                       midpoint = 50) +\r\n  theme_map() +\r\n  theme(legend.position = 'bottom') +\r\n  labs(fill = 'Biden Two-Party Vote Share')\r\n\r\n\r\n\r\n\r\nAnd we can make an interactive map with leaflet(). See\r\nhere\r\nfor instructions on modifying the color palette, and here\r\nfor the complete list of base maps you can add.\r\n\r\n\r\n# create the color scheme\r\npal <- colorNumeric(\r\n  palette = party_colors,\r\n  domain = d$percent_biden)\r\n\r\np <- leaflet(data = d) %>% \r\n  # add the county polygons, with fill color based on Biden vote share and label with county name\r\n  addPolygons(fillColor = ~pal(percent_biden),\r\n              weight = 1,\r\n              opacity = 1,\r\n              color = 'white',\r\n              fillOpacity = 0.7,\r\n              label = d$NAME) %>% \r\n  # add a basemap\r\n  addProviderTiles(providers$Esri.WorldGrayCanvas) %>% \r\n  # add a legend\r\n  addLegend(pal = pal, values = ~percent_biden,\r\n            opacity = 0.7, title = NULL,\r\n            position = 'bottomright')\r\n\r\np\r\n\r\n\r\n\r\n\r\nReading Assignments\r\nNext week, we discuss the challenges and opportunities presented by\r\ndata that is collected across multiple time periods. To prepare, please\r\nread and annotate Chapter 16 of\r\nR For Data Science.\r\nTeam Project\r\nRevise your map from last week based on our in-class feedback. Submit\r\nboth a still image of your map from ggplot() and create an\r\ninteractive version of the map with leaflet() to show off\r\nin class next week.\r\n\r\nAll the code is available on the\r\nrepository at\r\nR/week-08/interactive-map-election-results-2020.R.↩︎\r\n",
      "last_modified": "2022-08-19T09:41:20-04:00"
    },
    {
      "path": "week-09.html",
      "title": "Week 9",
      "description": "Middle-of-the-semester stuff",
      "author": [],
      "contents": "\r\n\r\nContents\r\nMidterm\r\nSurvey\r\nPractice\r\nQuiz\r\nReading\r\nAssignments\r\nTeam Project\r\n\r\nMidterm Survey\r\n\r\n\r\n\r\n\r\nPractice Quiz\r\nFor the quiz this week, you will fix errors in a script that creates\r\na map with ggplot – importing, tidying, and joining\r\ndatasets along the way. You can practice these skills at\r\nR/week-08/quiz-2-practice.R\r\nReading Assignments\r\nNo reading assignments!\r\nTeam Project\r\nNo team project!\r\n\r\n\r\n\r\n",
      "last_modified": "2022-08-19T09:41:22-04:00"
    },
    {
      "path": "week-10.html",
      "title": "Week 10",
      "description": "What to do about time...",
      "author": [],
      "contents": "\r\n\r\nContents\r\nExample Code\r\nSolution 1: Look at\r\nCross-Sections\r\nSolution 2: Look at a time\r\nseries\r\nSolution 3: Make a movie!\r\n\r\nReading\r\nAssignments\r\nTeam Project\r\n\r\nThis week, we discuss how to work with datasets that include\r\ninformation from multiple time periods.\r\nExample Code\r\nLet’s look at the relationship between national income and life\r\nexpectancy in the gapminder dataset. Do people in wealthier\r\ncountries live longer on average?\r\n\r\n\r\nlibrary(tidyverse)\r\nlibrary(gapminder)\r\n\r\nhead(gapminder)\r\n\r\n\r\n# A tibble: 6 × 6\r\n  country     continent  year lifeExp      pop gdpPercap\r\n  <fct>       <fct>     <int>   <dbl>    <int>     <dbl>\r\n1 Afghanistan Asia       1952    28.8  8425333      779.\r\n2 Afghanistan Asia       1957    30.3  9240934      821.\r\n3 Afghanistan Asia       1962    32.0 10267083      853.\r\n4 Afghanistan Asia       1967    34.0 11537966      836.\r\n5 Afghanistan Asia       1972    36.1 13079460      740.\r\n6 Afghanistan Asia       1977    38.4 14880372      786.\r\n\r\nNotice that the gapminder dataset has country-level data\r\non life expectancy, population, and GDP per capita every five years\r\nbetween 2007 and 2007. So when you plot it all together, it looks like\r\nthis:\r\n\r\n\r\np <- ggplot(data = gapminder,\r\n            mapping = aes(x = gdpPercap,\r\n                          y = lifeExp,\r\n                          color = continent,\r\n                          size = pop)) +\r\n  geom_point(alpha = 0.5) +\r\n  scale_x_log10(labels = scales::dollar) +\r\n  scale_size_continuous(labels = scales::comma,\r\n                        breaks = c(1e5, 5e5,\r\n                                   1e6, 5e6,\r\n                                   5e7, 2e8,\r\n                                   1e9)) +\r\n  theme_minimal() + \r\n  labs(x = 'GDP Per Capita',\r\n       y = 'Life Expectancy',\r\n       color = 'Continent',\r\n       size = 'Population',\r\n       title = 'The Health and Wealth of Nations')\r\n\r\np\r\n\r\n\r\n\r\n\r\nIt looks like a strong relationship between wealth and health, but\r\nmaybe it’s just that both GDP and life expectancy have been increasing\r\nover time, which causes a spurious correlation. Like plotting\r\nUS margarine\r\nconsumption and the divorce rates over time. To be sure we know\r\nwhat’s going on, we want to take a few precautions.\r\nSolution 1: Look at\r\nCross-Sections\r\nInstead of plotting all the data at once, just filter out a single\r\nyear and see if there’s a relationship. This is called taking a\r\ncross-section.\r\n\r\n\r\nggplot(data = filter(gapminder, year == 2007),\r\n            mapping = aes(x = gdpPercap,\r\n                          y = lifeExp,\r\n                          color = continent,\r\n                          size = pop)) +\r\n  geom_point(alpha = 0.5) +\r\n  scale_x_log10(labels = scales::dollar) +\r\n  scale_size_continuous(labels = scales::comma,\r\n                        breaks = c(1e5, 5e5,\r\n                                   1e6, 5e6,\r\n                                   5e7, 2e8,\r\n                                   1e9)) +\r\n  theme_minimal() + \r\n  labs(x = 'GDP Per Capita',\r\n       y = 'Life Expectancy',\r\n       color = 'Continent',\r\n       size = 'Population',\r\n       title = 'The Health and Wealth of Nations (2007)')\r\n\r\n\r\n\r\n\r\nStill a relationship!\r\nSolution 2: Look at a time\r\nseries\r\nInstead of looking at all the countries at once, let’s isolate a\r\nsingle country and see what’s happening to its GDP and life expectancy\r\nover time. The geom_path() layer connects points based on\r\ntheir order in the dataset (rather than their order on the x-axis like\r\ngeom_line()).\r\n\r\n\r\nggplot(data = filter(gapminder, country == 'Poland'),\r\n            mapping = aes(x = gdpPercap,\r\n                          y = lifeExp,\r\n                          label = year)) +\r\n  geom_text() +\r\n  geom_path() +\r\n  scale_x_log10(labels = scales::dollar) +\r\n  scale_size_continuous(labels = scales::comma,\r\n                        breaks = c(1e5, 5e5,\r\n                                   1e6, 5e6,\r\n                                   5e7, 2e8,\r\n                                   1e9)) +\r\n  theme_minimal() + \r\n  labs(x = 'GDP Per Capita',\r\n       y = 'Life Expectancy',\r\n       color = 'Continent',\r\n       size = 'Population',\r\n       title = 'The Health and Wealth of Poland')\r\n\r\n\r\n\r\n\r\nSolution 3: Make a movie!\r\nWhy just look at a cross-section or a time series, when you\r\ncan do both simultaneously? Take that original plot object\r\np and make the dots move over time:\r\n\r\n\r\nlibrary(gganimate)\r\n\r\np + transition_time(time = year)\r\n\r\n\r\n\r\n\r\nNow we can see the trajectory of individual countries over time\r\n(check out China - the big one!) and verify that the relationship\r\nbetween health and wealth is positive from the 1950s all the way to\r\ntoday.\r\nReading Assignments\r\nNext week, text as data! The following tutorial is your guide to the\r\ntidytext package, and make you’ve completed the\r\ninstructions to sign up for the Twitter\r\nAPI.\r\nText\r\nMining with Tidy Data Principles\r\nTeam Project\r\nCreate an animation of a time series dataset. Post the replication\r\ncode to eLC.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-08-19T09:42:20-04:00"
    },
    {
      "path": "week-11.html",
      "title": "Weeks 11-12",
      "description": "Text As Data",
      "author": [],
      "contents": "\r\n\r\nContents\r\nGetting Twitter Data\r\nTeam Project\r\n\r\nGetting Twitter Data\r\nTo get data from Twitter, we need to sign up for their API\r\n(Application Programming Interface). That will allow us to import tweets\r\ndirectly into R.\r\nBut getting set up with the API is a bit of a hassle. The following\r\ndirections are, to the best of my knowledge, the most pain-free way to\r\ndo it:\r\nApply for a Twitter developer account here. If you already have a\r\npersonal account, you can login with that username and password, or\r\ncreate a new account.\r\nComplete the application for a standard developer account. In the\r\napplication, tell them that you’re taking an undergraduate data science\r\nclass at the University of Georgia, and you’ll be using the Twitter\r\ndeveloper account to search for Tweets through the API and conduct basic\r\ntext-as-data analysis, including tokenization, visualization, and\r\nsentiment analysis. You do not plan to Tweet, Retweet, or Like anything\r\nusing your developer account, and you do not plan to display Twitter\r\ncontent off of Twitter.\r\nYou may receive an email from Twitter asking you additional\r\nquestions. I responded to this email by politely reiterating what I told\r\nthem the application, and the application was approved shortly\r\nthereafter!\r\nCreate an “app”. Instructions here.\r\nCreate your API token and secret keys. These are your unique\r\n“passwords” for accessing the API. Within your app, click the “keys and\r\ntokens” tab. Copy your Consumer API keys. Scroll down to “Access token\r\n& access token secret.” Click create, and copy the two strings that\r\nare generated (copy them now or you’ll need to go through this process\r\nagain!)\r\nAnd then you’re ready to begin!\r\nTeam Project\r\nImport text data from Twitter through the API and conduct a topic\r\nand/or sentiment analysis. Create a visualization to illustrate your\r\nresults. Submit your R script and image files to eLC.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-08-19T09:42:21-04:00"
    },
    {
      "path": "week-13.html",
      "title": "Weeks 13-15",
      "description": "Topics By Popular Demand + Final Projects",
      "author": [],
      "contents": "\r\nIn the final three weeks of class, we will set aside time for bonus\r\ntopics and final projects. If there is any particular topic or dataset\r\nyou would like to look at in our final weeks, please complete the form\r\nbelow.\r\n\r\n\r\n\r\n\r\nWe will also take a day to collectively agree on a grading rubric for the\r\nfinal projects.\r\n\r\n\r\n\r\n",
      "last_modified": "2022-08-19T09:42:22-04:00"
    }
  ],
  "collections": []
}
